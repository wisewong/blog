<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一次线上CPU突破天际的排查过程]]></title>
    <url>%2F2019%2F02%2F27%2F%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8ACPU%E7%AA%81%E7%A0%B4%E5%A4%A9%E9%99%85%E7%9A%84%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[问题出现 线上报警,看监控图，第一个是cpu使用率，第二个是load 排查步骤 查看cpu使用率高的几个线程 查看gc情况 dump内存分析 根据dump分析结果排查具体原因 排查过程查看cpu使用率高的几个线程查看方法：linux性能瓶颈分析 结果如下：1234567891011121314151617181920212223242526272829303132333435363738394041The stack of busy(83.4%) thread(1549/0x60d) of java pid(1546) all times():&quot;GC task thread#0 (ParallelGC)&quot; os_prio=0 tid=0x00007f98a801e800 nid=0x60d runnable The stack of busy(81.4%) thread(1550/0x60e) of java pid(1546) all times():&quot;GC task thread#1 (ParallelGC)&quot; os_prio=0 tid=0x00007f98a8020000 nid=0x60e runnable The stack of busy(81.4%) thread(1551/0x60f) of java pid(1546) all times():&quot;GC task thread#2 (ParallelGC)&quot; os_prio=0 tid=0x00007f98a8022000 nid=0x60f runnable The stack of busy(77.4%) thread(1552/0x610) of java pid(1546) all times():&quot;GC task thread#3 (ParallelGC)&quot; os_prio=0 tid=0x00007f98a8023800 nid=0x610 runnable The stack of busy(17.9%) thread(1553/0x611) of java pid(1546) all times():&quot;VM Thread&quot; os_prio=0 tid=0x00007f98a8077000 nid=0x611 runnable The stack of busy(0.0%) thread(1546/0x60a) of java pid(1546) all times():The stack of busy(0.0%) thread(1548/0x60c) of java pid(1546) all times():&quot;main&quot; #1 prio=5 os_prio=0 tid=0x00007f98a8009800 nid=0x60c runnable [0x00007f98af608000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409) at java.net.ServerSocket.implAccept(ServerSocket.java:545) at java.net.ServerSocket.accept(ServerSocket.java:513) at org.apache.catalina.core.StandardServer.await(StandardServer.java:452) at org.apache.catalina.startup.Catalina.await(Catalina.java:779) at org.apache.catalina.startup.Catalina.start(Catalina.java:725) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:322) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:456) The stack of busy(0.0%) thread(1554/0x612) of java pid(1546) all times():&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=0 tid=0x00007f98a807e800 nid=0x612 in Object.wait() [0x00007f9898dfc000] java.lang.Thread.State: BLOCKED (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x0000000080782fb0&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153) 很明显，cpu使用率较高的几个线程都是gc线程，ParallelGC并行回收四个gc线程，有三个在80%以上，一个77.4% 结论：内存有问题 查看gc和内存情况12345672019-02-27T20:53:35.407+0800: 183330.132: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398225K-&gt;1398224K(1398272K)] 1675217K-&gt;1675215K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4637406 secs] [Times: user=5.55 sys=0.00, real=1.46 secs]2019-02-27T20:53:36.872+0800: 183331.597: [Full GC (Ergonomics) [PSYoungGen: 276992K-&gt;276991K(475136K)] [ParOldGen: 1398224K-&gt;1398224K(1398272K)] 1675216K-&gt;1675216K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4722518 secs] [Times: user=5.63 sys=0.00, real=1.48 secs]2019-02-27T20:53:38.345+0800: 183333.070: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398226K-&gt;1398226K(1398272K)] 1675218K-&gt;1675218K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4388783 secs] [Times: user=5.50 sys=0.00, real=1.44 secs]2019-02-27T20:53:39.785+0800: 183334.510: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398226K-&gt;1398226K(1398272K)] 1675218K-&gt;1675218K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4565019 secs] [Times: user=5.51 sys=0.00, real=1.45 secs]2019-02-27T20:53:41.242+0800: 183335.967: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398229K-&gt;1398229K(1398272K)] 1675221K-&gt;1675221K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4389919 secs] [Times: user=5.50 sys=0.00, real=1.44 secs]2019-02-27T20:53:42.682+0800: 183337.407: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398231K-&gt;1398231K(1398272K)] 1675223K-&gt;1675223K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.4568581 secs] [Times: user=5.53 sys=0.00, real=1.46 secs]2019-02-27T20:53:44.140+0800: 183338.865: [Full GC (Ergonomics) [PSYoungGen: 276991K-&gt;276991K(475136K)] [ParOldGen: 1398233K-&gt;1398231K(1398272K)] 1675225K-&gt;1675223K(1873408K), [Metaspace: 91794K-&gt;91794K(1134592K)], 1.5388401 secs] [Times: user=5.62 sys=0.00, real=1.54 secs] 一直在full gc，YoungGen 和 OldGen 都gc不掉，每次stw 1.5s左右,不停的在stw,系统无法提供服务 看一下堆内存的使用情况：12345678910111213141516171819202122232425262728293031323334353637383940414243444546Attaching to process ID 1546, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.91-b14 using thread-local object allocation.Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2147483648 (2048.0MB) NewSize = 715653120 (682.5MB) MaxNewSize = 715653120 (682.5MB) OldSize = 1431830528 (1365.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage:PS Young GenerationEden Space: capacity = 283639808 (270.5MB) used = 283639808 (270.5MB) free = 0 (0.0MB) 100.0% usedFrom Space: capacity = 202899456 (193.5MB) used = 0 (0.0MB) free = 202899456 (193.5MB) 0.0% usedTo Space: capacity = 218103808 (208.0MB) used = 0 (0.0MB) free = 218103808 (208.0MB) 0.0% usedPS Old Generation capacity = 1431830528 (1365.5MB) used = 1431780696 (1365.4524765014648MB) free = 49832 (0.04752349853515625MB) 99.99651969985096% used 43030 interned Strings occupying 4910192 bytes. eden使用了100.0% ，old使用了99.99651969985096%，已经基本用完了 所以现在应该看一下内存使用情况，分析一下内存使用哪里出问题了 dump内存分析dump之后用mat分析的结果： 12345678910111213141516171819202122http-bio-8080-exec-58 at java.util.Arrays.copyOf([Ljava/lang/Object;I)[Ljava/lang/Object; (Arrays.java:3181) at java.util.ArrayList.grow(I)V (ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(I)V (ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(I)V (ArrayList.java:227) at java.util.ArrayList.add(Ljava/lang/Object;)Z (ArrayList.java:458) at org.apache.xmlbeans.impl.values.NamespaceContext$NamespaceContextStack.push(Lorg/apache/xmlbeans/impl/values/NamespaceContext;)V (NamespaceContext.java:81) at org.apache.xmlbeans.impl.values.NamespaceContext.push(Lorg/apache/xmlbeans/impl/values/NamespaceContext;)V (NamespaceContext.java:106) at org.apache.xmlbeans.impl.values.XmlObjectBase.check_dated()V (XmlObjectBase.java:1273) at org.apache.xmlbeans.impl.values.XmlObjectBase.stringValue()Ljava/lang/String; (XmlObjectBase.java:1484) at org.apache.xmlbeans.impl.values.XmlObjectBase.getStringValue()Ljava/lang/String; (XmlObjectBase.java:1492) at org.apache.poi.xssf.usermodel.XSSFRichTextString.preserveSpaces(Lorg/openxmlformats/schemas/spreadsheetml/x2006/main/STXstring;)V (XSSFRichTextString.java:491) at org.apache.poi.xssf.usermodel.XSSFRichTextString.&lt;init&gt;(Ljava/lang/String;)V (XSSFRichTextString.java:91) at org.apache.poi.xssf.usermodel.XSSFCell.setCellValue(Ljava/lang/String;)V (XSSFCell.java:315) at com.xxx.ExportUtil.export(Ljavax/servlet/http/HttpServletResponse;[Ljava/lang/String;Ljava/lang/String;Ljava/util/List;)V (ExportUtil.java:53) at com.xxx.ApplyServiceImpl.export(Ljavax/servlet/http/HttpServletResponse;[Ljava/lang/String;Ljava/lang/String;Lcom/xxx/ApplyRequest;)Lcom/xxx/ApplyResultEnum; (ApplyServiceImpl.java:321) at com.xxx.UpDownController.export(Ljavax/servlet/http/HttpServletResponse;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/Integer;ILjava/lang/String;Ljava/lang/Integer;IILjava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ILjava/lang/String;Ljava/lang/String;Ljava/lang/String;Z)Lcom/xxx/APIResponse; (UpDownController.java:192) at com.xxx.UpDownController$$FastClassBySpringCGLIB$$8f2b3db8.invoke(ILjava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (Unknown Source) at org.springframework.cglib.proxy.MethodProxy.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint()Ljava/lang/Object; (CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed()Ljava/lang/Object; (ReflectiveMethodInvocation.java:157) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed()Ljava/lang/Object; (MethodInvocationProceedingJoinPoint.java:85) 分析结果表示，有一个线程里的本地变量占了总内存的94.91%，将近1.5g大小 根据线程栈看出来，是ArrayList扩容的时候占的内存相当多，这个ArrayList的数据占了1.5个G，调用位置在ExportUtil.java:53,这是一个导出excel的工具类，在这里创建单元格，并设置值。 问题根源问题根源在这里就查到了，同时根据access log能查出来，这是用户的一个导出数据操作，数据量上百万，于是就出问题了 问题根源有两点： 大量数据的情况下没有增加数量限制 堆内存设置的比较小,从配置信息可以看出来,heap只配了2g,但我们的机器内存有8G]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>load</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈QMQ的实现]]></title>
    <url>%2F2019%2F02%2F17%2F%E8%B0%88%E8%B0%88QMQ%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概述前段时间公司开源了内部的QMQ消息中间件,这里简单根据开源文档来看一下QMQ的实现原理,同时与kafka做一个对比. QMQ github地址 余昭辉大佬的文章 :去哪儿网消息队列设计与实现 消息中间件的设计一个消息中间件的设计需要考虑哪些问题呢? 高可用(服务与数据投递) 消息的存储模型 不同消费组消费隔离 上面是实现一个消息中间件需要考虑的基础问题,同时可以考虑的是一些其他功能: 事务:解决分布式事务数据一致性的问题 幂等Exactly once消费 监控 trace QMQ的实现服务架构 delay server 向meta server注册 实时server 向meta server注册 producer在发送消息前需要询问meta server获取server list meta server返回server list给producer(根据producer请求的消息类型返回不同的server list) producer发送延时/定时消息 延时时间已到，delay server将消息投递给实时server producer发送实时消息 consumer需要拉取消息，在拉取之前向meta server获取server list(只会获取实时server的list) meta server返回server list给consumer consumer向实时server发起pull请求 实时server将消息返回给consumer 实时消息的存储存储模型QMQ实时消息的存储,结合了Kafka和RocketMQ的实现方式,引入了三种log: message log 所有subject的消息进入该log，消息的主存储 consume log 每个主题(topic)对应一个consume log,存储的是当前主题在message log的索引信息 pull log 每个consumer都有一个pull log,在consumer拉取消息的时候会产生log，pull log记录的是拉取的消息在consume log中的sequence 存储模型如下: 设计初衷这里讨论的就是,为什么要使用这三种log的存储模型呢?原因如下 顺序append文件，提供很好的性能 顺序消费文件，使用offset表示消费进度，成本极低 将所有subject的消息合并在一起，减少parition数量，可以提供更多的subjec QMQ Server与Consumer解耦 最后一点,之所以说将Server与Consumer解耦,是源于kafka的存储结构和消费方式. kafka的存储结构和消费方式,使得kafka存储消息的分区与消费者数量相关联:对于同一个topic,每个partition只能被一个Consumer Group下的一个Consumer消费 不同数量的partition和consumer可能会形成以下三种对应关系: 这样的关联性就导致了一个问题:当消息量突增消息产生堆积的情况下,无法通过增加partition和consumer的数量来来加快消费进度 所以对于我们的在线服务来说,存在这样一个问题是比较坑的.试问谁家的系统还没个几次突发流量啊? 因此我们可以发现,采用QMQ的三种log存储的方式,把消息中间件的存储方式与消费者解耦了,我们完全可用通过增加一个消费组下面消费者的数量,使消费者的消费能力得到线性的提升 延时消息的存储存储模型话不多说,看图: schedule log 是按小时把消息分片,不同时间段的消息存储到不同的文件中. 当消息的投递时间即将到来的时候，会将这个小时的消息索引(索引包括消息在schedule log中的offset和size)从磁盘文件加载到内存中的hash wheel上，内存中的hash wheel则是以500ms为一个刻度 消费隔离一个主题,可以有多个消费组来消费.可以这样理解消费组和消费者: 每个消费组代表了一应用 一个应用可以有一台或多台机器作为消费者来消费消息 每个消费组之间的消费进度是隔离的,消费组内所有消费者的消费进度应该是共享的 由于不同消费组之间的消费进度不同,以及消费能力不同,这样在时间消费隔离的时候就面临了两个问题: 消费进度的隔离以消费组为维度 消费组消费的公平性 对于Consumer端的拉请求而言，其实就是典型的request/reponse方式，那么对于request/response的处理方式一般如下图所示: 但是对于消息队列来讲有个很大的问题：比如有一个消息主题，有几个不同的消费组(consumer group)来消费，消费组里是包含多个消费者的。假设A消费组有100个消费者，而B消费组只有两个消费者，这样Server就会收到大量来自A消费组的拉请求，而来自B消费组的拉请求要少得多，最后很可能就是这种情况： 而qmq的实现方案是,为每个消费组分配一个actor，那么来自这个消费组的所有拉请求都会进入对应actor的信箱(队列)，然后这些actor再被调度。 这些actor在一个线程池里被调度，当有拉请求进入对应actor的信箱时，该actor的状态变为runnable，进入线程池的队列等待被执行，当执行到该actor时，该actor的信箱里可能存在多个拉请求，那么我们并不是将该拉请求全部执行完毕，而是给每个actor分配了一个最大执行时间(时间片)，如果该时间片耗完，即使它的信箱里仍然有拉请求还是会不再执行该actor，这个时候会将该actor放到线程池队列的末尾。那么就能够确保每个actor都有执行的机会，并且请求多的actor也不会挤占其他actor的资源。 高可用分别从两个角度提供高可用能力：分片和复制 分片首先因为QMQ不是基于partition的，所以很容易通过添加更多的机器就能提高一个subject的可用性，消息按照一定的负载均衡策略分布在不同的机器上，某台机器离线后producer将不再将消息发送给该Server。 复制除此之外，QMQ通过主从复制来提高单机可用性。QMQ将服务端集群划分为多个group，每个group包含一个master和一个slave。消息的发送和消费全部指向master，slave只为保证可用性。 目前当master离线后，不提供自动切换功能，需要人工启动master。当slave离线后，该group不再提供接收消息服务，只提供消息消费服务。当master出现故障，导致消息丢失时，可以将其切换为slave，原来的slave切换为master，slave将从master同步数据，同步完成后提供服务。 provider发送消息当provider消息发送给master后，slave会从master同步消息，只有消息同步到slave后master才会返回成功的响应给producer，这就保证了master和slave上都有一致的消息。当master和slave之间的延迟增大时，会标记该group为readonly状态，这个时候将不再接收消息，只提供消息消费服务。下图为消息发送和主从同步示意图: consumer消费消息 ack机制(消费完返回ack,ack可包含异常信息) 重试机制(消费异常,默认每隔5s重试一次) 幂等Exactly once消费 服务降级因为每个消费组都是隔离的,所以每个消费组的pull请求都在各自的队列里，那么如果前面处理慢了，就会拖慢整个队列，最后导致整个队列都是做无用功，整个系统的大量资源都被消耗了,因此就要考虑服务降级了. 服务端降级QMQ在收到每个请求，根据请求的超时参数，都赋予了一个deadline，在该请求在actor里被执行的时候，会首先对deadline进行判断，如果觉得这个请求在deadline之前根本是无法执行完成的，那么我们就直接丢弃这个请求。那么这样就有两个作用： 防止队列恶化，减少无用功 拖慢消费者 因为请求被直接丢弃了，被丢弃的请求server端没有任何返回，那么consumer端就一直等到这个请求超时，这个时候相当于将consumer端发送拉请求的频率拖慢了，server的压力也进一步得到减轻 客户端降级当一台Server被熔断后一段时间内拉请求(也包括发送消息的)不再发给这台Server，这样客户端也不会挂起在资源不足的server上，而server也进一步得到喘息的机会，当一段时间后客户端会用少量的请求对server进行探测，一旦server完全恢复则请求会再次在多台server之间均分。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>QMQ</tag>
        <tag>kafka</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 常用命令]]></title>
    <url>%2F2018%2F12%2F10%2FJVM%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常见命令 jps JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程 jstat JVM statistics Monitoring 是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据 jmap JVM Memory Map 命令用于查看内存使用情况,生成heap dump文件 jhat JVM Heap Analysis Tool 命令是与jmap搭配使用，用来分析jmap生成的dump jstack 用于生成java虚拟机当前时刻的线程快照 jstat 用法1jstat [option] LVMID [interval] [count] [option] : 操作参数 LVMID : 本地虚拟机进程ID [interval] : 连续输出的时间间隔 [count] : 连续输出的次数 查看选项12345678910111213➜ ~ jstat -options-class-compiler-gc-gccapacity-gccause-gcmetacapacity-gcnew-gcnewcapacity-gcold-gcoldcapacity-gcutil-printcompilation 查看gc状况对于进程1262, 每隔2000ms输出gc情况，一共输出20次 jstat -gc 1262 2000 20 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 26112.0 24064.0 6562.5 0.0 564224.0 76274.5 434176.0 388518.3 524288.0 42724.7 320 6.417 1 0.398 6.815 输出参数的含义: 单位KB 所有后缀带C的,代表Capacity 总容量 所有后缀带U的,代表Used 已使用的容量 s0,s1和eden是新生代的区域,O是old老年带,P是perm永久带(方法区) YGC和FGC是gc次数,后面带T的是时间 jmap用法类似jstat,输入不同的option jmap [option] LVMID dump堆快照dump 进程28920的对快照到文件dump.hprof,只dump存活的对象 jmap -dump:live,format=b,file=dump.hprof 28920 Dumping heap to /home/xxx/dump.hprof ... Heap dump file created 不指定live的话,默认是全部对象. 查看heap情况打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况,可以用此来判断内存目前的使用情况以及垃圾回收情况 查看进程28920的heap情况: $ jmap -heap 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 using thread-local object allocation. Parallel GC with 4 thread(s)//GC 方式 Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage://堆内存使用情况 PS Young Generation Eden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used To Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used PS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% used PS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used 670 interned Strings occupying 43720 bytes. jstack用法jstack [option] LVMID option参数 -F : 当正常输出请求不被响应时，强制输出线程堆栈 -l : 除堆栈外，显示关于锁的附加信息 -m : 如果调用到本地方法的话，可以显示C/C++的堆栈 查看线程快照查看进程11494的当前线程快照,并且显示关于锁的附加信息 jstack -l 11494|more 2016-07-28 13:40:04 Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.71-b01 mixed mode): &quot;Attach Listener&quot; daemon prio=10 tid=0x00007febb0002000 nid=0x6b6f waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None &quot;http-bio-8005-exec-2&quot; daemon prio=10 tid=0x00007feb94028000 nid=0x7b8c waiting on condition [0x00007fea8f56e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000cae09b80&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None ..... jvm调优-命令大全（jps jstat jmap jhat jstack jinfo）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux性能瓶颈分析]]></title>
    <url>%2F2018%2F09%2F30%2Flinux%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[常见的几种问题： swap高 load高 cpu使用率 磁盘报警 几种case可能独立出现，也可能有因果关系的导致先后、同时出现。 说一下一般的排查、处理思路 CPU使用率高这个查起来很方便，直接使用top命令，查看CPU使用最高的进程，查找该进程中CPU占用最高的线程，再进行具体排查。 对于web应用来说，CPU使用率变高，很大可能是因为程序的问题CPU过高一般是有如下原因造成的： java代码中存在死循环导致CPU过高 系统存在不恰当的代码， 尽管没有死循环， 但仍然CPU过高。 JNI中有死循环代码， 堆内存设置太小造成的频繁GC. (堆内存设置过小， 或者存在内存泄漏) 32位JDK下， 堆内存设置太大造成的频繁GC. JDK自身存在死循环的Bug. CPU过高问题定位的第一步就是要找到CPU高消耗的线程。这个过程可以写成脚本，自动找出web服务中CPU消耗最高的N个线程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#!/bin/sh#changed MIao PROG=`basename $0` JAVA_HOME=你的java路径WEB_HOME=你的web项目所在路径 jstack="$JAVA_HOME/bin/jstack" usage() &#123; cat &lt;&lt;EOFUsage: $&#123;PROG&#125; &lt;pid|webapp&gt; [&lt;count&gt;] Find out the highest cpu consumed threads of java, and print the stack of these threads.Example: $&#123;PROG&#125; twell 50EOF exit $1&#125; redEcho() &#123; if [ -c /dev/stdout ] ; then # if stdout is console, turn on color output. echo -e "\033[1;31m$@\033[0m" else echo "$@" fi&#125; printStackOfThreads() &#123; while read threadLine ; do threadId=`echo $&#123;threadLine&#125; | awk '&#123;print $1&#125;'` threadId0x=`printf %x $&#123;threadId&#125;` pcpu=`echo $&#123;threadLine&#125; | awk '&#123;print $2&#125;'` jstackFile=/tmp/$&#123;uuid&#125;_$&#123;javaid&#125; [ ! -f "$&#123;jstackFile&#125;" ] &amp;&amp; &#123; sudo -u tomcat $jstack $&#123;javaid&#125; &gt; $&#123;jstackFile&#125; || &#123; redEcho "Fail to jstack java process $&#123;javaid&#125;" rm $&#123;jstackFile&#125; continue &#125; &#125; redEcho "The stack of busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/0x$&#123;threadId0x&#125;) of java pid($&#123;javaid&#125;) all times($3):" sed "/nid=0x$&#123;threadId0x&#125;/,/^$/p" -n $&#123;jstackFile&#125; done &#125; if echo $1 | grep -q "$WEB_HOME"then export CATALINA_BASE=$1else export CATALINA_BASE=$WEB_HOME/$1fi if [ -e $CATALINA_BASE/conf/server.xml ]then javaid=`ps aux |grep "java"|grep "Dcatalina.base=$CATALINA_BASE "|grep -v "grep"|awk '&#123; print $2&#125;'`else javaid=`ps -eo pid | grep "^$1$"`fi if [ -z "$javaid" ] ; then redEcho "process ($1) not found !" usage 1;fi if [ -z "$2" ] ; then count=1000else (( count = $2 +7 ))fi uuid=`date +%s`_$&#123;RANDOM&#125;_$$ top -p $javaid -H -n 1 -b | sed -n "8,$&#123;count&#125;p" | awk '&#123;print $1,$9,$11&#125;' | printStackOfThreads rm /tmp/$&#123;uuid&#125;_* 替换上面脚本中的java环境变量以及web项目路径:12JAVA_HOME=你的java路径WEB_HOME=你的web项目所在路径 假设你的tomcat进程是用tomcat账户启动的,用法如下：12sudo chmod 755 ./slow_stack.shsudo -utomcat ./slow_stack.sh 进程pid 使用率最高的count个线程 load高load高与cpu和io的相关性很大。 load值的算法load 的1分钟、5分钟、14分钟的average值，代表了这几分钟内，运行中+可运行等待调度的进程数量的平均值，也就是CPU使用队列的长度的统计信息 与CPU使用率的区别 CPU使用率是程序在运行期间实时占用的CPU百分比。进程是非CPU密集型、以及CPU上下文切换等情况下，CPU使用率是不高的。因此可见，CPU使用率与CPU负载load并没有必然联系。 但往往CPU使用率的提升是导致load增高的一个主要原因 CPU对load的影响理论上来说，单核CPU的load如果到了1，就说明cpu的负载能力被充分使用了，大于1的时候，就有进程在等待CPU了。所以N核的CPU，load满载的时候是1×N。可以参考理解Linux系统负荷 由此可以看出，当出现上面的CPU消耗过高的情况，就可能导致等待、堆积的进程变多，导致load增高。 IO对load的影响根据上面对load和cpu的分析可以看出，若是有过多的IO等待，也会造成CPU使用队列堆积，load增高的现象。 磁盘读写请求过多就会导致大量I/O等待。 cpu的工作效率要高于磁盘，而进程在cpu上面运行需要访问磁盘文件，这个时候cpu会向内核发起调用文件的请求，让内核去磁盘取文件，这个时候会切换到其他进程或者空闲，这个任务就会转换为不可中断睡眠状态。当这种读写请求过多就会导致不可中断睡眠状态的进程过多，从而导致负载高，cpu低的情况。 排查问题的时候可以重点排查IO状况是否正常、不可中断睡眠状态的线程是否过多。 Linux中CPU使用率低负载高 绑核特定情况下，会发现cpu使用率低，idle比较高、io没有异常，但是load一直很高的情况。这种情况可能是出现了绑核。 当你使用top命令时，cpu的使用状况、idle值是平均值，如果展开看每个cpu的使用的状况，也许会发现很多进程都绑到了同一个核上，其他内核一直空闲，而这一个内核因为任务堆积导致load增高 Load高，CPU idle很高，这情况太诡异了 load异常变高的的场景，排查问题的方向始终来源于load值本身的算法，load增高必然是因为任务过多导致cpu队列堆积，以此为思路就可以展开排查，从cpu使用率、io、绑核等常见原因入手。 swap增高swap高的原因，直接原因就是内存不够用，导致内存中的数据换出到磁盘上，而这样同时会导致写磁盘的IO增高 swap增高通常的原因可以检查一下进程是否有内存泄露。 可以看:Swap使用情况 内存问题排查思路 磁盘报警磁盘报警目前常见的基本两类：磁盘被写满、inode用尽 磁盘写满问题很直接，直接查找一下系统中持续增长的大文件，删减就ok。删除方法：线上大日志文件的删除。不过这背后的原因需要深究。 一般来说，web服务器出现这样的情况，是因为日志文件过大导致的，所以需要思考一下日志输出是否合理、日志文件的压缩时机是否合适。 inode用尽inode用尽通常是因为小文件过多导致将有限的inode资源用尽，所以可能磁盘使用率并不高 使用df -ih查看使用情况:12345678[sage.wang@machine /path]$ df -ihFilesystem Inodes IUsed IFree IUse% Mounted on/dev/vda2 640K 41K 600K 7% /tmpfs 1000K 4 1000K 1% /dev/shm/dev/vda1 50K 39 50K 1% /boot/dev/vda6 63K 1.4K 62K 3% /home/dev/vda7 3.9M 3.8M 20k 99% /home/xxx/dev/vda5 256K 1.6K 255K 1% /var 可以看到/home/xxx下面的inode使用了99%,接下来就是看一下具体哪个目录里使用的最多了，按照上面的目录一层一层的找下，查找的方法用下面的脚本：123456789[sage.wang@machine /home/xxx/www/webserver]$ for i in ./*; do echo $i; find $i | wc -l; done./conf9./logs2365048904./webapps2349./work9 这里就能看出来，比较多的文件其实是log文件和webapps下面的类文件 PS：上面的文件个数是我随便写的 关键用法：for i in ./*; do echo $i; find $i | wc -l; done 查找当前目录下的目录有多少个文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>swap</tag>
        <tag>load</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot启动过程]]></title>
    <url>%2F2018%2F09%2F13%2FSpring%20Boot%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Spring Boot启动Spring Boot项目若从main方法启动，走的是SpringApplication的run方法来启动spring容器，从main的入口开始，一步一步往下看： 1234567@SpringBootApplicationpublic class Application extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 接下来就是SpringApplication的run方法了，进入了Spring的流程： 12345678public static ConfigurableApplicationContext run(Object source, String... args) &#123; return run(new Object[] &#123; source &#125;, args);&#125;public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; return new SpringApplication(sources).run(args);&#125; 到这一步可以看到，整个启动流程分为两个步骤：初始化一个SpringApplication对象、执行该对象的run方法。 SpringApplication对象初始化首先看SpringApplication创建的时候是怎么初始化的： 123456789101112131415161718192021222324public SpringApplication(Object... sources) &#123; initialize(sources);&#125;private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断是否是web项目 this.webEnvironment = deduceWebEnvironment(); //从spring.factories中获取配置的所有ApplicationContextInitializer初始化器 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从spring.factories中获取配置的所有ApplicationListenerj监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 这里的信息量还是不少的： getSpringFactoriesInstancesgetSpringFactoriesInstances方法，其作用是找到spring.factories中配置的接口的实现类，这里是用来获取ApplicationContextInitializer和ApplicationListener的实现类 实现方式是利用SpringFactoriesLoader查找META-INF/spring.factories下的配置，按properties取值： 123456789101112131415161718192021222324252627282930313233343536373839private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125;/** * The location to look for factories. * &lt;p&gt;Can be present in multiple JAR files. */public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories";public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException("Unable to load [" + factoryClass.getName() + "] factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex); &#125;&#125; ApplicationContextInitializerApplicationContextInitializer的作用， 是在应用的上下文ConfigurableApplicationContext做refresh之前，对ConfigurableApplicationContext实例做进一步的设置或处理。而ConfigurableApplicationContext接口继承了ApplicationContext接口。 ApplicationListenerApplicationListener就是spring中定义的监听器，用来监听后面SpringApplicationRunListener发布的消息，可以在应用启动中监听应用的不同阶段，做不同的操作。 SpringApplication启动看完了初始化，看一下SpringApplication是怎么run起来的吧： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //加载SpringApplicationRunListener，并发布事件：应用开始启动了 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.started(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //创建、配置Environment ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //打印spring boot的logo，可定制 Banner printedBanner = printBanner(environment); //根据是否是web项目，来创建不同的ApplicationContext容器。 context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //初始化ApplicationContext prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新context refreshContext(context); //查找、执行注册的CommandLineRunner和ApplicationRunner afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 说一说几个关键的阶段 SpringApplicationRunListener同样是利用SpringFactoriesLoader从spring.factories中查找SpringApplicationRunListener的实现类，只有一个EventPublishingRunListener，本质是一个事件发布者。 事件发布在应用的不同阶段，发布不同的事件，通知感兴趣的监听器在初始化的过程中做不同的操作。 发布事件的阶段分别在应用开始启动、Environment创建好后、ApplicationContext创建好后、ApplicationContext加载完成且refresh调用前、run方法结束调用前， 事件监听SpringApplication初始化时加载的ApplicationListener监听各个阶段相关的事件 EnvironmentEnvironment主要抽象了配置文件(profile)和属性(properties)，当Environment准备好后，在整个应用的任何时候，都可以从Environment中获取资源 ApplicationContext初始化ApplicationContext初始化ApplicationContext时的主要工作： 设置准备好的Environment 执行所有ApplicationContextInitializer的initialize方法 发布contextPrepared事件通知监听者 将所有的bean加载到容器中 发布contextLoaded事件通知监听者 刷新ApplicationContextrefreshContext方法一路点进去，就会发现最终调的还是AbstractApplicationContext的refresh方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 相信看过spring源码的，对spring初始化了解的都对这段代码很熟…]]></content>
      <categories>
        <category>Web框架</category>
      </categories>
      <tags>
        <tag>Web框架</tag>
        <tag>Spring</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Collectors.toMap的坑]]></title>
    <url>%2F2018%2F09%2F13%2FJava8%20Collectors.toMap%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[按照常规思维，往一个map里put一个已经存在的key，会把原有的key对应的value值覆盖，然而通过一次线上问题，发现Java8中的Collectors.toMap反其道而行之，它默认给抛异常，抛异常… 线上业务代码出现Duplicate Key的异常，影响了业务逻辑，查看抛出异常部分的代码，类似以下写法： 1Map&lt;Integer, String&gt; map = list.stream().collect(Collectors.toMap(Person::getId, Person::getName)); 然后list里面有id相同的对象，结果转map的时候居然直接抛异常了。。查源码发现toMap方法默认使用了个throwingMerger 1234567891011 public static &lt;T, K, U&gt;Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper) &#123; return toMap(keyMapper, valueMapper, throwingMerger(), HashMap::new);&#125; private static &lt;T&gt; BinaryOperator&lt;T&gt; throwingMerger() &#123; return (u,v) -&gt; &#123; throw new IllegalStateException(String.format("Duplicate key %s", u)); &#125;;&#125; 那么这个throwingMerger是哪里用的呢？ 1234567891011public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper, BinaryOperator&lt;U&gt; mergeFunction, Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer&lt;M, T&gt; accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; 这里传进去的是HashMap，所以最终走的是HashMap的merge方法。merge方法里面有这么一段代码：123456789101112131415if (old != null) &#123; V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); return v;&#125; 相信只看变量名就能知道这段代码啥意思了。。如果要put的key已存在，那么就调用传进来的方法。而throwingMerger的做法就是抛了个异常。所以到这里就可以知道写的代码为什么呲了。。 如果不想抛异常的话，自己传进去一个方法即可，上述代码可以改成： Map&lt;Integer, String&gt; map = list.stream().collect(Collectors.toMap(Person::getId, Person::getName,(oldValue, newValue) -&gt; newValue)); 这样就做到了使用新的value替换原有value。 写代码调方法时，多看源码实现，注意踩坑！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BigDecimal精度与相等比较的坑]]></title>
    <url>%2F2018%2F09%2F13%2FBigDecimal%E7%B2%BE%E5%BA%A6%E4%B8%8E%E7%9B%B8%E7%AD%89%E6%AF%94%E8%BE%83%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[先想一下，创建BigDecimal对象的时候一般是怎么创建的？ new一个，传进去值 BigDecimal.valueOf方法，传进去值 作为一个数字类型，经常有的操作是比较大小，有一种情况是比较是否相等。用equal方法还是compareTo方法？这里就是一个大坑 //new 传进去一个double BigDecimal newZero = new BigDecimal(0.0); System.out.println(BigDecimal.ZERO.equals(newZero)); //new 传进去一个字符串 BigDecimal stringNewZero = new BigDecimal(&quot;0.0&quot;); System.out.println(BigDecimal.ZERO.equals(stringNewZero)); //valueOf 传进去一个double BigDecimal noScaleZero = BigDecimal.valueOf(0.0); System.out.println(BigDecimal.ZERO.equals(noScaleZero)); //valueOf 传进去一个double，再手动设置精度为1 BigDecimal scaleZero = BigDecimal.valueOf(0.0).setScale(1); System.out.println(BigDecimal.ZERO.equals(scaleZero)); 用于比较的值全都是0，猜一猜上面几个equals方法返回的结果是什么？全都是true？no no no… true false false false 惊不惊喜，意不意外？原因是什么呢？看一下BigDecimal的equals方法的实现： public boolean equals(Object x) { //类型不同，直接返回false if (!(x instanceof BigDecimal)) return false; BigDecimal xDec = (BigDecimal) x; //同一个对象，直接返回true if (x == this) return true; //精度不同，直接返回false！！ if (scale != xDec.scale) return false; long s = this.intCompact; long xs = xDec.intCompact; if (s != INFLATED) { if (xs == INFLATED) xs = compactValFor(xDec.intVal); return xs == s; } else if (xs != INFLATED) return xs == compactValFor(this.intVal); return this.inflated().equals(xDec.inflated()); } 从前面三个简单的判断就可以看出来，debug跟一下就知道是上面equals方法有三个返回false，都是因为精度不同。那么BigDecimal.ZERO的精度是多少呢？看下源码： // Cache of common small BigDecimal values. private static final BigDecimal zeroThroughTen[] = { new BigDecimal(BigInteger.ZERO, 0, 0, 1), new BigDecimal(BigInteger.ONE, 1, 0, 1), new BigDecimal(BigInteger.valueOf(2), 2, 0, 1), new BigDecimal(BigInteger.valueOf(3), 3, 0, 1), new BigDecimal(BigInteger.valueOf(4), 4, 0, 1), new BigDecimal(BigInteger.valueOf(5), 5, 0, 1), new BigDecimal(BigInteger.valueOf(6), 6, 0, 1), new BigDecimal(BigInteger.valueOf(7), 7, 0, 1), new BigDecimal(BigInteger.valueOf(8), 8, 0, 1), new BigDecimal(BigInteger.valueOf(9), 9, 0, 1), new BigDecimal(BigInteger.TEN, 10, 0, 2), }; /** * The value 0, with a scale of 0. * * @since 1.5 */ public static final BigDecimal ZERO = zeroThroughTen[0]; BigDecimal.ZERO值为0，精度为0. 而上面几种返回false的case，都是因为精度不同。精度不同的原因，则是BigDecimal对象初始化的方式不同,从源码上看，前三种初始化的方式都不同。 所以说，BigDecimal比较大小，还是用compareTo方法比较靠谱，改为compareTo之后，上面四个case返回的结果都是相等： BigDecimal newZero = new BigDecimal(0.0); System.out.println(BigDecimal.ZERO.compareTo(newZero)); BigDecimal stringNewZero = new BigDecimal(&quot;0.0&quot;); System.out.println(BigDecimal.ZERO.compareTo(stringNewZero)); BigDecimal noScaleZero = BigDecimal.valueOf(0.0); System.out.println(BigDecimal.ZERO.compareTo(noScaleZero)); BigDecimal scaleZero = BigDecimal.valueOf(0.0).setScale(1); System.out.println(BigDecimal.ZERO.compareTo(scaleZero)); 输出结果 0 0 0 0 由此联想到的一个更大的坑是，如果将BigDecimal的值作为HashMap的key，因为精度的问题，相同的值就可能出现hashCode值不同并且equals方法返回false，导致put和get就很可能会出现相同的值但是存取了不同的value。 再想一想，小数类型在计算机中本来就不能精确存储，再把其作为HashMap的key就相当不靠谱了，以后还是少用。 另外需要注意的一点是，写代码调别人写的方法时，最好是点进去看一下实现。再小再常用的方法，都可能埋着大坑]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>BigDecimal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Innodb的锁与MVCC]]></title>
    <url>%2F2018%2F08%2F20%2FInnodb%E7%9A%84%E9%94%81%E4%B8%8EMVCC%2F</url>
    <content type="text"><![CDATA[事务的四个特性，ACID。来聊一聊一致性。 并发与一致性的关系并发的任务对同一个临界资源进行操作，如果不采取措施，可能导致不一致，故必须进行并发控制 常用手段通过并发控制保证数据一致性的常见手段有： 锁（Locking） 数据多版本（Multi Versioning） 锁锁的演化思路 串行的排它锁，并发性能不高 锁的读写分离，X锁和S锁，即排它锁和共享锁，提高并发性能。但这里读还是会受到写锁的影响，并没有真正的将读和写分离，而是实现的读和读的并发。 共享锁与排他锁的玩法 共享锁之间不互斥，所以可认为读读可以并行 排他锁与任何锁互斥，所以可认为写读，写写不可以并行 可以看到，一旦写数据的任务没有完成，数据是不能被其他任务读取的，这对并发度有较大的影响。对应到数据库，可以理解为，写事务没有提交，读相关数据的select也会被阻塞。 此时，提高性能的关键就是，如何让读和写可以并行，以此来提高并发性能。 多版本并发控制可以想到的一个操作是，当一个事务进行写操作的时候，把要操作的数据存一份，作为一个版本，其他事务进行读操作的时候，读取的数据是原有数据的版本，这样读操作并没有没已存在的写操作阻塞住，从而提高了并发度。 这样带来的一个结果就是，一个读事务，读到的要么是其他写事务提交之后的数据，要么是其他写事务未提交时修改前的数据。这样在提高并发性能的同时也避免了脏读。 那么多版本并发控制是怎么做呢？ 数据库事务未提交时，会将事务修改数据的镜像（即修改前的旧版本）存放到undo日志里，当事务回滚时，或者数据库奔溃时，可以利用undo日志，即旧版本数据，撤销未提交事务对数据库产生的影响。 undo日志存在回滚段里，多版本并发控制就是通过读取回滚段的旧版本数据来实现的。 回滚段里的数据，其实是历史数据的快照（snapshot），这些数据是不会被修改，select可以肆无忌惮的并发读取他们。 快照读（Snapshot Read），这种一致性不加锁的读（Consistent Nonlocking Read），就是InnoDB并发如此之高的核心原因之一。 这里的一致性是指，事务读取到的数据，要么是事务开始前就已经存在的数据（当然，是其他已提交事务产生的），要么是事务自身插入或者修改的数据。 总结 常见并发控制保证数据一致性的方法有锁，数据多版本； 普通锁串行，读写锁读读并行，数据多版本读写并行； redo日志保证已提交事务的ACID特性，设计思路是，通过顺序写替代随机写，提高并发； undo日志用来回滚未提交的事务，它存储在回滚段里； InnoDB是基于MVCC的存储引擎，它利用了存储在回滚段里的undo日志，即数据的旧版本，提高并发； InnoDB之所以并发高，快照读不加锁； InnoDB所有普通select都是快照读； 参考文章： https://mp.weixin.qq.com/s/R3yuitWpHHGWxsUcE0qIRQ]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上大日志文件的删除]]></title>
    <url>%2F2018%2F08%2F12%2F%E7%BA%BF%E4%B8%8A%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%9A%84%E5%88%A0%E9%99%A4%2F</url>
    <content type="text"><![CDATA[磁盘报警线上磁盘报警,查看磁盘使用率: [sage.wang@machine /home/www/web/logs]$ sudo df -h Filesystem Size Used Avail Use% Mounted on /dev/vda2 9.9G 1.5G 8.0G 16% / tmpfs 3.9G 12K 3.9G 1% /dev/shm /dev/vda1 194M 54M 131M 29% /boot /dev/vda6 985M 111M 824M 12% /home /dev/vda7 60G 45G 13G 78% /home/q /dev/vda5 4.0G 354M 3.4G 10% /var 登机器查看大文件： [sage.wang@machine /home/www/web]$ sudo du -sh * |grep G 39G logs [sage.wang@machine /home/www/web/logs]$ sudo du -sh * |grep G 7.4G access..2018-08-12.log 4.5G cache.log 1.2G catalina.out 8.5G qta.log 由于日志打印不当或者压缩策略设置不当，导致有比较大的日志文件 删除大文件 [sage.wang@machine /home/www/web/logs]$ sudo rm access..2018-08-12.log sudo rm access..2018-08-12.log 删除之后再查看磁盘使用率，其实还是没变： [sage.wang@machine /home/www/web]$ sudo df -h Filesystem Size Used Avail Use% Mounted on /dev/vda2 9.9G 1.5G 8.0G 16% / tmpfs 3.9G 12K 3.9G 1% /dev/shm /dev/vda1 194M 54M 131M 29% /boot /dev/vda6 985M 111M 824M 12% /home /dev/vda7 60G 45G 13G 79% /home/q /dev/vda5 4.0G 354M 3.4G 10% /var 原因跟Linux下文件的存储机制和存储结构有关： 一个文件在文件系统中的存放分为两个部分：数据部分和指针（inode）部分，指针位于文件系统的meta-data中，数据被删除后，这个指针就从meta-data中清除了，而数据部分存储在磁盘中，数据对应的指针从meta-data中清除后，文件数据部分占用的空间就可以被覆盖并写入新的内容，之所以出现删除access_log文件后，空间还没释放，就是因为tomcat进程还在一直向这个文件写入内容，导致虽然删除了access_log文件，但文件对应的指针部分由于进程锁定，并未从meta-data中清除，而由于指针并未被删除，那么系统内核就认为文件并未被删除，因此通过df命令查询空间并未释放也就不足为奇了。 如何确认这一点呢？可以通过lsof -p pid的方式来查看文件传输的状态： [sage.wang@machine /home/www/web]$ ps aux|grep java|grep Dcatalina tomcat 18784 97.9 28.3 7733348 2283632 ? Sl Aug10 3381:52 /home/q/java/default/bin/java -Djava.util.logging.config.file=/home/www/web/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms3537216k -Xmx3537216k -XX:NewSize=1074560k -XX:TargetSurvivorRatio=65 -XX:SurvivorRatio=4 -server -XX:+TieredCompilation -XX:CICompilerCount=3 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=60 -XX:+UseCMSInitiatingOccupancyOnly -XX:+CMSScavengeBeforeRemark -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:-UseBiasedLocking -XX:+PreserveFramePointer -XX:+DisableExplicitGC -XX:MaxMetaspaceSize=256m -XX:+TraceClassUnloading -XX:MaxTenuringThreshold=15 -XX:+PrintTenuringDistribution -verbose:gc -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintPromotionFailure -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -XX:+PrintClassHistogramBeforeFullGC -XX:+PrintClassHistogramAfterFullGC -XX:+PrintStringTableStatistics -XX:+PrintReferenceGC -XX:+PrintCommandLineFlags -XX:+PrintFlagsFinal -Xloggc:/home/www/web/logs/gc-201808101121.log -Dqunar.logs=/home/www/web/logs -Dqunar.cache=/home/www/web/cache -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Djava.endorsed.dirs=/home/q/tomcat/endorsed -classpath /home/q/tomcat/bin/bootstrap.jar:/home/q/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/home/www/web -Dcatalina.home=/home/q/tomcat -Djava.io.tmpdir=/home/www/web/temp org.apache.catalina.startup.Bootstrap start [sage.wang@machine /home/www/web]$ sudo lsof -p 18784|grep deleted java 18784 tomcat 8w REG 252,7 592867 1835029 /home/www/web/logs/catalina.2018-08-10.log (deleted) java 18784 tomcat 9w REG 252,7 773 1835037 /home/www/web/logs/localhost.2018-08-10.log (deleted) 当linux打开一个文件的时候,Linux内核会为每个进程在/proc/ 『/proc/nnnn/fd/文件夹（nnnn为pid）』建立一个以其pid为名的文件夹用来保存进程的相关信息，而其子文件夹fd保存的是该进程打开的全部文件的fd（fd：file descriptor）。 进去看一下内容： [sage.wang@machine /home/www/web]$ sudo ls -alh /proc/18784/fd/ |grep deleted l-wx------ 1 tomcat tomcat 64 Aug 12 20:54 8 -&gt; /home/www/web/logs/catalina.2018-08-10.log (deleted) l-wx------ 1 tomcat tomcat 64 Aug 12 20:54 9 -&gt; /home/www/web/logs/localhost.2018-08-10.log (deleted) 可以看到，这是被删除的文件，但实际上磁盘空间还是没有释放的 正确姿势那么到底应该用什么姿势来解决问题呢？两种方式： 重启应用，即可释放相应的空间 在线清空这个文件的内容 重启应用很简单，若要在线清空文件，则不要使用rm命令，而是使用如下命令 cat /dev/null &gt; file #或者 echo &gt; file #或者 echo &apos; &apos; &gt; file 再强调一遍，删除正在写的文件一般用 cat /dev/null &gt; file或者echo &gt; file，而不是直接rm（直接rm会造成文件删除空间不释放的问题）。 线上机器执行的时候会有权限的问题,比如： [n-sage.wang@machine /home/www/web/logs]$ sudo echo &gt; catalina.out bash: catalina.out: Permission denied 这是因为重定向符号 “&gt;” 也是 bash 的命令。sudo 只是让 echo 命令具有了 root 权限，但是没有让 “&gt;” 命令也具有root 权限，所以 bash 会认为这个命令没有写入信息的权限。 解决方案有两种 当做一条命令执行： sudo bash -c &apos;echo &quot;hello&quot; &gt; f.txt&apos; 或者使用tee命令： echo &quot;hello&quot; | sudo tee f.txt # add -a for append (&gt;&gt;) 实测第一条命令还是会有点问题，也是没权限。但是第二种方式是work的。 参考文章： http://www.ywnds.com/?p=5186 https://blog.csdn.net/wangyage198801151103/article/details/51723759 https://www.cnblogs.com/mfryf/p/3334451.html https://www.jb51.net/article/100462.htm https://blog.csdn.net/tianyao_myc/article/details/52179668 http://blog.163.com/aprilthirty60@126/blog/static/88613578201282703952163/ https://blog.csdn.net/hejinjing_tom_com/article/details/7767127 https://askubuntu.com/questions/103643/cannot-echo-hello-x-txt-even-with-sudo]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql从binlog恢复数据]]></title>
    <url>%2F2018%2F08%2F10%2FMysql%E4%BB%8Ebinlog%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[binlog信息查询查看binlog配置，是否开启，binlog位置： mysql&gt; show variables like &apos;%log_bin%&apos;; +---------------------------------+-------------------------------------------------+ | Variable_name | Value | +---------------------------------+-------------------------------------------------+ | log_bin | ON | | log_bin_basename | /home/q/mysql/multi/3306/binlog/mysql-bin | | log_bin_index | /home/q/mysql/multi/3306/binlog/mysql-bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+-------------------------------------------------+ 6 rows in set (0.00 sec) mysql&gt; show binary logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql-bin.000004 | 1659524 | | mysql-bin.000005 | 8161208 | +------------------+-----------+ 2 rows in set (0.00 sec) mysql&gt; show binlog events in &apos;mysql-bin.000004&apos;; +------------------+---------+-------------+-----------+-------------+--------------------------------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+---------+-------------+-----------+-------------+--------------------------------------------------------------+ | mysql-bin.000004 | 4 | Format_desc | 23625 | 120 | Server ver: 5.6.39-83.1-log, Binlog ver: 4 | | mysql-bin.000004 | 120 | Query | 23625 | 214 | BEGIN | | mysql-bin.000004 | 214 | Table_map | 23625 | 299 | table_id: 72 (qta_promotion_activity.activity_template) | | mysql-bin.000004 | 299 | Write_rows | 23625 | 43746 | table_id: 72 flags: STMT_END_F | | mysql-bin.000004 | 43746 | Xid | 23625 | 43773 | COMMIT /* xid=1 */ | | mysql-bin.000004 | 43773 | Query | 23625 | 43867 | BEGIN | | mysql-bin.000004 | 43867 | Table_map | 23625 | 43958 | table_id: 71 (qta_promotion_activity.activity_instance) | | mysql-bin.000004 | 43958 | Write_rows | 23625 | 44049 | table_id: 71 flags: STMT_END_F | | mysql-bin.000004 | 44049 | Xid | 23625 | 44076 | COMMIT /* xid=2 */ | 去相应的路径可以看到binlog的文件 [sage.wang@machine /home/q/mysql/multi/3306]$ sudo ls -alh binlog/ total 9.4M drwx------ 2 mysql mysql 4.0K Aug 10 15:13 . drwxr-xr-x 11 mysql mysql 4.0K Aug 10 15:13 .. -rw-rw---- 1 mysql mysql 1.6M Aug 10 15:12 mysql-bin.000004 -rw-rw---- 1 mysql mysql 7.8M Aug 10 20:12 mysql-bin.000005 -rw-rw---- 1 mysql mysql 98 Aug 10 15:13 mysql-bin.index mysql-bin.000004和mysql-bin.000005就是binlog的文件。 使用mysqlbinlog命令对binlog文件进行操作 查看文件内容 sudo /home/q/mysql/bin/mysqlbinlog --stop-datetime=&apos;2018-08-10 11:25:56&apos; /home/q/mysql/multi/3306/binlog/mysql-bin.000004 可以查看到类似如下的很多日志信息 BEGIN /*!*/; # at 1657217 #180810 10:48:20 server id 23625 end_log_pos 1657329 Table_map: `qta_promotion_coupon`.`coupon_00` mapped to number 129 # at 1657329 #180810 10:48:20 server id 23625 end_log_pos 1657890 Write_rows: table id 129 flags: STMT_END_F BINLOG &apos; 9PxsWxNJXAAAcAAAAPFJGQAAAIEAAAAAAAEAFHF0YV9wcm9tb3Rpb25fY291cG9uAAljb3Vwb25f MDAAGAgIDwgPCA8PDwH29gEI/Pz8DxEREREDAReAAIAAgAAAAgACCgIKAgICAgACAAAAAADAAQ== 9PxsWx5JXAAAMQIAACJMGQAAAIEAAAAAAAEAAgAY////AAAAJgAAAAAAAADgcxtWAAAAAAEwnAIA AAAAAAAUMjAxNjAxMTkxMjAwMjgwNDExNTOrTKbtNQAAAAwyMzE2MjAzNjU0ODMAAA8A5paw5a6i 5LqU5oqY5Yi4FYAAADwAgAAAPAABAAAAAAAAAAAxAHsicHJvcG9ydGlvblNlZ21lbnQiOiJ0cnVl IiwiZGlzY291bnRMZXZlbCI6IjUwIn0AADMBeyJzZWdtZW50TW9uZXlDb25kaXRpb25zIjpbeyJt b25leU9wZXJhdGlvbiI6IkdFIiwic2VnbWVudE1vbmV5QmFzZSI6eyJhbW91bnQiOjAuMDAsImN1 cnJlbmN5IjoiQ05ZIn0sInNlZ21lbnRNb25leUJvbnVzIjp7ImFtb3VudCI6NjAuMDAsImN1cnJl bmN5IjoiQ05ZIn19XSwiaG90ZWxMZXZlbCI6MCwib3BlcmF0aW9uQ29kZSI6MiwiY291cG9uQ29u ZGl0aW9uRGVzY0JvZHlMaXN0IjpbeyJ0aXRsZSI6IuS8mOaDoOivtOaYjiIsImRlc2MiOiLorqLl jZXkuK3miL/otLnmgLvpop3mu6Hvv6Uw5Y+v55So77yM6ZmQ55So5LiA5qyhIn1dfSEAY2F0YWx5 c2lzLWRpc2NfdGVzdC1ORkROXzEtTkZETl8xW2z89Ft28P9bbPz0W2z89AEAAAAA &apos;/*!*/; # at 1657890 #180810 10:48:20 server id 23625 end_log_pos 1657917 Xid = 175 COMMIT/*!*/; DELIMITER ; # End of log file ROLLBACK /* added by mysqlbinlog */; /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; server id是数据库主机的服务号 end_log_pos 是位置点 thread_id 是线程号 数据恢复要恢复数据的话，可以从位置点恢复，默认就会执行从开始到位置点的语句。也可以通过结束时间恢复。 基于时间点的恢复恢复2018-08-10 11:25:56时间点以前的数据 sudo /home/q/mysql/bin/mysqlbinlog --stop-datetime=&apos;2018-08-10 11:25:56&apos; /home/q/mysql/multi/3306/binlog/mysql-bin.000004 |mysql -h127.0.0.1 -uqta_noah_rw -p密码 基于位置点恢复恢复位置点1656329之前的数据 sudo /home/q/mysql/bin/mysqlbinlog --stop-position=&apos;1656329&apos; /home/q/mysql/multi/3306/binlog/mysql-bin.000004 |mysql -h127.0.0.1 -uqta_noah_rw -p密码 相应的，使用mysqlbinlog可以指定开始时间、开始位置点、结束时间、结束位置点的方式查询、导出、恢复数据。 详细参考文章： http://blog.51cto.com/lvnian/1699627 https://www.cnblogs.com/martinzhang/p/3454358.html https://blog.csdn.net/leshami/article/details/39801867 https://blog.csdn.net/yhjsspz/article/details/17360809]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>binlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux上传下载文件]]></title>
    <url>%2F2018%2F08%2F06%2Flinux%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[本地机器、跳板机和线上机器之间，文件互相传输，可以使用nc或者scp nc文件传输：123456#接受端监听nc -l -p 8210 &gt; demo.txt # 在本机8210端口侦听TCP连接，将收到的数据写入文本文件#发送端发送nc dest_ip 8210 &lt; demo.txt # 向ip为dest_ip的机器的8210端口发送demo.txt文件 但是这个方式从跳板机到本机传输文件是有问题的，屡次传输文件都是空的，加上-v参数查看详细信息：12[sage.wang@machine ~]$ nc -v 100.80.181.74 9912 &lt; SENSITIVITY_2018_08_full.txtnc: connect to 100.80.181.74 port 9912 (tcp) failed: No route to host 显示的是No route to host，但是使用host命令查看是能找到的。到网上查了一下，应该是被防火墙iptables限制了，跳板机上也没权限修改防火墙配置，只能使用scp来传输了。 https://blog.argcv.com/articles/2840.c https://unix.stackexchange.com/questions/353452/no-route-to-host-with-nc-but-can-ping http://man.linuxde.net/iptables 本机执行scp，从跳板机上copy文件到本地1➜ ~ scp sage.wang@machine:/home/q/home/sage.wang/source.txt ~/dest.txt 语法：scp 用户名@目的主机:源文件路径 本机目的文件路径 如果是目录的话，加上-r参数 http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/scp.html]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>scp</tag>
        <tag>nc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GET、POST编码问题]]></title>
    <url>%2F2018%2F06%2F25%2FGET%E3%80%81POST%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[GET请求、POST经常会出现中文乱码的问题，最好约定前后端的编码，一般为UTF-8。但是这里面也是有坑的。 后端设置编码为UTF-8的推荐方式： SpringMVC配置过滤器： &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 此配置可以将请求体的内容按照UTF-8编码解码。 Tomcat的server.xml配置： &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;200&quot; connectionTimeout=&quot;20000&quot; enableLookups=&quot;false&quot; compression=&quot;on&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot; compressableMimeType=&quot;text/html,text/xml,text/plain,text/javascript,application/json&quot; /&gt; URIEncoding可以配置url中的编码，防止get请求参数中文乱码。这里还可以加一个参数，useBodyEncodingForURI。useBodyEncodingForURI=true时，代表url中请求参数的编码方式要采用请求体的编码方式。 这两个都配上，基本上就可以保证从前端传来的utf-8编码的请求到后端不会乱码了。 这里的一个坑是，对于Tomcat来说，URIEncoding就是针对url中的请求参数的编码设置的，而代码中的request.setCharacterEncoding(‘UTF-8’)或者http报文请求头中的content-type中的编码都是针对请求体的。所以说如果只配了SpringMVC的过滤器却没有配置server.xml，就很可能会出现get请求中文乱码的问题。 配上SpringMVC的编码过滤器后，server.xml中的URIEncoding和useBodyEncodingForURI可以任选一种或者两个都配上，保证不会出现中文乱码。 事实上Tomcat8.0之后server.xml中的默认URIEncoding就是UTF-8。官方文档中建议使用第一种URIEncoding的方式。第二种配置方式主要为了兼容 Tomcat 4.1.x之前的版本。 题外话，可以看一下Spring的CharacterEncodingFilter实现： @Override protected void doFilterInternal( HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { if (this.encoding != null &amp;&amp; (this.forceEncoding || request.getCharacterEncoding() == null)) { request.setCharacterEncoding(this.encoding); if (this.forceEncoding) { response.setCharacterEncoding(this.encoding); } } filterChain.doFilter(request, response); } 可以看出，是通过setCharacterEncoding解决编码问题的，其作用与设置Content-Type等效。因此只能解决请求体的编码。 参考文章 https://blog.csdn.net/x_iya/article/details/78636733 http://www.cnblogs.com/panxuejun/p/6837677.html https://blog.csdn.net/hqfhello/article/details/51496955 https://www.cnblogs.com/yoyotl/p/5390876.html]]></content>
      <categories>
        <category>Java</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis插入数据后返回主键id]]></title>
    <url>%2F2018%2F06%2F25%2FMybatis%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E5%90%8E%E8%BF%94%E5%9B%9E%E4%B8%BB%E9%94%AEid%2F</url>
    <content type="text"><![CDATA[有时候使用mybatis插入数据后，需要用到记录在数据库中的自增id，可以利用keyProperty来返回，赋值给实体类中的指定字段。 单条记录插入并返回First, if your database supports auto-generated key fields (e.g. MySQL and SQL Server), then you can simply set useGeneratedKeys=”true” and set the keyProperty to the target property and you’re done. For example, if the Authortable above had used an auto-generated column type for the id, the statement would be modified as follows。 &lt;insert id=&quot;insertAuthor&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into Author (username,password,email,bio) values (#{username},#{password},#{email},#{bio}) &lt;/insert&gt; 添加useGeneratedKeys=&quot;true&quot; 以及keyProperty=&quot;id&quot;即可。id为实体类中的字段名称 多条记录插入并返回If your database also supports multi-row insert, you can pass a list or an array of Authors and retrieve the auto-generated keys. &lt;insert id=&quot;insertAuthor&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into Author (username, password, email, bio) values &lt;foreach item=&quot;item&quot; collection=&quot;list&quot; separator=&quot;,&quot;&gt; (#{item.username}, #{item.password}, #{item.email}, #{item.bio}) &lt;/foreach&gt; &lt;/insert&gt; 坑：要注意，多条记录时，有可能会出现id没有返回的情况。检查以下几点： 1、Mybatis版本3.3.1及其以上。 2、在Dao中不能使用@param注解。 3、Mapper.xml中使用list变量接受Dao中的集合。]]></content>
      <categories>
        <category>Java</category>
        <category>框架</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>框架</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据量下的集合过滤—Bloom Filter]]></title>
    <url>%2F2018%2F06%2F23%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E4%B8%8B%E7%9A%84%E9%9B%86%E5%90%88%E8%BF%87%E6%BB%A4%E2%80%94Bloom%20Filter%2F</url>
    <content type="text"><![CDATA[算法背景如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。 链表 、 树 、 散列表 （又叫哈希表，Hash table）等等数据结构都是这种思路，存储位置要么是磁盘，要么是内存。很多时候要么是以时间换空间，要么是以空间换时间。 在响应时间要求比较严格的情况下，如果我们存在内里，那么随着集合中元素的增加，我们需要的存储空间越来越大，以及检索的时间越来越长，导致内存开销太大、时间效率变低。 此时需要考虑解决的问题就是，在数据量比较大的情况下，既满足时间要求，又满足空间的要求。即我们需要一个时间和空间消耗都比较小的数据结构和算法。Bloom Filter就是一种解决方案。 Bloom Filter 概念布隆过滤器 （ 英语： Bloom Filter ）是1970年由布隆提出的。它实际上是一个很长的 二进制 向量和一系列随机 映射函数 。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 Bloom Filter 原理布隆过滤器的原理是，当一个元素被加入集合时，通过K个 散列函数 将这个元素映射成一个位 数组 中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。 Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。 Bloom Filter的缺点bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用 Counting Bloom Filter Bloom Filter 实现布隆过滤器有许多实现与优化，Guava中就提供了一种Bloom Filter的实现。 在使用bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp， 在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的大小。 对于一个确定的场景，我们预估要存的数据量为n，期望的误判率为fpp，然后需要计算我们需要的Bit数组的大小m，以及hash函数的个数k，并选择hash函数 (1)Bit数组大小选择根据预估数据量n以及误判率fpp，bit数组大小的m的计算方式： (2)哈希函数选择由预估数据量n以及bit数组长度m，可以得到一个hash函数的个数k： 哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数 。 哈希函数个数k、位数组大小m、加入的字符串数量n的关系可以参考 Bloom Filters - the math ， Bloom_filter-wikipedia 看看Guava中BloomFilter中对于m和k值计算的实现，在 com.google.common.hash.BloomFilter类中： /** * 计算 Bloom Filter的bit位数m * * &lt;p&gt;See http://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives for the * formula. * * @param n 预期数据量 * @param p 误判率 (must be 0 &lt; p &lt; 1) */ @VisibleForTesting static long optimalNumOfBits(long n, double p) { if (p == 0) { p = Double.MIN_VALUE; } return (long) (-n * Math.log(p) / (Math.log(2) * Math.log(2))); } /** * 计算最佳k值，即在Bloom过滤器中插入的每个元素的哈希数 * * &lt;p&gt;See http://en.wikipedia.org/wiki/File:Bloom_filter_fp_probability.svg for the formula. * * @param n 预期数据量 * @param m bloom filter中总的bit位数 (must be positive) */ @VisibleForTesting static int optimalNumOfHashFunctions(long n, long m) { // (m / n) * log(2), but avoid truncation due to division! return Math.max(1, (int) Math.round((double) m / n * Math.log(2))); } BloomFilter实现的另一个重点就是怎么利用hash函数把数据映射到bit数组中。Guava的实现是对元素通过 MurmurHash3计算hash值，将得到的hash值取高8个字节以及低8个字节进行计算，以得当前元素在bit数组中对应的多个位置。MurmurHash3算法详见: Murmur哈希 ， 于2008年被发明。这个算法hbase,redis,kafka都在使用。 这个过程的实现在两个地方： 将数据放入bloom filter中 判断数据是否已在bloom filter中 这两个地方的实现大同小异，区别只是，前者是put数据，后者是查数据。 这里看一下put的过程，hash策略以MURMUR128_MITZ_64为例： public &lt;T&gt; boolean put( T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, LockFreeBitArray bits) { long bitSize = bits.bitSize(); //利用MurmurHash3得到数据的hash值对应的字节数组 byte[] bytes = Hashing.murmur3_128().hashObject(object, funnel).getBytesInternal(); //取低8个字节、高8个字节，转成long类型 long hash1 = lowerEight(bytes); long hash2 = upperEight(bytes); boolean bitsChanged = false; //这里的combinedHash = hash1 + i * hash2 long combinedHash = hash1; //根据combinedHash，得到放入的元素在bit数组中的k个位置，将其置1 for (int i = 0; i &lt; numHashFunctions; i++) { bitsChanged |= bits.set((combinedHash &amp; Long.MAX_VALUE) % bitSize); combinedHash += hash2; } return bitsChanged; } 判断元素是否在bloom filter中的方法mightContain与上面的实现基本一致，不再赘述。 Bloom Filter的使用简单写个demo，用法很简单，类似HashMap package com.sage.wang.common.bloom.filter; import com.google.common.base.Charsets; import com.google.common.hash.BloomFilter; import com.google.common.hash.Funnel; import com.google.common.hash.Funnels; import com.google.common.hash.PrimitiveSink; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.ToString; /** * BloomFilterTest * * @author sage.wang * @date 18-5-14 下午5:02 */ public class BloomFilterTest { public static void main(String[] args) { long expectedInsertions = 10000000; double fpp = 0.00001; BloomFilter&lt;CharSequence&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), expectedInsertions, fpp); bloomFilter.put(&quot;aaa&quot;); bloomFilter.put(&quot;bbb&quot;); boolean containsString = bloomFilter.mightContain(&quot;aaa&quot;); System.out.println(containsString); BloomFilter&lt;Email&gt; emailBloomFilter = BloomFilter .create((Funnel&lt;Email&gt;) (from, into) -&gt; into.putString(from.getDomain(), Charsets.UTF_8), expectedInsertions, fpp); emailBloomFilter.put(new Email(&quot;sage.wang&quot;, &quot;quanr.com&quot;)); boolean containsEmail = emailBloomFilter.mightContain(new Email(&quot;sage.wangaaa&quot;, &quot;quanr.com&quot;)); System.out.println(containsEmail); } @Data @Builder @ToString @AllArgsConstructor public static class Email { private String userName; private String domain; } } Bloom Filter的应用常见的几个应用场景： cerberus在收集监控数据的时候, 有的系统的监控项量会很大, 需要检查一个监控项的名字是否已经被记录到db过了, 如果没有的话就需要写入db. 爬虫过滤已抓到的url就不再抓，可用bloom filter过滤 垃圾邮件过滤。 如果用哈希表，每存储一亿个 email地址，就需要 1.6GB的内存（用哈希表实现的具体办法是将每一个 email地址对应成一个八字节的信息指纹，然后将这些信息指纹存入哈希表，由于哈希表的存储效率一般只有 50%，因此一个 email地址需要占用十六个字节。一亿个地址大约要 1.6GB，即十六亿字节的内存）。因此存贮几十亿个邮件地址可能需要上百 GB的内存。而Bloom Filter只需要哈希表 1/8到 1/4 的大小就能解决同样的问题。 参考文章 guava 布隆过滤器 那些优雅的数据结构(1) : BloomFilter——大规模数据处理利器 哈希表存储效率50%的原因 https://blog.csdn.net/hfmbook/article/details/70209184]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>Bloom Filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 时间类型精度截取的bug]]></title>
    <url>%2F2018%2F06%2F23%2FMysql%20%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B%E7%B2%BE%E5%BA%A6%E6%88%AA%E5%8F%96%E7%9A%84bug%2F</url>
    <content type="text"><![CDATA[mysql-connector-java版本升级出现的一次问题。涉及到了时间精度的截取和四舍五入。 首先了解一点，timestamp,datetime如果不指定精度,默认的精度是秒。 当mysql-connector-java版本&lt;=5.1.22时,db的客户端会将Datetime,Timestamp秒以下的精度丢弃。版本&gt;5.1.22后，秒以下的值将不会截断 db的server端会对超出精度位数的数据进行四舍五入!! 举个例子：在db建表时没指定精度时，插入精确到毫秒级别的日期 如果使用mysql-connector-java版本&lt;=5.1.22，在客户端用’2018-04-02 23:59:59.999’插入日期，精度会在客户端被截取到秒，插入db里是’2018-04-02 23:59:59’ 如果升级版本，在db的客户端用’2018-04-02 23:59:59.999’插入日期，精度在客户端不会被截断，db的server端会对超出精度位数的数据进行四舍五入，即插入db里是’2018-04-03 00:00:00 ‘ 所以说mysql-connector-java版本升级就带了时间与原本不一致的问题，结合具体业务逻辑上的使用，可能会造成不同大小的影响。 要想证实这个观点，可以分两步： server端是否会四舍五入 客户端代码不同版本对精度是否有不同的处理方式 来实际测一下server会不会四舍五入： CREATE TABLE `time_test` ( `id` int(11) NOT NULL AUTO_INCREMENT , `create_time` timestamp NOT NULL DEFAULT &apos;1971-01-01 00:00:00&apos; , `end_time` timestamp NOT NULL DEFAULT &apos;1971-01-01 00:00:00&apos; , PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4; insert into time_test (create_time,end_time) values(&apos;2018-04-02 23:59:59&apos;,&apos;2018-04-02 23:59:59.999&apos;); select * from time_test; 看一下记录： +----+---------------------+---------------------+ | id | create_time | end_time | +----+---------------------+---------------------+ | 2 | 2018 - 04 - 02 23 : 59 : 59 | 2018 - 04 - 03 00 : 00 : 00 | +----+---------------------+---------------------+ 可以看出db的server端果然会进行四舍五入。 再看一下mysql驱动里是怎么写的，是否真的是截断精度了。 Mysql对于时间精度的处理在 com.mysql.jdbc.PreparedStatement#setTimestampInternal这个方法中 翻一下5.1.21的源码看一下： private void setTimestampInternal(int parameterIndex, Timestamp x, Calendar targetCalendar, TimeZone tz, boolean rollForward) throws SQLException { synchronized (checkClosed()) { if (x == null) { setNull(parameterIndex, java.sql.Types.TIMESTAMP); } else { checkClosed(); if (!this.useLegacyDatetimeCode) { newSetTimestampInternal(parameterIndex, x, targetCalendar); } else { String timestampString = null; Calendar sessionCalendar = this.connection.getUseJDBCCompliantTimezoneShift() ? this.connection.getUtcCalendar() : getCalendarInstanceForSessionOrNew(); synchronized (sessionCalendar) { x = TimeUtil.changeTimezone(this.connection, sessionCalendar, targetCalendar, x, tz, this.connection .getServerTimezoneTZ(), rollForward); } if (this.connection.getUseSSPSCompatibleTimezoneShift()) { doSSPSCompatibleTimezoneShift(parameterIndex, x, sessionCalendar); } else { synchronized (this) { if (this.tsdf == null) { //这里，截断秒以下的精度 this.tsdf = new SimpleDateFormat(&quot;&apos;&apos;yyyy-MM-dd HH:mm:ss&apos;&apos;&quot;, Locale.US); //$NON-NLS-1$ } timestampString = this.tsdf.format(x); //这里永远不会执行添加秒以下的精度 if (false) { // not so long as Bug#50774 is around StringBuffer buf = new StringBuffer(); buf.append(timestampString); int nanos = x.getNanos(); if (nanos != 0) { buf.append(&apos;.&apos;); buf.append(formatNanos(nanos)); } buf.append(&apos;\&apos;&apos;); } setInternal(parameterIndex, timestampString); // SimpleDateFormat is not // thread-safe } } } this.parameterTypes[parameterIndex - 1 + getParameterIndexOffset()] = Types.TIMESTAMP; } } } 再看下5.1.32的实现： private void setTimestampInternal(int parameterIndex, Timestamp x, Calendar targetCalendar, TimeZone tz, boolean rollForward) throws SQLException { synchronized (checkClosed().getConnectionMutex()) { if (x == null) { setNull(parameterIndex, java.sql.Types.TIMESTAMP); } else { checkClosed(); if (!this.useLegacyDatetimeCode) { newSetTimestampInternal(parameterIndex, x, targetCalendar); } else { Calendar sessionCalendar = this.connection.getUseJDBCCompliantTimezoneShift() ? this.connection.getUtcCalendar() : getCalendarInstanceForSessionOrNew(); synchronized (sessionCalendar) { x = TimeUtil.changeTimezone(this.connection, sessionCalendar, targetCalendar, x, tz, this.connection .getServerTimezoneTZ(), rollForward); } if (this.connection.getUseSSPSCompatibleTimezoneShift()) { doSSPSCompatibleTimezoneShift(parameterIndex, x, sessionCalendar); } else { synchronized (this) { //同样截断精度 if (this.tsdf == null) { this.tsdf = new SimpleDateFormat(&quot;&apos;&apos;yyyy-MM-dd HH:mm:ss&quot;, Locale.US); //$NON-NLS-1$ } StringBuffer buf = new StringBuffer(); buf.append(this.tsdf.format(x)); //这里，如果server支持fractional seconds的话，就加上毫秒的精度 if (this.serverSupportsFracSecs) { int nanos = x.getNanos(); if (nanos != 0) { buf.append(&apos;.&apos;); buf.append(TimeUtil.formatNanos(nanos, this.serverSupportsFracSecs, true)); } } buf.append(&apos;\&apos;&apos;); setInternal(parameterIndex, buf.toString()); // SimpleDateFormat is not // thread-safe } } } this.parameterTypes[parameterIndex - 1 + getParameterIndexOffset()] = Types.TIMESTAMP; } } } 看来果然是个bug…看一下mysql官网的描述： 参见bugFix第三条]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swap使用情况]]></title>
    <url>%2F2018%2F04%2F28%2FSwap%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[查看swap使用情况 静态使用情况free -m 查看内存、swap使用情况，单位为M，默认为K [sage.wang@machine /proc/19843]$ free -m total used free shared buffers cached Mem: 3830 3700 130 0 42 691 -/+ buffers/cache: 2965 865 Swap: 4095 86 4009 历史使用情况它能列出系统在各个时间的SWAP使用情况，使用sar命令。-S查看swap，-r查看内存使用情况 [sage.wang@machine ~]$ sar -S Linux 2.6.32-358.23.2.el6.x86_64 (machine) 08/03/2018 _x86_64_ (4 CPU) 12:00:01 AM kbswpfree kbswpused %swpused kbswpcad %swpcad 12:10:01 AM 4105976 88320 2.11 25788 29.20 12:20:01 AM 4105976 88320 2.11 25788 29.20 12:30:01 AM 4105976 88320 2.11 25788 29.20 12:40:01 AM 4105976 88320 2.11 25788 29.20 [sage.wang@machine ~]$ sar -r Linux 2.6.32-358.23.2.el6.x86_64 (machine) 08/03/2018 _x86_64_ (4 CPU) 12:00:01 AM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit 12:10:01 AM 608928 3313760 84.48 5256 322840 3185080 39.24 12:20:01 AM 588864 3333824 84.99 6616 342316 3185072 39.24 12:30:01 AM 571256 3351432 85.44 7928 359152 3185080 39.24 12:40:01 AM 551160 3371528 85.95 9296 375488 3185084 39.24 实时大小使用vmstat查看实时的数据，可以显示刷新频率，每隔1秒刷新一次： [sage.wang@machine ~]$ vmstat 1 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 88248 118900 39112 727652 0 0 4 7 0 0 1 0 99 0 0 0 0 88248 118892 39112 727684 0 0 0 0 333 406 1 0 99 0 0 0 0 88248 118916 39112 727716 0 0 0 0 337 442 1 0 99 0 0 0 0 88248 118900 39120 727740 0 0 0 12 458 448 2 0 98 0 0 关注几个值 Memory swpd: the amount of virtual memory used. 使用的虚拟内存大小 free: the amount of idle memory. buff: the amount of memory used as buffers. cache: the amount of memory used as cache. inact: the amount of inactive memory. (-a option) active: the amount of active memory. (-a option) Swap si: Amount of memory swapped in from disk (/s). 磁盘-&gt;内存 so: Amount of memory swapped to disk (/s). 内存-&gt;磁盘 如果它们一直是零当然最好不过了，偶尔不为零也没啥，糟糕的是一直不为零。 123456789101112131415161718192021222324#!/bin/bashcd /procfor pid in [0-9]*; do command=$(cat /proc/$pid/cmdline) swap=$( awk ' BEGIN &#123; total = 0 &#125; /Swap/ &#123; total += $2 &#125; END &#123; print total &#125; ' /proc/$pid/smaps ) if (( $swap &gt; 0 )); then if [[ "$&#123;head&#125;" != "yes" ]]; then echo -e "PID\tSWAP\tCOMMAND" head="yes" fi echo -e "$&#123;pid&#125;\t$&#123;swap&#125;\t$&#123;command&#125;" fidone sudo权限执行 https://huoding.com/2012/11/08/198 https://my.oschina.net/shyl/blog/477122 查看磁盘io https://my.oschina.net/shyl/blog/477122]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>swap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat NIO]]></title>
    <url>%2F2018%2F04%2F11%2FTomcat%20NIO%2F</url>
    <content type="text"><![CDATA[说起Tomcat的NIO，不得不提的就是Connector这个Tomcat组件。Connector是Tomcat的连接器，其主要任务是负责处理收到的请求，并创建一个Request和Response的对象，然后用一个线程用于处理请求，Connector会把Request和Response对象传递给该线程，该线程的具体的处理过程就是Container容器的事了。 在tomcat启动过程中，会初始化Connector，并调用Connector的startInternal()方法开启Connector,开始监听、处理请求。 想了解Tomcat NIO的工作方式，就得先了解一下Connector的实现原理。下面从三个方面来了解一下Connector组件：Connector的数据结构、Connector初始化以及Connector开启。 ConnectorConnector的数据结构先了解一下Connector的数据结构。Connector的一个主要的属性：ProtocolHandler protocolHandler（协议） protocolHandler（协议） 维护服务器使用的协议，如http1.1等。ProtocolHandler是接口，实现类有Http11Nio2Protocol 、Http11Nio2Protocol等 维护服务提供的IO方式，负责EndPoint的初始化、启动。目前有BIO、NIO、AIO等IO方式，来实现监听端口、读写socket数据的功能。通过EndPoint封装实现不同的IO方式 EndPoint监听到IO读写，交给Tomcat线程池中的一个线程来处理，SocketProcessor会根据protocolHandler采用的协议，调用协议的process方法处理请求。 维护adapter（适配器），可以将请求/响应数据进行适配 protocolHandler会找到socket对应的处理器(如Http11Processor)，然后进行数据读写、适配，处理。请求由adapter最终会交给servlet处理 常说的BIO、NIO，主要的应用就在protocolHandler中。protocolHandler负责维护Connector使用的协议以及IO方式。在protocolHandler中，不同的IO方式，会使用不同的EndPoint，具体采用哪种IO方式，取决于采用哪个EndPoint，每一个EndPoint的实现类,都封装了一种IO策略。若采用NIO，则为NioEndpoint。 Connector初始化创建Connector时，会拿到Tomcat目录下conf/server.xml中Connector的协议配置，利用反射创建ProtocolHandler： /** * Coyote Protocol handler class name. * Defaults to the Coyote HTTP/1.1 protocolHandler. */ protected String protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11NioProtocol&quot;; public Connector(String protocol) { //设置protocolHandlerClassName类名 setProtocol(protocol); // Instantiate protocol handler ProtocolHandler p = null; try { //根据server.xml中&lt;connector/&gt;标签的protocol属性值，获取到对应的http协议类 Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName); p = (ProtocolHandler) clazz.getConstructor().newInstance(); } catch (Exception e) { log.error(sm.getString( &quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;), e); } finally { this.protocolHandler = p; } if (Globals.STRICT_SERVLET_COMPLIANCE) { uriCharset = StandardCharsets.ISO_8859_1; } else { uriCharset = StandardCharsets.UTF_8; } } //设置protocolHandlerClassName类名 public void setProtocol(String protocol) { boolean aprConnector = AprLifecycleListener.isAprAvailable() &amp;&amp; AprLifecycleListener.getUseAprConnector(); //若配置了protocol=&quot;HTTP/1.1&quot;或者没配，则默认是Http11NioProtocol或者Http11AprProtocol if (&quot;HTTP/1.1&quot;.equals(protocol) || protocol == null) { if (aprConnector) { setProtocolHandlerClassName(&quot;org.apache.coyote.http11.Http11AprProtocol&quot;); } else { setProtocolHandlerClassName(&quot;org.apache.coyote.http11.Http11NioProtocol&quot;); } } else if (&quot;AJP/1.3&quot;.equals(protocol)) { if (aprConnector) { setProtocolHandlerClassName(&quot;org.apache.coyote.ajp.AjpAprProtocol&quot;); } else { setProtocolHandlerClassName(&quot;org.apache.coyote.ajp.AjpNioProtocol&quot;); } } else { //直接取配置的类名 setProtocolHandlerClassName(protocol); } } 以Tomcat8.5.20为例，这里默认是http1.1的NIO。 Connector.start()开启Connector初始化后，调用start方法开启。主要涉及一下几个方法： Connector的startInternal()方法，会调用protocolHandler.start()； protocolHandler中会调用endpoint.start()，从而达到开启endpoint、监听端口、读写Socket的目的： //Connector开启 protected void startInternal() throws LifecycleException { // 校验端口 if (getPort() &lt; 0) { throw new LifecycleException(sm.getString( &quot;coyoteConnector.invalidPort&quot;, Integer.valueOf(getPort()))); } //设置Connector的状态为开启 setState(LifecycleState.STARTING); try { //开启protocolHandler protocolHandler.start(); } catch (Exception e) { String errPrefix = &quot;&quot;; if(this.service != null) { errPrefix += &quot;service.getName(): \&quot;&quot; + this.service.getName() + &quot;\&quot;; &quot;; } throw new LifecycleException (errPrefix + &quot; &quot; + sm.getString (&quot;coyoteConnector.protocolHandlerStartFailed&quot;), e); } } //protocolHandler开启 public void start() throws Exception { if (getLog().isInfoEnabled()) getLog().info(sm.getString(&quot;abstractProtocolHandler.start&quot;, getName())); try { //endpoint开启，初始化Processor缓存、event缓存、exector线程池，开启轮询线程、acceptor线程 endpoint.start(); } catch (Exception ex) { getLog().error(sm.getString(&quot;abstractProtocolHandler.startError&quot;, getName()), ex); throw ex; } // Start async timeout thread asyncTimeout = new AsyncTimeout(); Thread timeoutThread = new Thread(asyncTimeout, getNameInternal() + &quot;-AsyncTimeout&quot;); int priority = endpoint.getThreadPriority(); if (priority &lt; Thread.MIN_PRIORITY || priority &gt; Thread.MAX_PRIORITY) { priority = Thread.NORM_PRIORITY; } timeoutThread.setPriority(priority); timeoutThread.setDaemon(true); timeoutThread.start(); } 至此，Connector完成了开启的过程，开启监听端口、可以读写Socket了。 总结一下，关于Connector： 创建Connector时，会拿到Tomcat目录下conf/server.xml中Connector的协议配置，利用反射创建ProtocolHandler。 ProtocolHandler负责维护Connector使用的协议以及IO方式，不同的IO方式如BIO、NIO、AIO封装在EndPoint中 开启Connector时，会开启protocolHandler，从而达到EndPoint的开启，开始监听端口、读写socket数据了 protocolHandler中将请求拿到的数据进行适配，通过adapter适配成Request和Response对象，最终交给Container去处理 下面重点就来了，NIO。 Tomcat NIOTomcat在处理客户端请求时，读写socket数据是一种网络IO操作。目前Tomcat有几种IO方式，分别是BIO(同步阻塞)，NIO(同步非阻塞)和AIO(异步非阻塞)。不同IO方式的读写机制，被封装在了Endpoint中。BIO、AIO不再赘述。这里主要看NIO。 Tomcat NIO模型当然要了解一下Tomcat NIO的模型了。Tomcat NIO是基于Java NIO实现的，其基本原理如下： Tomcat NIO是对Java NIO的一种典型的应用方式：通过JDK提供的同步非阻塞的IO方式，实现了IO多路复用，即一个线程管理多个客户端的连接。了解Java NIO，可以看一下 Java NIO 。 Tomcat在NIO模式下，所有客户端的请求先由一个接收线程接收，然后由若干个(一般为CPU的个数)线程轮询读写事件，最后将具体的读写操作交由线程池处理。 NioEndpoint要了解Tomcat的NIO实现，其实就是了解NioEndpoint的实现原理。 数据结构它一共包含LimitLatch、Acceptor、Poller、SocketProcessor、Excutor5个部分 LimitLatch是连接控制器，它负责维护连接数的计算，nio模式下默认是10000，达到这个阈值后，就会拒绝连接请求。 Acceptor负责接收连接，默认是1个线程来执行，将请求的事件注册到事件列表 Poller来负责轮询上述产生的事件。Poller线程数量是cpu的核数Math.min(2,Runtime.getRuntime().availableProcessors())。由Poller将就绪的事件生成SocketProcessor，然后交给Excutor去执行。 SocketProcessor继承了SocketProcessorBase，实现了Runnable接口，可以提交给线程池Excutor来执行。它里面的doRun()方法，封装了读写Socket、完成Container调用的逻辑 Excutor线程池是一个Tomcat线程池。用来执行Poller创建的SocketProcessor。Excutor线程池的大小就是我们在Connector节点配置的maxThreads的值。 SocketProcessor被一个线程执行的时候，会完成从socket中读取http request，解析成HttpServletRequest对象，分派到相应的servlet并完成逻辑，然后将response通过socket发回client。在从socket中读数据和往socket中写数据的过程，并没有像典型的非阻塞的NIO的那样，注册OP_READ或OP_WRITE事件到主Selector，而是直接通过socket完成读写，这时是阻塞完成的，但是在timeout控制上，使用了NIO的Selector机制，但是这个Selector并不是Poller线程维护的主Selector，而是BlockPoller线程中维护的Selector，称之为辅Selector， 实现可见org.apache.coyote.http11.Http11InputBuffer#fill。 了解了NioEndPoint的数据结构之后，可以看一下它们的关系图 NioEndpoint组件关系图 以上过程就以同步非阻塞的方式完成了网络IO。 其实是一个Reactor模型： 一个Acceptor（当然多个也行，不过一般场景一个够了）负责accept事件，把接收到SocketChannel注册到按某种算法从Reactor池中取出的一个Reactor上，注册的事件为读，写等，之后这个Socket Channel的所有IO事件都和Acceptor没关系，都由被注册到的那个Reactor来负责。 每个Acceptor和每个Reactor都各自持有一个Selector 当然每个Acceptor和Reactor都是一个线程 这里的Poller池其实就是一个Reactor池，可以是多个线程。 NioEndPoint实现工作原理简单了解了一下，接下来看一下具体的代码实现吧。先上一个NioEndpoint的UML图： NioEndPoint启动AbstractEndpoint里实现了一些EndPoint的抽象的通用的方法，其中主要的一个入口方法是 org.apache.tomcat.util.net .AbstractEndpoint#start方法 public final void start() throws Exception { if (bindState == BindState.UNBOUND) { bind(); bindState = BindState.BOUND_ON_START; } startInternal(); } 其中，bind()方法和startInternal()方法，由其子类具体实现。 bind()方法用于初始化endpoint，绑定监听端口等、设置最大线程数、ssl等。 startInternal()方法在EndPoint初始化完毕后，创建pollers轮询线程以及acceptors线程并开启。 /** * 开启 NIO endpoint, 创建pollers轮询线程以及acceptors线程 */ @Override public void startInternal() throws Exception { if (!running) { running = true; paused = false; //SocketProcessor缓存。若缓存没有，则创建新的SocketProcessor processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getProcessorCache()); //poller事件缓存 eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getEventCache()); //nioChannels缓存。 nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getBufferPool()); // Create worker collection 创建线程池 if ( getExecutor() == null ) { createExecutor(); } initializeConnectionLatch(); // Start poller threads pollers = new Poller[getPollerThreadCount()]; for (int i=0; i&lt;pollers.length; i++) { pollers[i] = new Poller(); Thread pollerThread = new Thread(pollers[i], getName() + &quot;-ClientPoller-&quot;+i); pollerThread.setPriority(threadPriority); pollerThread.setDaemon(true); pollerThread.start(); } //start acceptor threads startAcceptorThreads(); } } protected final void startAcceptorThreads() { int count = getAcceptorThreadCount(); acceptors = new Acceptor[count]; for (int i = 0; i &lt; count; i++) { acceptors[i] = createAcceptor(); String threadName = getName() + &quot;-Acceptor-&quot; + i; acceptors[i].setThreadName(threadName); Thread t = new Thread(acceptors[i], threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); } } NioEndPoint时序图看完了开启EndPoint的过程，再来详细看一下NioEndpoint处理的的时序图： 通过上面的时序图，结合代码来详细了解一下Acceptor和Poller的工作方式。 Acceptor接收请求NioEndPoint中的Acceptor方法实现了Runnable接口，主要干的活就是上述图中的3,4,5,6,7 @Override public void run() { int errorDelay = 0; // 循环，直到收到一个关闭的命令 while (running) { // 如果EndPoint被暂停，则循环sleep while (paused &amp;&amp; running) { state = AcceptorState.PAUSED; try { Thread.sleep(50); } catch (InterruptedException e) { // Ignore } } if (!running) { break; } state = AcceptorState.RUNNING; try { //如果达到了最大连接数，则等待 countUpOrAwaitConnection(); SocketChannel socket = null; try { // 创建一个socketChannel，接收下一个从服务器进来的连接 socket = serverSock.accept(); } catch (IOException ioe) { // We didn&apos;t get a socket countDownConnection(); if (running) { // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; } else { break; } } // 成功接收，重置error delay errorDelay = 0; // 如果处于EndPoint处于running状态并且没有没暂停，Configure the socket if (running &amp;&amp; !paused) { // setSocketOptions()将把socket传递给适当的处理器。如果成功，会关闭socket。 // 否则，在这里关闭socket if (!setSocketOptions(socket)) { closeSocket(socket); } } else { closeSocket(socket); } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(sm.getString(&quot;endpoint.accept.fail&quot;), t); } } state = AcceptorState.ENDED; } 看的出来，Acceptor使用serverSock.accept()阻塞的监听端口，如果有连接进来，拿到了socket，并且EndPoint处于正常运行状态，则调用NioEndPoint的setSocketOptions方法，一顿操作。 至于setSocketOptions做了什么，概括来说就是根据socket构建一个NioChannel，然后把这个的NioChannel注册到Poller的事件列表里面，等待poller轮询。 看下setSocketOptions的代码： /** * 处理指定的连接 * @param socket The socket channel * @return * 如果socket配置正确，并且可能会继续处理，返回true * 如果socket需要立即关闭，则返回false */ protected boolean setSocketOptions(SocketChannel socket) { // Process the connection try { //非阻塞模式 socket.configureBlocking(false); Socket sock = socket.socket(); socketProperties.setProperties(sock); //从缓存中拿一个nioChannel 若没有，则创建一个。将socket传进去 NioChannel channel = nioChannels.pop(); if (channel == null) { SocketBufferHandler bufhandler = new SocketBufferHandler( socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); if (isSSLEnabled()) { channel = new SecureNioChannel(socket, bufhandler, selectorPool, this); } else { channel = new NioChannel(socket, bufhandler); } } else { channel.setIOChannel(socket); channel.reset(); } //从pollers数组中获取一个Poller对象，注册这个nioChannel getPoller0().register(channel); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); try { log.error(&quot;&quot;,t); } catch (Throwable tt) { ExceptionUtils.handleThrowable(tt); } // Tell to close the socket return false; } return true; } 显然，下面的重点就是register这个方法了。这个方法是NioEndPoint中的Poller实现的，主要干的事就是在Poller注册新创建的套接字。 /** * 使用轮询器注册新创建的socket * * @param socket 新创建的socket */ public void register(final NioChannel socket) { socket.setPoller(this); //创建一个NioSocketWrapper，包装一下socket。然后一顿设置。 NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this); socket.setSocketWrapper(ka); ka.setPoller(this); ka.setReadTimeout(getSocketProperties().getSoTimeout()); ka.setWriteTimeout(getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); ka.setReadTimeout(getConnectionTimeout()); ka.setWriteTimeout(getConnectionTimeout()); //从缓存中取出一个PollerEvent对象，若没有则创建一个。将socket和NioSocketWrapper设置进去 PollerEvent r = eventCache.pop(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); //添到到该Poller的事件列表 addEvent(r); } 总结一下，从Acceptor接收到请求，它做了这么些工作： 如果达到了最大连接数，则等待。否则，阻塞监听端口。 监听到有连接，则创建一个socketChannel。若服务正常运行，则把socket传递给适当的处理器。如果成功，会关闭socket。 在这里，适当的处理是指调用NioEndPoint的setSocketOptions方法，处理指定的连接： 将socket设置为非阻塞 从缓存中拿一个nioChannel 若没有，则创建一个。将socket传进去。 从pollers数组中获取一个Poller对象，把nioChannel注册到该Poller中。 其中最后一步注册的过程，是调用Poller的register()方法： 创建一个NioSocketWrapper，包装socket。然后配置相关属性，设置感兴趣的操作为SelectionKey.OP_READ PollerEvent。PollerEvent可以是从缓存中取出来的，若没有则创建一个。初始化或者重置此Event对象，设置感兴趣的操作为OP_REGISTER (Poller轮询时会用到) 将新的PollerEvent添加到这个Poller的事件列表events，等待Poller线程轮询。 Poller轮询其实上面已经提到了Poller将一个事件注册到事件队列的过程。接下来便是Poller线程如何处理这些事件了，这就是Poller线程的工作机制。 Poller作为一个线程，实现了Runnable接口的run方法，在run方法中会轮询事件队列events，将每个PollerEvent中的SocketChannel感兴趣的事件注册到Selector中，然后将PollerEvent从队列里移除。之后就是SocketChanel通过Selector调度来进行非阻塞的读写数据了。 看下Poller.run()代码： /** * The background thread that adds sockets to the Poller, checks the * poller for triggered events and hands the associated socket off to an * appropriate processor as events occur. */ @Override public void run() { // 循环直到 destroy() 被调用 while (true) { boolean hasEvents = false; try { if (!close) { //将events队列，将每个事件中的通道感兴趣的事件注册到Selector中 hasEvents = events(); if (wakeupCounter.getAndSet(-1) &gt; 0) { //如果走到了这里，代表已经有就绪的IO通道 //调用非阻塞的select方法，直接返回就绪通道的数量 keyCount = selector.selectNow(); } else { //阻塞等待操作系统返回 数据已经就绪的通道，然后被唤醒 keyCount = selector.select(selectorTimeout); } wakeupCounter.set(0); } if (close) { events(); timeout(0, false); try { selector.close(); } catch (IOException ioe) { log.error(sm.getString(&quot;endpoint.nio.selectorCloseFail&quot;), ioe); } break; } } catch (Throwable x) { ExceptionUtils.handleThrowable(x); log.error(&quot;&quot;,x); continue; } //如果上面select方法超时，或者被唤醒，先将events队列中的通道注册到Selector上。 if ( keyCount == 0 ) hasEvents = (hasEvents | events()); Iterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; // 遍历已就绪的通道，并调用processKey来处理该Socket的IO。 while (iterator != null &amp;&amp; iterator.hasNext()) { SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); // 如果其它线程已调用，则Attachment可能为空 if (attachment == null) { iterator.remove(); } else { iterator.remove(); //创建一个SocketProcessor，放入Tomcat线程池去执行 processKey(sk, attachment); } }//while //process timeouts timeout(keyCount,hasEvents); }//while getStopLatch().countDown(); } 读取已就绪通道的部分，是常见的Java NIO的用法，Selector调用selectedKeys()，获取IO数据已经就绪的通道，遍历并调用processKey方法来处理每一个通道就绪的事件。而processKey方法会创建一个SocketProcessor，然后丢到Tomcat线程池中去执行。 其中需要注意的一个点是，events()方法，用来处理PollerEvent事件，执行PollerEvent.run()，然后将PollerEvent重置再次放入缓存中，以便对象复用。 /** * Processes events in the event queue of the Poller. * * @return &lt;code&gt;true&lt;/code&gt; if some events were processed, * &lt;code&gt;false&lt;/code&gt; if queue was empty */ public boolean events() { boolean result = false; PollerEvent pe = null; while ( (pe = events.poll()) != null ) { result = true; try { //把SocketChannel感兴趣的事件注册到Selector中 pe.run(); pe.reset(); if (running &amp;&amp; !paused) { eventCache.push(pe); } } catch ( Throwable x ) { log.error(&quot;&quot;,x); } } return result; } 可以看出，PollerEvent.run()方法才是重点： public void run() { //Acceptor调用Poller.register()方法时，创建的PollerEvent感兴趣的事件为OP_REGISTER，因此走这个分支 if (interestOps == OP_REGISTER) { try { //将SocketChannel的读事件注册到Poller线程的Selector中，使用Selector来调度IO。 socket.getIOChannel().register( socket.getPoller().getSelector(), SelectionKey.OP_READ, socketWrapper); } catch (Exception x) { log.error(sm.getString(&quot;endpoint.nio.registerFail&quot;), x); } } else { final SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try { if (key == null) { // The key was cancelled (e.g. due to socket closure) // and removed from the selector while it was being // processed. Count down the connections at this point // since it won&apos;t have been counted down when the socket // closed. socket.socketWrapper.getEndpoint().countDownConnection(); } else { final NioSocketWrapper socketWrapper = (NioSocketWrapper) key.attachment(); if (socketWrapper != null) { //we are registering the key to start with, reset the fairness counter. int ops = key.interestOps() | interestOps; socketWrapper.interestOps(ops); key.interestOps(ops); } else { socket.getPoller().cancelledKey(key); } } } catch (CancelledKeyException ckx) { try { socket.getPoller().cancelledKey(key); } catch (Exception ignore) {} } } } 至此，可以看出Poller线程的作用 将Acceptor接收到的请求注册到Poller的事件队列中 Poller轮询事件队列中，处理到达的事件，将PollerEvent中的通道注册到Poller的Selector中 轮询已就绪的通道，对每个就绪通道创建一个SocketProcessor，交个Tomcat线程池去处理 剩下的事情，就是SocketProcessor怎么适配客户端发来请求的数据、然后怎样交给Tomcat容器去处理了。 SocketProcessor处理请求简单提一下SocketProcessor的处理过程，不是这篇文章的重点。通过上面可以知道，具体处理一个请求，是在SocketProcessor通过线程池去执行的。执行一次请求的时序图 SocketProcessor中通过Http11ConnectionHandler，取到Htpp11Processor，Htpp11Processor调用prepareRequest方法，准备好请求数据。然后调用CoyoteAdapter的service方法进行request和response的适配，之后交给容器进行处理。 在CoyoteAdapter的service方法中，主要干了2件事： org.apache.coyote.Request -&gt; org.apache.catalina.connector.Request extends HttpServletRequest，org.apache.coyote.Response -&gt; org.apache.catalina.connector. Response extends HttpServletResponse 将请求交给StandardEngineValue处理 将请求交给Tomcat容器处理后，后将请求一层一层传递到Engin、Host、Context、Wrapper，最终经过一系列Filter，来到了Servlet，执行我们自己具体的代码逻辑。其中，容器之间数据的传递用到了管道流的机制。这里就不在赘述，以后有时间专门写一篇Tomcat容器的工作原理。 参考文章： 《Tomcat内核设计剖析》 深度解读Tomcat中的NIO模型]]></content>
      <categories>
        <category>Tomcat</category>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO]]></title>
    <url>%2F2018%2F03%2F28%2FJava%20NIO%2F</url>
    <content type="text"><![CDATA[了解java的NIO，需要先了解同步异步以及阻塞非阻塞的概念， 同步/异步，阻塞/非阻塞 NIO就是采用的同步非阻塞这种组合方式。或简单一点，采用的是IO复用的策略，可以使用一个线程管理多个IO连接。 BIO常见使用方式传统的BIO是同步阻塞的方式，因此，在服务器中常见的使用方式是： 来一个请求创建一个线程，阻塞的等待网络IO的数据。 使用一个线程池，来一个请求就从线程池里取出来一个线程，阻塞的等待网络IO的数据。 两种方式的图例： BIO面临的问题上面的方案可能会出现的问题是 针对第一种方式，如果短时间内qps过高，可能会导致线程数过多，拖垮服务器。 针对第二种方式，现在一般用的http1.1支持长连接，若系统中有大量的长连接没有释放，依然在阻塞的等待网络IO，就会导致线程池资源慢慢被消耗调，最终可能导致线程池满无法提供服务。 总结一下，上述两点问题的原因，其共同点是可能会有很多的空闲线程阻塞的等待IO，导致服务器以各种表现形式没有办法继续对外提供服务。 NIONIO的IO多路复用因此，如果是同步非阻塞的方式，可以只需要一个线程，管理多个IO连接。一旦有连接可以读/写，才开启一个线程进行读/写、执行相应的操作。如下： Java中的NIO原理接说到这里，下面看一下jdk中NIO的实现和用法。jdk中的NIO的实现，主要几个部分是Channel（通道），Buffer（缓冲区），Selector（选择器）。 Channel提供从文件、网络读取数据的通道，但是读取或写入的数据都必须经由Buffer。通道是双向的，通过一个Channel既可以进行读，也可以进行写 Buffer，故名思意，缓冲区，实际上是一个容器，是一个连续数组。服务端接收数据必须通过Channel将数据读入到Buffer中，然后再从Buffer中取出数据来处理。 Selector类是NIO的核心类，Selector能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。 在一个基于NIO的IO多路复用的具体应用场景中，它们之间的关系可能是这样的： 其中，一个线程管理一个Selector，而一个Selector管理多个Channel，被管理的Channel需要在该Selector上注册自己感兴趣的事件，如Accept，Read，Write等。 每个Channel对应一个缓冲区Buffer，每次Channel中有数据可以读写的时候，就读写到缓冲区中。然后程序再对缓冲区进行操作。 这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用相应的方法或者线程来进行读写、操作，大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多个空闲连接的多线程之间的上下文切换导致的开销。 Selector既然NIO是非阻塞，其实就是 把阻塞的位置从系统的CPU层面提到了程序层面， 那么当Channel中注册的感兴趣的事件就绪时，Selector需要通过某种策略得知Channel数据已经就绪，可以采用轮询、事件驱动等方式。这里就封装成了Selector的select方法，返回值是已经就绪的通道的数量。 当Selector得知有通道对其感兴趣的事件就绪时，就取出所有已经就绪的通道，进行读写或者其它操作。Selector的 selectedKeys()方法就封装了取出所有就绪的通道的事件，返回值是一个SelectionKey的集合。SelectionKey中封装了一个Channel与selector的对应关系、Channel感兴趣的事件、Channel哪种事件已经就绪的判断(isReadable、isWritable等)。 Selector的工作方式看一下Selector的工作方式： 流程总结如下： 通过 Selector.open() 打开一个 Selector. 将 Channel 注册到 Selector 中, 并设置需要监听的事件(interest set) 不断重复: 调用 select() 方法，阻塞获取到就绪通道 调用 selector.selectedKeys() 获取 selected keys 迭代每个selected keys，对每个 selected key: 从 selected key 中获取 对应的 Channel 和附加信息(如果有的话) 判断是哪些 IO 事件已经就绪了, 然后处理它们. 如果是 OP_ACCEPT 事件, 则获取 SocketChannel, 并将它设置为 非阻塞的, 然后将这个 Channel 注册到 Selector 中.，如果是读/写事件，则进行读写操作。 根据需要更改 selected key 的监听事件. 将已经处理过的 key 从 selected keys 集合中删除. 需要注意的一点是，图中第4步中的select方法，有几个重载的方法： select() 阻塞到至少有一个通道在你注册的事件上就绪了。 select(long timeout) 和select()一样，但最长阻塞事件为timeout毫秒。 selectNow() 非阻塞，立即返回结果，如果没有已就绪事件，直接返回0。 IO多路复用由一个线程管理一个Selector，一个Selector可以管理多个通道Channel。当调用Selector的select方法时，会阻塞的等待操作系统返回已经就绪的IO通道。这里用到的技术是IO多路复用，从而实现了同步非阻塞，解决了一个请求一个线程一直在阻塞的问题。因为一个selector线程管理了多个连接、通道，select一旦拿到有准备就绪的通道，无论是在本线程内对其做读写操作，还是交给一个其他线程去做读写操作，这个时候Selector所在的线程其实一直是可用的，并没有因为其他通道还未就绪而一直空闲。 同步因为我们的Selector线程是去主动问操作系统有没有IO已经就绪，若就绪则进行读写(用户空间↔内核空间数据copy)，而不是操作系统把数据准备好之后(用户空间↔内核空间数据copy完成)再来通知我们的程序。所以说这里的IO是同步的。 非阻塞因为Selector线程对于每一个通道的数据，并没有等待数据就绪，而是直接返回，所以这里的IO是非阻塞的。上面提到的阻塞等待，等待的是这个Selector所管理的所有通道。也因此一个Selector线程可以管理多个IO通道。 综上所述，Java的NIO是以Selector为核心的，基于同步非阻塞的IO多路复用。 OS的IO多路复用那么，Selector是如何得知哪些通道是就已经就绪了呢？这里涉及到的系统调用是select，poll，epoll。既然我们的程序使用了IO多路复用实现了一个线程管理多个IO，那么操作系统告诉我们已就绪的IO通道时，底层是否也采用了IO多路复用呢？操作系统的IO多路复用(IO multiplexing)就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 所以总结来说，就是我们的用户线程使用IO多路复用，管理多个IO通道，一旦有通道就绪，就进行读写。而我们的操作系统同样采用了IO多路复用，一旦有socket数据准备就绪，就通知我们的的用户线程。 select()的实现翻一番Selector实现类的源码，select()方法其实还是调用了select(long timeout)方法。 public int select() throws IOException { return this.select(0L); } public int select(long timeout) throws IOException { if (timeout &lt; 0L) { throw new IllegalArgumentException(&quot;Negative timeout&quot;); } else { return this.lockAndDoSelect(timeout == 0L ? -1L : timeout); } } public int selectNow() throws IOException { return this.lockAndDoSelect(0L); } 看得出来，select阻塞获取操作系统就绪通道的关键的实现在于lockAndDoSelect方法中： private int lockAndDoSelect(long var1) throws IOException { synchronized(this) { if (!this.isOpen()) { throw new ClosedSelectorException(); } else { Set var4 = this.publicKeys; int var10000; synchronized(this.publicKeys) { Set var5 = this.publicSelectedKeys; synchronized(this.publicSelectedKeys) { var10000 = this.doSelect(var1); } } return var10000; } } } 加了两个锁，然后会调用一个doSelect方法。doSelect方法由子类实现，有PollSelectorImpl、EPollSelectorImpl。他们实现doSelect时分别调用了本地方法poll0、epollWait，分别对应操作系统的poll、epoll策略。 在调用Selector的open方时，就已经根据操作系统、内核版本决定了采用哪种IO复用策略，简单看一下 sun.nio.ch .DefaultSelectorProvider#create里Selector的创建： public static SelectorProvider create() { String var0 = (String)AccessController.doPrivileged(new GetPropertyAction(&quot;os.name&quot;)); if (var0.equals(&quot;SunOS&quot;)) { return createProvider(&quot;sun.nio.ch.DevPollSelectorProvider&quot;); } else { return (SelectorProvider)(var0.equals(&quot;Linux&quot;) ? createProvider(&quot;sun.nio.ch.EPollSelectorProvider&quot;) : new PollSelectorProvider()); } } 如果是Linux系统的话，使用的是操作系统的epoll 的策略 对于操作系统来说： epoll：如果有IO已经就绪，会给用户线程返回所有就绪的事件，可以对这个就绪的IO通道进行读写。 poll：得到有就绪的IO时，需要遍历去查询哪些IO是已就绪的，然后返回给用户线程去读写。 参考文章： Java NIO系列教程 Java NIO：NIO概述 Java IO &amp; NIO &amp; NIO2 Java 网络 IO 模型 Java NIO系列教程（六） 多路复用器Selector Java 网络IO编程总结（BIO、NIO、AIO均含完整实例代码） Java NIO 反应堆模式简单模型 Java NIO(7): Epoll版的Selector Linux IO模式及 select、poll、epoll详解]]></content>
      <categories>
        <category>Java</category>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程的几种状态]]></title>
    <url>%2F2018%2F03%2F20%2FJava%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[java.lang.Thread.State中定义的集中Java线程的状态： /** * A thread state. A thread can be in one of the following states: * &lt;ul&gt; * &lt;li&gt;{@link #NEW}&lt;br&gt; * A thread that has not yet started is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #RUNNABLE}&lt;br&gt; * A thread executing in the Java virtual machine is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #BLOCKED}&lt;br&gt; * A thread that is blocked waiting for a monitor lock * is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #WAITING}&lt;br&gt; * A thread that is waiting indefinitely for another thread to * perform a particular action is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #TIMED_WAITING}&lt;br&gt; * A thread that is waiting for another thread to perform an action * for up to a specified waiting time is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #TERMINATED}&lt;br&gt; * A thread that has exited is in this state. * &lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt; * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * * @since 1.5 * @see #getState */ public enum State { /** * 没有start()的线程状态 */ NEW, /** * 可运行线程的线程状态。处于可运行状态的线程正在Java虚拟机中执行，但它可能正在等待来自操作系统（如处理器）的其他资源 */ RUNNABLE, /** * 线程处于阻塞状态。在进入或者重新进入synchronized代码块/方法时，等待monitor lock的一种状态 */ BLOCKED, /** * 线程处于等待状态。,由于调用以下方法之一，线程会处于等待状态： * Object.wait() 没有超时时间 * Thread.join() 没有超时时间 * LockSupport.park() */ WAITING, /** * 具有指定等待时间的等待状态。调用以下方法之一,在指定的等待时间内，使线程处于等待状态： * Thread.sleep * Object#wait(long) 有超时时间 * Thread.join(long) 有超时时间 * LockSupport.parkNanos * LockSupport.parkUntil */ TIMED_WAITING, /** * 终止状态。 线程已完成执行 */ TERMINATED; } 上述Java代码定义的几个状态中其实是没有running状态的。 线程的runnable状态是从虚拟机的角度来看的,表示这个线程正在运行。 但是处于Runnable状态的线程不一定真地消耗CPU. 处于Runnable的线程只能说明该线程没有阻塞在java的wait或者sleep方法上， 同时也没等待在锁上面。 但是如果该线程调用了本地方法， 而本地方法处于等待状态， 这个时候虚拟机是不知道本地代码中发生了什么， 此时尽管当前线程实际上也是阻塞的状态， 但实际上显示出来的还是runnable状态，这种情况下是不消耗CPU的。 阻塞与等待的区别： 阻塞：当一个线程试图获取对象锁（非java.util.concurrent库中的锁，即synchronized），而该锁被其他线程持有，则该线程进入阻塞状态。它的特点是使用简单，由JVM调度器来决定唤醒自己，而不需要由另一个线程来显式唤醒自己，不响应中断。 等待：当一个线程等待另一个线程通知调度器一个条件时，该线程进入等待状态。它的特点是需要等待另一个线程显式地唤醒自己，实现灵活，语义更丰富，可响应中断。例如调用：Object.wait()、Thread.join()以及等待Lock或Condition。 参考文章： 线程状态]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读取含有BOM头的文件遇到的问题]]></title>
    <url>%2F2018%2F03%2F13%2F%E8%AF%BB%E5%8F%96%E5%90%AB%E6%9C%89BOM%E5%A4%B4%E7%9A%84%E6%96%87%E4%BB%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[需求是读取一个csv文件，然后解析成对应的数据结构。csv必须包含指定的某些列，通过列名header来进行校验。 解析配置文件的方法。 public List&lt;QuestionData&gt; buildConfigData(final MultipartFile file) { CsvReader csvReader = null; List&lt;QuestionData&gt; questionDataList; try (DataInputStream inputStream = new DataInputStream(file.getInputStream())) { csvReader = new CsvReader(new InputStreamReader(inputStream, Charset.forName(&quot;UTF-8&quot;))); if (!csvReader.readHeaders()) { return Lists.newLinkedList(); } final String[] headers = csvReader.getHeaders(); getAndCheckHeader(headers); questionDataList = getQuestionData(csvReader, headers); } catch (final IOException e) { log.error(&quot;解析配置文件错误&quot;, e); throw new FatalException(&quot;解析配置文件错误&quot;); } finally { if (csvReader != null) { csvReader.close(); } } return questionDataList; } 其中，检查header的方法： private static final Set&lt;String&gt; NEEDED_COLUMNS = ImmutableSet .of(QuestionDataType.ORDER.name(), QuestionDataType.DESC.name(), QuestionDataType.OPTION_A.name(), QuestionDataType.OPTION_B.name(), QuestionDataType.OPTION_C.name(), QuestionDataType.ANSWER.name()); private void getAndCheckHeader(final String[] headers) { //某些必要的列不存在 HashSet&lt;String&gt; sets = Sets.newHashSet(headers); if (!sets.containsAll(NEEDED_COLUMNS)) { throw new FatalException(&quot;缺少必要的列信息&quot;); } } 实际出现的问题是，上传文件的时候总是出现缺少必要的列信息这个异常。debug发现，containsAll这个方法一直返回false，但是看NEEDED_COLUMNS里面的字符串，在header里面都存在，例如ORDER字符串： 从这里看，headers里面有ORDER字符串，但是NEEDED_COLUMNS.contains(headers[0])返回的结果就是false。 debug时使用evaluate，将headers[0]的value copy一下，粘贴到输入框里，就发现了问题： 可以看的出来，headers[0]的实际值是” \uFEFF ORDER “,而非” ORDER “,前面多了一个” \uFEFF “。 经查，” \uFEFF “是BOM头，windows下保存文件时经常会插入在字符串最前面，debug时直接看值是看不出来有这个BOM头的。 解决方案，使用apache的BOMInputStream，可以过滤掉BOM头： public List&lt;QuestionData&gt; buildConfigData(final MultipartFile file) { CsvReader csvReader = null; List&lt;QuestionData&gt; questionDataList; //过滤BOM头 try (BOMInputStream inputStream = new BOMInputStream(file.getInputStream())) { csvReader = new CsvReader(new InputStreamReader(inputStream, Charset.forName(&quot;UTF-8&quot;))); if (!csvReader.readHeaders()) { return Lists.newLinkedList(); } final String[] headers = csvReader.getHeaders(); getAndCheckHeader(headers); questionDataList = getQuestionData(csvReader, headers); } catch (final IOException e) { log.error(&quot;解析配置文件错误&quot;, e); throw new FatalException(&quot;解析配置文件错误&quot;); } finally { if (csvReader != null) { csvReader.close(); } } return questionDataList; } 使用BOMInputStream，将原有的InputSteam包一层即可。 参考文章： Java处理文件BOM头的方式推荐]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS]]></title>
    <url>%2F2018%2F03%2F12%2FAQS%2F</url>
    <content type="text"><![CDATA[概述对于并发场景，单机情况下，java通过synchronize关键字、juc并发包下的原子类、各种锁的实现，来达到多线程间的同步。 AQS维护了一个volatile int state状态（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。state的访问方式有三种: getState() setState() compareAndSetState() AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 AQS应用来看一下AQS的子类 可以看到，常用的几个锁ReentrantLock、Semaphore的内部，都有AQS类的实现，用来进行同步的管理。每个锁内部都有一个Sync对象。 AQS的几个抽象方法tryAcquire、tryRelease等方法，在其实现类中都有实现。Sync也是一个抽象类，可以由子类实现公平锁和非公平锁。 举个例子，ReentrantLock的中的Sync，有两个子类，FairSync和NonfairSync，公平所和非公平锁。 Sync实现了AQS的几个抽象方法，并将lock()方法交给子类FairSync和NonfairSync分别去实现公平锁和非公平锁。本文主要以ReentrantLock为例，看一下可重入锁在独占方式下公平锁的实现、可重入锁的实现与AQS的关系。 ReentrantLock加锁(公平锁)公平锁：对于请求同一个锁的多线程，按照FIFO的原则分配锁的持有权。 看一下可重入锁中的公平锁的实现： 1234567891011121314//ReentrantLock加锁final void lock() &#123; //调用AQS的aquire方法 acquire(1);&#125;//AQS中阻塞获取锁public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; AQS中获取锁的方法中，分别采用了tryAcquire、acquireQueued、addWaiter、selfInterrupt等方法： tryAcquire尝试非阻塞的获取锁 addWaiter将当前线程放入阻塞队列中 acquireQueued实现阻塞队列中的当前线程阻塞的获得锁。若等待过程中被中断，则返回true selfInterrupt方法，线程自我中断 加锁的整体流程如下： 调用自定义同步器FairSync的tryAcquire()尝试直接去获取资源，如果成功则直接返回； 没成功，则标记为独占模式，addWaiter()将该线程加入等待队列的队尾； acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 以上过程都是通过AQS的acquire方法管理的。 下面来分别看一下其实现。 tryAcquire()尝试直接去获取资源，不论成功或失败，方法都直接返回，非阻塞。 12345678910111213141516171819202122//FairSync实现非阻塞获取锁的方法protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; //是阻塞队列队首元素 compareAndSetState(0, acquires)) &#123; //CAS修改状态 setExclusiveOwnerThread(current); return true; &#125; &#125;//可重入，state+=acquires else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; //获取锁失败 return false;&#125; addWaiter(Node mode)如果尝试获取锁失败，则将当前线程节点标记为独占模式，放入阻塞队列队尾，并返回当前线程所在的结点。 123456789101112131415161718192021222324252627282930313233343536373839404142//AQS将当前线程节点添加到阻塞队列队尾，private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 尝试快速方式直接放到队尾 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //上一步失败则采用enq入队 enq(node); return node;&#125;//自旋将node加入队尾private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 如果队列为空，则初始化，创建一个空的标志结点作为head结点，并将tail也指向它 if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //node放入队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;//CAS尾结点private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; 此处采用CAS自旋volatile变量，类似AtomicInteger.getAndIncrement()中的实现。 compareAndSetTail中传进去的是t，但只用于与tail的值相比较，实际修改的是tail的值，t用于存原本的tail节点 acquireQueued走到这一步时，该线程通过tryAcquire()获取资源失败，然后通过addWaiter()加入阻塞队列队尾。这时候当前线程可以进入等待状态，直到有持有锁的线程释放资源并唤醒当前线程，然后尝试获取锁。看一下实现： 123456789101112131415161718192021222324//AQS获取锁final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //一直循环到获取锁 final Node p = node.predecessor(); //前一个元素是阻塞队列队首元素 并且 尝试获取锁成功 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); //拿到资源后，将head指向该节点。所以head所指的节点，就是当前获取到资源的那个结点或null。 p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //尝试获取锁失败后，是否需要进入等待状态 parkAndCheckInterrupt()) //进入等待状态。若被唤醒，则检查等待过程中是否被中断过 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这里有一点需要注意，就是head指向的节点，要么是当前获取到资源的线程，要么是null。 线程如果因为调用park而阻塞的话，能够响应中断请求(中断状态被设置成true)，但是不会抛出InterruptedException 。acquireInterruptibly和doAcquireInterruptibly才会抛出中断异常 至于怎么判断改线程是否可以进入等待状态，是在shouldParkAfterFailedAcquire方法中通过前驱节点的waitStatus状态来判断的： 123456789101112131415161718192021222324252627282930313233343536373839/** waitStatus值表示线程已被取消 */static final int CANCELLED = 1;/** waitStatus值表示后续的线程需要被唤醒 */static final int SIGNAL = -1;/** waitStatus值表示线程正在等待状态。 */static final int CONDITION = -2;/** waitStatus值表示下一个获得共享应该无条件地传播。*/static final int PROPAGATE = -3;/** 0代表以上状态都不是*///AQS判断当先线程是否可以进入等待状态private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 前驱节点的waitStatus已经设置为SIGNAL，即前驱节点线程释放锁后，会唤醒后续线程 * 因此，该线程可以放心的等着被唤醒了 */ return true; if (ws &gt; 0) &#123; /* * waitStatus大于0时，代表前驱节点的线程处于取消状态 * 因此，一直向前查找到最后一个没有没取消的节点，中间被取消的节点成为无效节点， */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它释放锁后通知自己一下 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 如果可以进入等待状态，则调用parkAndCheckInterrupt方法，挂起当前线程。当线程被唤醒后，返回当前线程在等待过程中是否被中断过： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 总结总结一下加锁的总流程： 释放锁接下来是释放锁的过程： 12345678910111213141516//ReentrantLock释放锁public void unlock() &#123; sync.release(1);&#125;//AQS中释放锁public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; //持有资源的当前线程 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //唤醒等待队列里的下一个线程 return true; &#125; return false;&#125; 分两步： 先释放资源 如果资源释放完毕，则唤醒等待队列里的下一个线程。 释放资源释放资源的实现是在ReentrantLock.Sync中实现的，因为公平锁和非公平锁释放锁的方式是一样的。 tryRelease在ReentrantLock.Sync中释放锁的实现： 12345678910111213protected final boolean tryRelease(int releases) &#123; //释放占有资源 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 每次释放资源直接减去相应量的资源releases。free代表是否释放完。 如果剩余的state==0，则free置为true，利用setExclusiveOwnerThread(null)设置排它锁的拥有线程是null。代表当前线程已将资源释放完毕，把锁释放了。 否则，free为false，代表资源没有释放完。 最后返回释放的结果free。 唤醒后续线程然后是AQS中实现的unparkSuccessor，唤醒后续线程： 12345678910111213141516171819202122232425262728/** * 唤醒节点的继任者，如果存在的话。 */private void unparkSuccessor(Node node) &#123; /* * 如果状态为负值（即可能需要信号），则尝试清除信号。 允许失败或状态被等待线程修改 * @param node 刚刚释放完资源的当前线程，用户唤醒后续线程 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 将唤醒后继线程节点，这通常只是下一个节点。 Node s = node.next; //但如果下一个节点为空或状态为取消，则从尾部向后遍历以找到实际未取消的后继者。 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 这里找到阻塞队列中第一个未放弃的线程，然后利用unpark唤醒。 总结来说，release()是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。 参考文章Java并发之AQS详解 JAVA并发编程学习笔记之AQS源码分析（获取与释放） volatile关键字与CAS操作 线程状态]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RequestParam加与不加的区别]]></title>
    <url>%2F2018%2F03%2F12%2F%E6%B3%A8%E8%A7%A3%40RequestParam%E5%8A%A0%E4%B8%8E%E4%B8%8D%E5%8A%A0%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[最简单的两种写法，加或不加@RequestParam注解 123456789101112@RequestMapping("/list")public String test(int userId) &#123; return "list";&#125; @RequestMapping("/list")public String test(@RequestParam int userId) &#123; return "list";&#125; 第一种写法参数为非必传，第二种写法参数为必传。参数名为userId。 第二种写法可以通过@RequestParam(required = false)设置为非必传。因为required值默认是true，所以默认必传。 第二种写法可以通过@RequestParam(“userId”)或者@RequestParam(value = “userId”)指定参数名。 第二种写法可以通过@RequestParam(defaultValue = “0”)指定参数默认值 用法如下： 12345@RequestMapping("/list")public String test(@RequestParam(value = "userId", defaultValue = "0", required = false) int userId) &#123; return "list";&#125;]]></content>
      <categories>
        <category>Web</category>
        <category>Web框架</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>Web框架</tag>
        <tag>SpringMVC</tag>
        <tag>RequestParam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存问题排查思路]]></title>
    <url>%2F2018%2F03%2F08%2F%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[内存泄漏的判断判断系统是否存在内存泄漏的依据是： 如果系统存在内存泄漏， 那么完全垃圾回收完之后的内存值应该持续上升。 如果在现场能观察到这个现象， 说明系统存在内存泄漏。 当怀疑一个系统存在内存泄漏的时候， 首先使用FULL GC信息对内存泄漏进行一个初步确认， 确认系统是否存在内存泄漏。 只检查完全垃圾回收后的可用内存值是否一直再增大， 步骤如下: 首先截取系统稳定运行以后的GC信息 过滤出FULL GC的行。 只有FULL GC的行才有分析价值。 因为完全GC后的内存是当前Java对象真正使用的内存数量 如果完全垃圾回收后的内存持续增长， 大有一直增长到Xmx设定值的趋势， 那么这个时候基本上就可以断定系统存在内存泄漏。如果当前完全垃圾回收后内存增长到一个值之后， 又能回落， 总体上处于一个动态平衡， 那么内存泄漏基本可以排除。 内存泄露的原因直接内存native区域内存泄露的原因可能有三： 如果系统中存在JNI调用， 本地内存泄漏可能存在于JNI代码中。 JDK的Bug. 操作系统的Bug. 本地内存泄露也可能会引发OOM，但如果出现的是Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread这个异常，则往往是创建的线程过多或者堆内存过大导致的 主要原因可能有三： 系统当前有过多的线程， 操作系统无法再创建更多的线程 swap分区不足 在32位的系统下， 过大的堆内存设置， 导致本地内存不足。32位操作系统下一个进程的内存空间是有限的，当设置的heap大小+perm大小比较大时，势必会挤压native的大小。解决方式：(a) 减少Xmx或者PermSize的设置 (b) 如果系统需要的堆内存确实很大， 无法减少Xmx的设置， 可以通过设置-Xss强行将每个线程堆栈的尺寸设小， 一旦线程堆栈过长， 则自动截断， 从而可以让线程堆栈占用的内存不过渡膨胀。 但这个效果往往有限的。 Perm在使用大量反射、jsp、jar包、动态代理的情况下，加载的class很多，就有可能会OOM。 查看swap使用情况可以参见：Swap使用情况 内存泄漏的定位 jmap -histo &gt; objhist.log, 可以打印出当前对象的个数和大小 如果系统已经OutOfMemory异常并停止工作， 可以通过jmap -heap:format=b 获取内存信息 在启动期间增加-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=”具体的路径”， 当系统一旦OutOfMemory之后， 就会将内存信息和堆信息收集下来。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl命令踩的坑]]></title>
    <url>%2F2018%2F03%2F08%2Fcurl%E5%91%BD%E4%BB%A4%E8%B8%A9%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[使用curl命令执行get请求，带多个参数： curl localhost:8080/user/binding/query?userId=123456&amp;wrapperId=123&amp;from=test [1] 8937 [2] 8938 {&quot;ver&quot;:&quot;1.0.0&quot;,&quot;status&quot;:1,&quot;message&quot;:&quot;Required String parameter &apos;wrapperId&apos; is not present&quot;,&quot;data&quot;:null,&quot;ok&quot;:false} [1]- Done curl localhost:8080/user/binding/query?userId=123456 [2]+ Done wrapperId=123 返回结果提示缺少参数wrapperId，但是上述url中的确有wrapperId。 看最后两行的结果，发现是url被&amp;号截开，在shell中被当做两条命令来执行的。 解决方案 在url外面加上引号： curl &quot;localhost:8080/user/binding/query?userId=123456&amp;wrapperId=123&amp;from=test&quot;]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS握手]]></title>
    <url>%2F2018%2F03%2F08%2FHTTPS%E6%8F%A1%E6%89%8B%2F</url>
    <content type="text"><![CDATA[作用 内容加密 建立一个信息安全通道，来保证数据传输的安全； 身份认证 确认网站的真实性 数据完整性 防止内容被第三方冒充或者篡改 https的采用了对称加密和非对称加密。握手过程中采用非对称加密，得到一个对称加密的秘钥。数据传输的过程中，采用对称加密。 采用非对称加密比较慢，因此只在握手期间采用非对称加密，保证拿到的对称加密的秘钥的安全性，数据传输期间通过对称加密来加密，速度更快。 握手： 对称加密秘钥的生成： 握手期间，client与server两次往来。会生成三个随机数，由这三个随机数组成对称加密的秘钥。 client验证server可靠性： 浏览器第一次收到服务器的ack时，会验证数字证书，一直验证到最顶层的根证书，如果浏览器内置有，则可信，否则不可信。 数据传输： http报文的内容都会经过TLS层进行对称加密，秘钥是握手时生成的。发送使用秘钥加密，接收时使用秘钥解密。 这里有一个问题，就是利用哪种非对称加密算法，这可能会影响https握手过程中的交换数据。以RSA算法和Diffie-Hellman算法为例，看一下两种加密方式分别经历了什么。 这个是RSA加密的交互过程。 第一个随机数由client生成，第二个随机数由server生成。 第三个随机数由client生成，使用server的公钥加密，并发送给server。第三个随机数即图中的Premaster secret。这个过程中，Premaster secret只有client和server知道，不会泄露。 然后client和server根据三个随机数生成一个session key，即接下来数据传输过程中用到的对称秘钥。 总结来说就是一共生成三个随机数，根据三个随机数创建一个对称加密的秘钥。前两个随机数可以被抓包拿到，但是第三个随机数已经使用非对称加密算法加密过，所以最终生成的秘钥是保密的。 现在的问题就是，对称秘钥的安全靠第三个随机数的不可破解来保证。理论上来说，只要服务器的公钥足够长，那么Premaster secret可以保证不被破解。但是为了足够安全，我们可以考虑把握手阶段的算法从默认的RSA算法，改为 Diffie-Hellman算法（简称DH算法）。 下面是DH算法握手的过程： 与上面client使用RSA公钥加密Premaster secret然后传递的server不同的是，由server发送一个server的DH 参数+private key，client发送一个client的DH参数，那么client和server都能分别通过两个DH参数得到Premaster secret。这样就提高了Premaster secret的安全性。 参考文章： 图解SSL/TLS协议 HTTPs入门, 图解SSL从回车到握手 HTTPS科普扫盲帖 详解https是如何确保安全的？]]></content>
      <categories>
        <category>计算机网络</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>网络协议</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat启动过程源码解读]]></title>
    <url>%2F2018%2F03%2F07%2FTomcat%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[根据Tomcat源码来看一下Tomcat启动过程都做了什么 部分代码为主要流程代码，删去了try-catch以及一些校验逻辑，方便理解主流程 先来一张启动过程时序图，了解一下启动顺序 Tomcat启动的入口类：org.apache.catalina.startup.Bootstrap#main main方法是整个tomcat启动时的入口。在main方法中，使用bootstrap.init()来初始化类加载器和创建Catalina实例，然后再启动Catalina线程。 public static void main(String args[]) { if (daemon == null ) { // Don&#39;t set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try { bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return ; } daemon = bootstrap; } else { // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } try { String command = &quot;start&quot; ; if (args.length &gt; 0 ) { command = args[args.length - 1 ]; } if (command.equals( &quot;startd&quot; )) { args[args.length - 1 ] = &quot;start&quot; ; daemon.load(args); daemon.start(); } else if (command.equals( &quot;stopd&quot; )) { args[args.length - 1 ] = &quot;stop&quot; ; daemon.stop(); } else if (command.equals( &quot;start&quot; )) { daemon.setAwait( true ); daemon.load(args); daemon.start(); } else if (command.equals( &quot;stop&quot; )) { daemon.stopServer(args); } else if (command.equals( &quot;configtest&quot; )) { daemon.load(args); if ( null ==daemon.getServer()) { System.exit( 1 ); } System.exit( 0 ); } else { log.warn( &quot;Bootstrap: command \&quot;&quot; + command + &quot;\&quot; does not exist.&quot; ); } } catch (Throwable t) { // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null ) { t = t.getCause(); } handleThrowable(t); t.printStackTrace(); System.exit( 1 ); } } bootstrap.init()方法，用于初始化容器相关，首先创建类加载器，然后通过反射创建org.apache.catalina.startup.Catalina实例： public void init() throws Exception { initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug( &quot;Loading startup class&quot; ); Class&lt;?&gt; startupClass = catalinaLoader.loadClass ( &quot;org.apache.catalina.startup.Catalina&quot; ); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader if (log.isDebugEnabled()) log.debug( &quot;Setting startup class properties&quot; ); String methodName = &quot;setParentClassLoader&quot; ; Class&lt;?&gt; paramTypes[] = new Class[ 1 ]; paramTypes[ 0 ] = Class.forName( &quot;java.lang.ClassLoader&quot; ); Object paramValues[] = new Object[ 1 ]; paramValues[ 0 ] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance; } 之后Bootstrap的demon.start()方法就会调用Catalina的start方法。 Catalina实例执行start方法。这里有两个点，一个是load()加载server.xml配置、初始化Server的过程，一个是getServer().start()开启服务、初始化并开启一系列组件、子容器的过程。 org.apache.catalina.startup.Catalina#start public void start() { if (getServer() == null ) { load(); } if (getServer() == null ) { log.fatal( &quot;Cannot start server. Server instance is not configured.&quot; ); return ; } long t1 = System.nanoTime(); // Start the new server try { getServer().start(); } catch (LifecycleException e) { log.fatal(sm.getString( &quot;catalina.serverStartFail&quot; ), e); try { getServer().destroy(); } catch (LifecycleException e1) { log.debug( &quot;destroy() failed for failed Server &quot; , e1); } return ; } long t2 = System.nanoTime(); if (log.isInfoEnabled()) { log.info( &quot;Server startup in &quot; + ((t2 - t1) / 1000000 ) + &quot; ms&quot; ); } // Register shutdown hook if (useShutdownHook) { if (shutdownHook == null ) { shutdownHook = new CatalinaShutdownHook(); } Runtime.getRuntime().addShutdownHook(shutdownHook); // If JULI is being used, disable JULI&#39;s shutdown hook since // shutdown hooks run in parallel and log messages may be lost // if JULI&#39;s hook completes before the CatalinaShutdownHook() LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).setUseShutdownHook( false ); } } if (await) { await(); stop(); } } load方法解析server.xml配置文件，并加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。加载完成后，调用getServer().start()来开启一个新的Server。 下面先看load方法怎么加载组件和容器的： /** * Start a new server instance. */ public void load() { long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed initNaming(); // Create and execute our Digester Digester digester = createStartDigester(); InputSource inputSource = null ; InputStream inputStream = null ; File file = null ; file = configFile(); inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); inputSource.setByteStream(inputStream); digester.push( this ); digester.parse(inputSource); getServer().setCatalina( this ); getServer().setCatalinaHome(Bootstrap.getCatalinaHomeFile()); getServer().setCatalinaBase(Bootstrap.getCatalinaBaseFile()); // Stream redirection initStreams(); // Start the new server getServer().init(); } 首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。 然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。顺序是StandardServer、StandardService、StandardEngine、Connector。每个容器都在初始化自身相关设置的同时，将子容器初始化。 这里插入一个Tomcat中生命周期的概念。在初始化、开启一系列组件、容器的过程中，由tomcat’管理的组件和容器，都有一个共同的特点，都实现了org.apache.catalina.Lifecycle接口，由Tomcat管理其生命周期。Lifecycle提供一种统一的管理对象生命周期的接口。通过Lifecycle、LifecycleListener、LifecycleEvent，Catalina实现了对tomcat各种组件、容器统一的启动和停止的方式。 在Tomcat服务开启过程中启动的一些列组件、容器，都继承了org.apache.catalina.util.LifecycleBase这个抽象类，其中的init()、start() 方法、stop() 方法，为其子类实现了统一的start和stop管理。方法中具体的initInternal()、startInternal() 和stopInternal() 方法，交由子类自己实现。 看一下LifecycleBase的init()和start()的实现吧： org.apache.catalina.util.LifecycleBase#start public final synchronized void init() throws LifecycleException { if (!state.equals(LifecycleState.NEW)) { invalidTransition(Lifecycle.BEFORE_INIT_EVENT); } try { setStateInternal(LifecycleState.INITIALIZING, null , false ); initInternal(); setStateInternal(LifecycleState.INITIALIZED, null , false ); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null , false ); throw new LifecycleException( sm.getString( &quot;lifecycleBase.initFail&quot; ,toString()), t); } } public final synchronized void start() throws LifecycleException { if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) { if (log.isDebugEnabled()) { Exception e = new LifecycleException(); log.debug(sm.getString( &quot;lifecycleBase.alreadyStarted&quot; , toString()), e); } else if (log.isInfoEnabled()) { log.info(sm.getString( &quot;lifecycleBase.alreadyStarted&quot; , toString())); } return ; } if (state.equals(LifecycleState.NEW)) { init(); } else if (state.equals(LifecycleState.FAILED)) { stop(); } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) { invalidTransition(Lifecycle.BEFORE_START_EVENT); } try { setStateInternal(LifecycleState.STARTING_PREP, null , false ); startInternal(); if (state.equals(LifecycleState.FAILED)) { stop(); } else if (!state.equals(LifecycleState.STARTING)) { invalidTransition(Lifecycle.AFTER_START_EVENT); } else { setStateInternal(LifecycleState.STARTED, null , false ); } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null , false ); throw new LifecycleException(sm.getString( &quot;lifecycleBase.startFail&quot; , toString()), t); } } 可以看到，init()和start()方法里，调用了initInternal()方法、startInternal()方法和stop()方法，这三者最终会走子类的具体实现。 上面的StandardServer的初始化过程就是一个活生生的例子。在Catalina的load过程中，getServer().init()方法就是LifecycleBase中的init()方法，调用initInternal()时是走的StandardServer的实现，StandardServer的initInternal()中会调用StandardServer的init()方法，进行子容器的初始化。然后依次初始化。 看一下代码，了解一下StandardServer中的initInternal()实现。 /** * Invoke a pre-startup initialization. This is used to allow connectors * to bind to restricted ports under Unix operating environments. */ @Override protected void initInternal() throws LifecycleException { super .initInternal(); // Register global String cache // Note although the cache is global, if there are multiple Servers // present in the JVM (may happen when embedding) then the same cache // will be registered under multiple names onameStringCache = register( new StringCache(), &quot;type=StringCache&quot; ); // Register the MBeanFactory MBeanFactory factory = new MBeanFactory(); factory.setContainer( this ); onameMBeanFactory = register(factory, &quot;type=MBeanFactory&quot; ); // Register the naming resources globalNamingResources.init(); // Populate the extension validator with JARs from common and shared // class loaders if (getCatalina() != null ) { ClassLoader cl = getCatalina().getParentClassLoader(); // Walk the class loader hierarchy. Stop at the system class loader. // This will add the shared (if present) and common class loaders while (cl != null &amp;&amp; cl != ClassLoader.getSystemClassLoader()) { if (cl instanceof URLClassLoader) { URL[] urls = ((URLClassLoader) cl).getURLs(); for (URL url : urls) { if (url.getProtocol().equals( &quot;file&quot; )) { try { File f = new File (url.toURI()); if (f.isFile() &amp;&amp; f.getName().endsWith( &quot;.jar&quot; )) { ExtensionValidator.addSystemResource(f); } } catch (URISyntaxException e) { // Ignore } catch (IOException e) { // Ignore } } } } cl = cl.getParent(); } } // Initialize our defined Services for ( int i = 0 ; i &lt; services.length; i++) { services[i].init(); } } 再举一个具体的例子: 回到刚才的启动过程中，getServer().start()开启服务的方法，实际就是上面提到的LifecycleBase中的start()方法。其中，会调用org.apache.catalina.core.StandardServer#initInternal方法，初始化Server并调用Service的init方法。org.apache.catalina.core.StandardServer在其实现的startInternal() 中，开启naming resources和services，调用service的start方法，开启所有service，调用其service的startInternal()方法。 下面分别看一下StandardServer中的initInternal()和startInternal()的实现： org.apache.catalina.core.StandardServer#startInternal protected void startInternal() throws LifecycleException { fireLifecycleEvent(CONFIGURE_START_EVENT, null ); setState(LifecycleState.STARTING); globalNamingResources.start(); // Start our defined Services synchronized (servicesLock) { for ( int i = 0 ; i &lt; services.length; i++) { services[i].start(); } } } 这里的service，是org.apache.catalina.core.StandardService的实例。 总结一下启动的Tomcat启动的过程 在Catalina的load方法里，就已经调用了StandardServer里的init方法，一层一层初始化了globalNamingResources，StandardService–》StandardEngine，executors，MapperListener，Connector–》CoyoteAdapter，protocolHandler。至此就将tomcat的catalina中的组件、容器初始化完成。 接下来就是调用start方法一层一层开启，StandardServer的startInternal方法，按层次start：globalNamingResources，StandardService–》StandardEngine，executors，MapperListener，Connector–》StandardHost，StandardContext，protocolHandler。顺序基本同init过程。StandardEngine在start时，会init子容器，并调用子容器的start方法。子容器依次这样init、start，就开启了StandardHost和StandardContext。 参考文章： tomcat源码分析-Connector初始化与启动 tomcat源码分析-Container初始化与加载 tomcat源码分析-http请求在Container中的执行路线 tomcat源码解析(一)–启动与Server.xml文件的解析]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步 异步，阻塞 非阻塞]]></title>
    <url>%2F2018%2F02%2F27%2F%E5%90%8C%E6%AD%A5%20%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%20%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
    <content type="text"><![CDATA[什么是同步和异步 同步和异步是针对应用程序和内核的交互而言的， 同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。 什么是阻塞和非阻塞 阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。 同步/异步与阻塞/非阻塞的区别 同步与异步：针对数据访问的方式，程序是主动去询问操作系统数据准备好了么，还是操作系统在数据准备好的时候通知程序。 阻塞与非阻塞：针对函数（程序）运行的方式，在IO未就绪时，是等待就绪还是直接返回（执行别的操作）。 阻塞与非阻塞的区别： 阻塞是程序在调用系统函数IO时，在系统执行系统调用时由CPU通过轮询等方式来实现数据的IO。 非阻塞是在程序级别通过轮询/信号/事件的机制，去查看IO数据是否就绪。 二者的区别其实就是，把阻塞的位置从系统的CPU层面提到了程序层面。 非阻塞与异步的区别： 非阻塞可以通过轮询或者信号/事件机制来实现，其目的是由内核通知我们何时可以启动一个I/O操作而异步I/O模型是在内核IO完成后，由内核通知我们I/O操作已经完成。 一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历： 从A的业务代码到A的软件框架 从A的软件框架到计算机的操作系统内核 从A所在计算机的内核到网卡 从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡 从B所在计算机的网卡到B所在计算机的内核 从B所在计算机的内核到B的程序的用户空间 从B的软件框架到B的业务代码 网卡&lt;-—&gt;网卡 同步执行。以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这是同步的。 网卡&lt;-—&gt;内核 异步执行。内核一般通过缓冲区，使用DMA来传输数据。CPU通知DMA读取IO设备数据，然后就去做其他的事情，等DMA把数据从IO设备中读到内核内存中，去通知CPU已经完成IO操作。所以这一步是异步的。 内核&lt;-—&gt;应用程序 同步执行，阻塞/非阻塞。用户进程/线程无法直接读写内核数据，需要数据在用户空间和内核空间搬来搬去。除非个别接口，否则一般是同步的。可以是阻塞或非阻塞，阻塞则一直在等待内核/应用程序把IO数据准备好，非阻塞则是直接返回内核/应用程序是否已经准备好数据。 应用程序框架：同步或异步。框架若使用异步IO，则通常需要应用程序&lt;-–&gt;内核之间是非阻塞的。一旦内核&lt;-–&gt;应用程序数据IO完成，则执行回调函数，执行一定的操作。 参考文章： 怎样理解阻塞非阻塞与同步异步的区别？ IO多路复用,同步，异步，阻塞和非阻塞 区别 关于异步，同步，阻塞与非阻塞 解读I/O多路复用技术]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC静态文件过滤]]></title>
    <url>%2F2018%2F02%2F26%2FSpringMVC%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%BF%87%E6%BB%A4%2F</url>
    <content type="text"><![CDATA[如果在web.xml加了如下配置，那么静态资源文件也会被拦截： &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 如果要静态资源文件不被过滤，有三种方法。 方案一、拦截器中增加针对静态资源不进行过滤(涉及spring-mvc.xml) SpringMVC提供 mvc:resources来设置静态资源，但是增加该设置如果采用通配符的方式增加拦截器的话仍然会被拦截器拦截。可以采用拦截器的方式。参考 https://www.cnblogs.com/banning/p/6195072.html 方案二、使用默认的静态资源处理Servlet处理静态资源(涉及spring-mvc.xml, web.xml) 1.在spring-mvc.xml中启用默认Servlet 用于处理静态资源的url请求 &lt;mvc:default-servlet-handler/&gt; 2.在web.xml中增加对静态资源的处理 &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.js&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.css&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 方案三、修改Spring的全局拦截设置为*.do的拦截（涉及web.xml） &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 这样设置，SpringMVC就会只针对以’.do’结尾的请求进行处理，不再处理静态资源.]]></content>
      <categories>
        <category>Web</category>
        <category>Web框架</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>Web框架</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git总结]]></title>
    <url>%2F2017%2F07%2F24%2FGit%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[git在本地分为三个区域，工作区、暂存区和本地仓库，具体情况如下： git的一般操作就是本地代码的修改提交回滚，以及与远程仓库的拉取、合并、提交等。 git fetch 从远程仓库上抓取分支到本机origin的dev分支上 git merge 将origin上的分支合并到工作区的dev分支上 git pull 相当于前两个命令合在一起 #切换到master分之后，将dev分支合并到master分支 git checkout master git merge dev 当本地仓库向远程仓库push失败的时候，先从远程仓库上fetch下最新的代码merge到本地的分支上，然后才能push 当fetch下来的代码与本地仓库的分支代码merge时发生冲突的话，需要解决掉冲突文件中的冲突再push。冲突文件这时已经被git程序更改，标记了冲突的位置。此时可以查看git status根据提示来操作，具体的做法： 1，若想回到没有更改前，即merge前，执行git merge –abort。再进行想要的操作。 2，可以直接更改冲突文件，然后git add file 然后git commit，再push 对于工作区、暂存区、本地仓库代码的差异比较 diff 用于对比差异 git diff 默认用于比较工作区和暂存区之间的差异 git diff –cached 和git diff –staged比较暂存区和本地仓库的差异 git diff HEAD 是工作区与本地仓库的差异 查看帮助 git merge –help 或者git help merge 对于分支相关的操作 git branch 查看所有分支 git branch -v 查看所有分支详细信息 git branch branchname 新建分支 git branch -d branchname 删除分支 git checkout branchname 切换分支 git checkout -b branchname 创建新分支并切换到新分支 git checkout – filename 把工作区的修改撤销，还原到修改前的暂存区的文件的内容（如果修改前已经add到暂存区），或者还原到本地仓库的文件的内容（修改前没有add到暂存区）。即把暂存区或者本地仓库的最近一次的提交检出到工作区使文件的更改撤销，让文件回到最后一次add或commit的状态。 git checkout versionid filename 可以将工作区某个文件还原到指定版本的那个文件的内容 具体场景： 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，可以分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 在Git中，用HEAD表示当前版本，也就是最新的commit的那个版本。上一个版本就是HEAD^，上上一个版本就是HEAD^^。也可以用数字HEAD～，HEAD～2 关于reset的几个参数 git reset –mixed HEAD～ 将HEAD指针指向上一个版本，同时将本地仓库改变后的HEAD的指向的内容覆盖到暂存区 git reset HEAD～ 同上，默认是–mixed git reset –hard HEAD～ 将HEAD指针指向上一个版本，同时将本地仓库HEAD的指向的内容同时覆盖到暂存区和工作区 git reset –soft HEAD～ 只将本地仓库的HEAD指针指向上一个版本，其他不做改变。 对于回滚来说： reset是针对的commit级别的操作，移动HEAD指针，同时可能会影响到暂存区和工作区 checkout改变的是工作区的内容，reset改变的可能是工作区、暂存区和HEAD指针的内容 git revert versionid 来使本地仓库的内容回到指定的版本内容。与reset的不同是，如果reset要回到以前的某个版本，则HEAD指针移到指定的版本的位置，此后的commit则不显示在git log里面了。而revert则是把它当做一次commit，即把工作区的内容修改成指定版本的内容然后add和commit了。 git cherry-pick versionid 经常用于将某个分支上的某次commit合并到master上，而分支的其他commit暂时不合并。（比如修复bug的commit） git merge和git rebase 两者最终结果相似，都是将分支合并，不过合并过程和方式不同。 上图：执行git merge master，把master分支合并到dev分支上 若是执行git rebase，就会将原来dev的两次提交d和e添加到master分支后面，变成d‘和e’。若有冲突的话，修改后使用git add 和git rebase –continue即可。过程中任何时候可以使用git rebase –abort来终止rebase操作回到原来的状态 其余还有一些命令，比如git log、git config等等，不写了。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习的图像风格转换]]></title>
    <url>%2F2017%2F06%2F21%2F%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[距离上次写博客已经好久好久好久了，真是懈怠的生活节奏，整天混吃等死玩游戏，前些日子做毕业设计时总算又学了点新东西。学了一点深度学习和卷积神经网络的知识，附带着详细学习了一下前段时间我觉得比较有意思的图像风格转换。毕竟是初学，顺便把神经网络方面的知识也写在前面了，便于理解。若有不对的地方的话，希望指正。 主要参考的文献有 《A Neural Algorithm of Artistic Style》 和 《Perceptual Losses for Real-Time Style Transfer and Super-Resolution》 这两篇论文，以及 深度学习实践：使用Tensorflow实现快速风格迁移 等文章，代码参考了 OlavHN /fast-neural-style 和 hzy46/fast-neural-style-tensorflow 等大神的。 先说一下卷积神经网络。卷积神经网络（ CNN）是一种前馈神经网络，了解机器学习中人工神经网络的话应该对这个概念不陌生。神经网络中的感知器模型如下图所示。 输入神经元与其各自权重相乘再相加得到z，利用激活函数g(z)进行变换得到神经元y。输入层神经元与其权重相乘再相加的过程可以用矩阵相乘相乘来表示，这点在下面的卷及神经网络里可以看到。神经网络里输入层和输出层中间的是隐藏层。 在卷积神经网络里，网络结构一般是由多个卷积层、非线性化层、池化层以及最后的全连接层组成。卷积层对输入进行卷积计算，得到的结果经过非线性化层的激活函数，再经过池化层进行采样，最后是全连接层。 先介绍卷积操作。假设输入图片是二维矩阵，每个像素值都是输入层的一个神经元，权值也用矩阵来表示，这个权值矩阵叫做卷积核，也可以成为滤波器，卷积核代表了你看这个图像时的感受野。不过卷积核是与输入图片的二维矩阵滑动计算的，这里涉及到了权值共享的问题。计算的过程如下图所示。 图中黄色部分为3x3卷积核，绿色的为5x5输入矩阵。卷积核在输入矩阵上滑动计算，每次都计算相应位置的乘积再相加，得到卷积后的矩阵中的新的元素。每次滑动的一格代表步长(stride)为1，也可以为其它值。然后再对右面矩阵的每一个得到的元素的值通过激励函数进行非线性化处理，一般是用的ReLU函数。如下图所示。 池化层进行下采样，目的是减小特征图，池化规模一般为2×2。常用的池化方法之一是最大池化（Max Pooling）,即取4个点的最大值，如下图所示，非常简单。 卷积神经网络通过这样可以不断提取图像的不同层次的特征图，然后用于分类问题等等。关于卷积神经网络的详细解释可以参考 卷积神经网络全面解析 和 卷积神经网络的理解 这两篇文章，这里就不多作解释了。下面进入正题，图像风格转换的原理。 图像风格转换 以目前的深度学习技术，如果给定两张图像，完全有能力让计算机识别出图像具体内容。而图像的风格是一种很抽象的东西，人眼能够很有效地的辨别出不同画家不同流派绘画的风格，而在计算机的眼中，本质上就是一些像素，多层网络的实质其实就是找出更复杂、更内在的特性(features)，所以图像的风格理论上可以通过多层网络来提取图像里面可能含有的一些有意思的特征。 根据前面第一篇论文中提出的方法， 风格迁移的速度非常慢的。在风格迁移过程中，把生成图片的过程当做一个“训练”的过程。每生成一张图片，都相当于要训练一次模型，这中间可能会迭代几百几千次。从头训练一个模型相对于执行一个已经训练好的模型来说相当费时。现在根据前面第二篇论文提出的另一种模型，使得把生成图片当做一个“执行”的过程，而不是一个“训练”的过程。 快速风格迁移的网络结构包含两个部分。一个是“ 生成网络 ”（Image Transform Net），一个是“ 损失网络 ”（Loss Network）。生成网络输入层接收一个输入图片，最终输出层输出也是一张图片（即风格转换后的结果）。模型总体分为两个阶段，训练阶段和执行阶段。模型如图所示。 其中左侧是生成网络，右侧为损失网络。 训练阶段：选定一张风格图片。训练过程中，将数据集中的图片输入网络，生成网络生成结果图片y，损失网络提取图像的特征图，将生成图片y分别与目标风格图片ys和目标输入图片（内容图片）yc做损失计算，根据损失值来调整生成网络的权值，通过最小化损失值来达到目标效果。 执行阶段：给定一张图片，将其输入已经训练好的生成网络，输出这张图片风格转换后的结果。 生成网络 对于生成网络，本质上是一个卷积神经网络，这里的生成网络是一个深度残差网络，不用任何的池化层，取而代之的是用步幅卷积或微步幅卷积做网络内的上采样或者下采样。这里的神经网络有五个残差块组成。除了最末的输出层以外，所有的非残差卷积层都跟着一个空间性的instance-normalization，和RELU的非线性层， instance-normalization 正则化是用来防止过拟合的。 最末层使用一个缩放的Tanh来确保输出图像的像素在[0,255]之间。除开第一个和最后一个层用9x9的卷积核(kernel)，其他所有卷积层都用3x3的卷积核。 损失网络 损失网络φ是能定义一个内容损失(content loss)和一个风格损失(style loss)，分别衡量内容和风格上的差距。对于每一张输入的图片x我们有一个内容目标yc一个风格目标ys，对于风格转换，内容目标yc是输入图像x，输出图像y，应该把风格ys结合到内容x=yc上。系统为每一个目标风格训练一个网络。 为了明确逐像素损失函数的缺点，并确保所用到的损失函数能更好的衡量图片感知及语义上的差距，需要使用一个预先训练好用于图像分类的CNN，这个CNN已经学会感知和语义信息编码，这正是图像风格转换系统的损失函数中需要做的。所以使用了一个预训练好用于图像分类的网络φ，来定义系统的损失函数。之后使用同样是深度卷积网络的损失函数来训练我们的深度卷积转换网络。 这里的损失网络虽然也是卷积神经网络(CNN)，但是参数不做更新，只用来做内容损失和风格损失的计算，训练更新的是前面的生成网络的权值参数。所以从整个网络结构上来看输入图像通过生成网络得到转换的图像，然后计算对应的损失，整个网络通过最小化这个损失去不断更新前面的生成网络权值。 感知损失 对于求损失的过程，不用逐像素求差构造损失函数，转而使用感知损失函数，从预训练好的损失网络中提取高级特征。在训练的过程中，感知损失函数比逐像素损失函数更适合用来衡量图像之间的相似程度。 （1）内容损失 上面提到的论文中设计了两个感知损失函数，用来衡量两张图片之间高级的感知及语义差别。内容的损失计算用VGG计算来高级特征（内容）表示，因为VGG模型本来是用于图像分类的，所以一个训练好的VGG模型可以有效的提取图像的高级特征（内容）。计算的公式如下： 找到一个图像 y使较低的层的特征损失最小，往往能产生在视觉上和 y不太能区分的图像，如果用高层来重建，内容和全局结构会被保留，但是颜色纹理和精确的形状不复存在。用一个特征损失来训练我们的图像转换网络能让输出非常接近目标图像 y，但并不是让他们做到完全的匹配 （2）风格损失 内容损失惩罚了输出的图像（当它偏离了目标y时），所以同样的，我们也希望对输出的图像去惩罚风格上的偏离：颜色，纹理，共同的模式，等方面。为了达成这样的效果，一些研究人员等人提出了一种风格重建的损失函数：让φj(x)代表网络φ的第j层，输入是x。特征图谱的形状就是Cj x Hj x Wj、定义矩阵Gj(x)为Cj x Cj矩阵（特征矩阵）其中的元素来自于： 如果把φj(x)理解成一个Cj维度的特征，每个特征的尺寸是Hj x Wj，那么上式左边Gj(x)就是与Cj维的非中心的协方差成比例。每一个网格位置都可以当做一个独立的样本。这因此能抓住是哪个特征能带动其他的信息。梯度矩阵可以很高效的计算，通过调整φj(x)的形状为一个矩阵ψ，形状为Cj x HjWj，然后Gj(x)就是ψψT/CjHjWj。风格重建的损失是定义的很好的，甚至当输出和目标有不同的尺寸是，因为有了梯度矩阵，所以两者会被调整到相同的形状。 具体实现 GitHub地址 mrxlz/ImageStyleTransform ，实现基本上参考了 hzy 的代码，代码从原版迁移到了python3.5，TensorFlow1.0，具体实现代码基本没变，加了一些注释，添加了一个web页面，效果如下。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校招碎碎念]]></title>
    <url>%2F2016%2F10%2F25%2F%E6%A0%A1%E6%8B%9B%E7%A2%8E%E7%A2%8E%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[前两天拿了去哪儿(Qunar)的offer，不打算接着找了，心累，结束我的校招生涯吧，写写这段时间的经历。 本科生一只，普通一本，非211/985学校，出了省就没人认那种，计算机专业，目前大四。找工作大概从大三下学期开始吧，那时候各大厂开始招实习，接着陆陆续续的有七八月份的内推，九、十月份的校招，一路面试过来，跪了一路。个人是做Java开发的，做过爬虫，做过Web，学过一点机器学习算法，然后就踏上了找工作的不归路。 找实习的时候内推了几个公司，不过不多，只面了阿里和美团。心酸的面试经历就从这里开始了。 阿里实习内推面，先是简历面，挂了。面试就随便问问简历，问问个人情况，看什么书，学习涉及到哪些领域啊之类的，人生中第一次面试，也不懂什么面试技巧，跟面试官瞎侃，然后简历面就挂了，不开心。后来还有一次校招内推面试，下面会提到。 然后是美团实习内推面，电话面，一面就挂了。面试官不错，加了微信，用的微信打过来聊的。问了Java源码，HashMap的实现，问题比较细，实现方式，还有插入的时候是插入到链表的哪个位置，扩容是在插入前还是插入后，加载因子什么作用，默认长度和加载因子是多少。然后问到如果重写compareTo()方法或实现Comparator接口要遵循什么，就是自反性对称性传递性一致性这些，主要是为了问Jdk中集合类的排序用什么方法。Jdk1.7的实现方案由归并排序改成TimSort了，如果被比较的类实现的比较器不能严格遵守自反性对称性传递性一致性这些原则，原来在jdk.6中运行正常的代码在升级到Jdk1.7中、后会出问题，所以说面试点主要在这里，估计是面试官踩过这坑。当然，这些东西，当时的我是一点都不知道的。又问到虚拟机调优，用到过什么工具，又问了一道算法题，对有序数组中找出和为给定值的两个数，比较简单。又问到用命令在linux中找出某文件中多行数据中重复次数排前几的数据。问到项目，爬虫的url去重问题，bloom filter原理，项目中的测试，等等，最后又聊了聊机器学习算法，MapReduce，PageRank算法，以及一些其他的，给了我一些建议，面试官很nice。 有了这两次面试经历之后，查缺补漏，哦，不对，应该算是女娲补天了，认真补了补各种知识，然而大厂的实习已经过去了。 所以后来暑假七八月份只能去了海尔某部门实习做后台开发。这期间差不多就是各大厂的校招内推时间，又是一波内推。这段时间其实也蛮无奈的，各厂都内推了一遍，最后得到面试机会的只有阿里和网易。 先是阿里内推的面试，面完hr之后挂了，内推了简历两天后，上午正在公司写代码，接到了阿里的面试电话，没想会到这么快。面试官上来问我知道Dubbo框架么，然后问到Hadoop，又问到数据库的一些知识，问到了丢失修改的解决方案，悲观锁或者乐观锁，我数据库一直很弱，当时没答出来。然后又问到我的项目，还是bloom filter，还有一个web项目，遇到什么问题，或者说有什么比较有创意的想法blabla….接着问到缓存啊，反向代理啊，以及分布式环境中怎么保证同一个用户多次请求，每次都能访问到它的session，解决方案是用一个缓存服务器来专门存储session，或者是用反向代理根据客户端的ip把请求交给相同的服务器来处理。框架方面问到了Spring的FactoryBean和BeanFactory，还问了什么记不清了，时间久了，最后让我问问题，我就问他那个防止丢失修改用什么解决方案，他也没直说，一步一步提示我，最后还是我自己给出了版本号方式的乐观锁解决方案。 本来对一面是不抱什么希望的，结果晚上就接到阿里二面的电话，吓死了好吗，怎么会这么快！二面应该是总监级别的，面试的时候总是乐呵呵的，但是分析总结能力极强。面试问到的多是一些安全相关的，问到了项目，遇到过什么反爬虫策略，还聊到淘宝会根据用户的行为轨迹来判断是不是爬虫，问到网络的几层模型，http和https，怎么加密的，公钥从哪来，还有项目中怎么防止sql注入。中间有问到在倒计时抢购时怎样保证客户端与服务器时间同步做到所有客户端公平，主要是用到了NTP协议。大体就这么多吧，当时以为gg了，没想到过了一段时间竟然接到了hr面的预约。阿里的hr面真的不想多谈，传说中的闻味官，第一次面到hr面，面试的感觉真是….如鲠在喉，很不爽。妥妥的，最后挂了。校招笔试没过，阿里的校招个人页面，笔试面试的记录，列的满满的全是Rejected。 然后是网易的面试，跑杭州去面的，顺便再杭州玩了两天，止步二面。一面面试官挺好，问到java内存模型，运行时数据区，辣鸡回收，volatil关键字的可见性以及是否线程安全，并发包，concurrentHashMap原理，synchronized底层实现，Redis数据类型，Spring框架源码，BeanFactory，ApplicationContext，AOP原理，动态代理，Spring事务原理Mybatis中#和$的区别。还问到了一些架构问题和高并发问题，限量抢购时怎么保证不超卖，给出四种解决方案，分别是悲观锁、乐观锁、队列、分布式文件锁，怎样防止服务器雪崩现象，可以采用快速失败。一面过程中聊得很愉快，虽然有些东西没答出来，还是给了机会二面。 二面就不爽了，主要是因为面试官似乎不怎么爱聊，态度很冷淡。去找面试官的时候正巧还有个同学跑去问他为什么二面把他给挂了。面试内容其实还不如一面难，问题主要都是一面中问到过的一些问题，没聊多久就结束了。最后前台hr告诉说面试没过。在杭州又玩了一天半，回青岛继续做码农。 一直到九月份，都没有任何内推面试，其他公司简历都没过，只能校招了。 校招也是跪了一路，先是京东，笔试过了之后去北京面试，中秋前面完技术面，中秋过后回学校hr电面。面试过程一直很轻松愉快，问题也没有跑出以前面试被问到的范围，然后我就安心等通知了，等到10月中旬，终于等到了…拒信。老实讲对京东蛮无语的。 面过京东后又做了n多笔试，一周之后收到了百度的面试通知，又赶去北京面试。一天面完，三面技术面，没有hr面。一面Java面试官，先是让手撸个快排，撸完之后拿过几张纸，上面都是题，让我一个一个指着说答案，有linux下各种操作和权限的问题，还有java基础的一些东西，一不小心就踩了很多坑。接着问设计模式，问到责任链设计模式，设计模式的六大原则，开闭原则是什么，问到项目等等，还有一些根据项目拓展的设计题，答的并不好，结果一面就过了，等了一会二面，结果是个c艹面试官，然后就是各种智力题各种手写代码，手写socket通信，写sql，聊项目，答得也不算好，面试官给个面子让过了，有幸来到了三面。好吧，三面又是个c艹面试官，以为不谈基础，结果上来就让我写了个链表奇偶位置交换的算法，然后对着我的代码拿样例一行一行的测试，卧槽。接着是个在数据中找有两个只出现一次的数的算法，又问了两个智力题，聊了聊项目，谈谈个人规划，目前怎么做的，平时怎么学习，等等，然后就回去了。至今仍未给消息，想必已经妥妥挂掉了。 百度面完已经是九月末了，就回家了。正巧又接到北京某IT教育公司的面试预约，回到家视频面了两面，轻松拿到offer，不过薪资略低，再加上岗位跟我方向不对路，没打算去，但也没立刻回绝，算是拿到的第一个offer吧。 其后投简历一直投的是一些银行证券或者金融类的科技公司，因为个人以后想做机器学习偏金融方向。做了n多笔试题，结果还是杳无音信。期间也拿到了几个面试机会，魅族，YY，华数，不过因为时间关系或者薪资太低就没去。最后意料之外的接到了去哪儿的面试邀请，第二天就坐车去北京面了，去的时候信心满满，也顺利拿到了offer。 一面又是c艹面试官，不过这次算是与c艹面试官聊得相当不错的一次了，问了道算法题，我说了思路，他貌似没太懂，就接着问了。问到设计模式，手写一个代理模式，什么是死锁，手写一个死锁例子，问到tcp，udp，握手挥手差错处理等一些老掉牙的问题，让我解释一下JVM的内存管理，辣鸡回收，运行时数据区，Java里面怎么解决的引用计数法中引用成环导致的内存泄漏，主要是因为Hotspot采用的是可达性分析算法，只要不可达，形成环也会也会被回收。问了一些项目的问题，最后就把我领到hr那里等二面了。 二面是个金融部门leader，先是问了一些机器学习的算法，又让我讲一下最熟悉的算法，就跟他简单聊了下推荐算法。问了下Object中有哪些方法，问了道算法题，然后是关于网络的问题，迅雷的浏览器在相同带宽下谁下载的快，为什么。我说迅雷下载的快，因为是P2P，面试官说不考虑P2P的话，其实是因为迅雷采用的多线程，而浏览器采用的是单线程下载，又让我解释一下为什么这样会下载的比较快。我说每个线程与服务器建立一条链接，而服务器对待每个连接都是平等的，所以迅雷多线程更快。然后他居然捏着下巴沉思夸道”平等”这个用的非常好，你是怎么想到这个词的呢？，我表示很无奈，不知道是不是这个拉高了面试的印象分。又问了些Java内存管理，运行时数据区，辣鸡回收，堆区的分区设计的原理。最后我问了他一堆问题，就让我去等着hr面了。 这时候已经基本算是拿到offer了，在去哪儿只要面到hr，基本都会现场发offer。等了会就到了hr面，聊的过程很愉快，hr很nice，不像阿里的hr，一趟面下来让人生厌。谈了谈各方面的东西，问了我期望薪资之后就直接把offer甩给我了，然后我问了不少问题了解公司情况，走的时候送了我一只小骆驼手办。 回去的路上想了想，薪资还可以接受，暂且决定去哪儿了，结束校招生涯。一路走来虽然面的公司不多，但是苦等不到面试机会也是难熬，面完之后等不到offer更是难熬，有段时间每天睡觉都睡不好，夜里做各种关于offer的梦，患得患失，白天精神状态也是奇差。也许是因为学校和学历的原因，两三个月以来饱尝挫败，不过毕竟大学是自己考的，没考到一个好的大学只怪当初自己不努力，人总要为自己的行为买单，现在或以后。过两天回学校拿三方，我的校招生涯告一段落。新的生活开始了。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈对Spring Framework的认识]]></title>
    <url>%2F2016%2F09%2F17%2F%E6%B5%85%E8%B0%88%E5%AF%B9Spring%20Framework%E7%9A%84%E8%AE%A4%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Spring Framework，作为一个应用框架，官方的介绍如下： The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. A key element of Spring is infrastructural support at the application level: Spring focuses on the “plumbing” of enterprise applications so that teams can focus on application-level business logic, without unnecessary ties to specific deployment environments. 在开发中，Spring框架从程序员手中接管了对象的创建，Spring根据配置文件或者扫描注解，得到类、组件之间的关系，并创建对象进行注入，这个过程不需要程序员手动创建并赋值，从而降低了耦合性，开发的时候也不需要理会这些与功能代码实现无关的部分，这就是DI/IOC(依赖注入/控制反转)。基于DI/IOC，Spring框架的不同模块提供了各种功能，为应用提供了AOP功能、持久层的支持，为Web层提供了SpringMVC以及与其他框架的整合使用等等。 (这特么不是上面的翻译啊啊啊) 这段时间正在学习Spring源码，浅谈一下我对Spring的认识。参考资料主要为Spring官方文档、《深入分析Java Web技术内幕》《Spring源码深度解析》，部分内容借鉴书中原文。 Spring中的主要组件如图： Spring中的核心容器中有四个部分，核心组件是其中的Beans、Core和Context组件，至于SpEL不太了解o(￣▽￣)o 。如果没有Core Container核心容器的支持，就不会有上层的AOP、Web等特性功能。 三个组件中，Beans组件可以说是比较核心的，Spring框架将对象之间的依赖关系转用配置文件、注解来配置，注入关系通过IOC容器来管理，而IOC容器中管理的实体就是被Bean包裹的对象。Bean就是被包装之后的Java对象，由Spring框架创建和维护。 Context组件是Bean的上下文，是Bean的生存环境，用于建立和维护Bean之间的关系，所以说Context其实是Bean关系的集合，这个关系的集合就叫做IOC容器。 而Core组件，就是发现、建立、维护Bean之间的关系所需要的一系列的工具类(Util)。 一、Beans组件 Beans组件主要解决了Bean的定义、创建和解析，实现在org.springframework.beans包中。 Bean的创建是典型的工厂模式，顶级接口是BeanFactory，简单的继承层次如下： BeanFactory有三个子类接口，ListableBeanFactory(可列表的)、HierarchicalBeanFactory(可继承的)、AutowireCapableBeanFactory(可自动装备的)，三者分别有不同的使用场合，而BeanFactory的默认实现类是DefaultListableBeanFactory，它实现了所有的接口。 Bean的定义主要由BeanDefinition描述。当Spring对配置文件中的Bean进行成功解析或者对注解的Bean解析完成后，其在Spring内部转换成BeanDefinition对象，此后所有的操作都是对这个对象进行的。UML图如下： Bean的解析比较复杂，主要有对配置文件的解析和对注解的解析，配置文件解析过程主要由以下类完成： 二、Context组件 Context组件提供Spring的一个运行时环境，在org.springframework.context包实现。ApplicationContext是Context的顶级接口，它继承了六个接口，主要是扩展了Context： 可以看出，ApplicationContext继承了BeanFactory，使得其有创建Bean的功能，这也间接说明了Spring容器中运行的实体是Bean。ApplicationContext继承了ResourceLoader 接口，意味着ApplicationContext可以访问外部资源。 ApplicationContext两个子类接口分别是ConfigurableApplicationContext和WebApplicationContext，根据字面意思便可理解其用途。 一般来说，ApplicationContext有一下几个作用： 1.标识一个应用环境 2.利用BeanFactory创建Bean对象 3.保存对象关系表 4.能捕获各种事件 Context作为Spring的IOC容器，整合了Spring的大部分功能的基础。 三、Core组件 Core组件提供了很多比较重要的关键类，比如资源的访问。这里暂时不想写了，留坑以后填。 写累了，下篇再接着写IOC容器的工作过程吧，BeanFactory的创建过程、Bean及其关系网的创建、IOC容器的扩展点等等。洗洗睡了(:зゝ∠) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Web框架</category>
      </categories>
      <tags>
        <tag>Web框架</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-70-Climbing Stairs]]></title>
    <url>%2F2016%2F06%2F24%2FLeetCode-70-Climbing%20Stairs%2F</url>
    <content type="text"><![CDATA[You are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? 题意：爬台阶问题。每次能爬一个或两个台阶，问一个有n个台阶的话，一共有几种方法爬到顶端。 思路： n&lt;=1，此时只有一种。 n&gt;1时，对于每一个台阶i，要到达台阶，最后一步都有两种方法，从i-1迈一步，或从i-2迈两步。 也就是说到达台阶i的方法数=达台阶i-1的方法数+达台阶i-2的方法数。所以该问题是个DP问题。 d(0) = 1 d(1) = 1 d(2) = d(2-1) + d(2-2) d(3) = d(3-1) + d(3-2) …… 好吧，状态转移方程其实就是Fibonacci数列。 代码实现给出两种方案吧： python代码如下： class Solution(object): def climbStairs(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n&lt;=1: return 1 res = [] res.append(1) res.append(1) for i in range(2,n+1): res.append(res[-1]+res[-2]) return res[-1] Java代码如下： public class Solution { public int climbStairs(int n) { if (n&lt;=1) return 1; int oneStep=1,twoStep = 1,res = 0; for (int i = 2; i &lt;= n; i++) { res = oneStep + twoStep; twoStep = oneStep; oneStep = res; } return res; } } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-66-Plus One]]></title>
    <url>%2F2016%2F06%2F24%2FLeetCode-66-Plus%20One%2F</url>
    <content type="text"><![CDATA[Given a non-negative number represented as an array of digits, plus one to the number. The digits are stored such that the most significant digit is at the head of the list. 题意：给定一个由数组表示的数字，加上一，返回由数组表示的结果 思路： 参考Discuss的解法，对于每一位来说，只有等于9的时候才会进位，小于就的时候，数值加一然后返回本数组即可。 如果最后数值进位后恰好比原值多一位，则直接new一个数组，默认值为0，赋值最高位为1，返回即可。 Java代码如下： public class Solution { public int[] plusOne(int[] digits) { if (digits.length==0) return digits; for (int i = digits.length -1; i&gt;=0;i--) { if (digits[i] &lt; 9) { digits[i]++; return digits; } digits[i] = 0; } int[] res = new int[digits.length+1]; res[0] = 1; return res; } } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-62-Unique Paths]]></title>
    <url>%2F2016%2F06%2F23%2FLeetCode-62-Unique%20Paths%2F</url>
    <content type="text"><![CDATA[A robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below). The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below). How many possible unique paths are there? Above is a 3 x 7 grid. How many possible unique paths are there? 题意：就是一个m*n的棋盘的上，从一个位置到另一位置的最短路径的个数。每次只能向下或向右走一步。 思路： 其实就是个高中的组合数学的问题。 m*n的棋盘，一共需要走(m-1)+(n-1)步，向右走m-1步，向下走n-1步，这(m-1)+(n-1)步中，只要确定了哪些步向右，即同时确定了哪些步向下走，反之亦然。 答案即C(m+n-2,m-1)或C(m+n-2,n-1) Java代码如下： public class Solution { public int uniquePaths(int m, int n) { double res = 1; for (int i = 1; i &lt;= n - 1; i++) res *= ((double) (m + i - 1) / (double) i); return (int) Math.round(res); } } 提交结果： 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-53-Maximum Subarray]]></title>
    <url>%2F2016%2F06%2F22%2FLeetCode-53-Maximum%20Subarray%2F</url>
    <content type="text"><![CDATA[Find the contiguous subarray within an array (containing at least one number) which has the largest sum. For example, given the array [−2,1,−3,4,−1,2,1,−5,4] ,the contiguous subarray [4,−1,2,1] has the largest sum = 6 . 题意：就是求最大字数组和。 思路： DP问题，O(n)内可破 对于位置arr[0]~arr[i]，最大字数组和 arr[0] i==0 maxSum[i]= max{ maxSum[i-1]+ arr[i] , arr[i] } 0&lt;i&lt;arr.length 具体来说该题没必要采用maxSum数组，用一个变量记住最大字数组和即可。 Java代码如下： public class Solution { public int maxSubArray(int[] nums) { int max = nums[0],maxEndingHere = nums[0]; for (int i = 1; i &lt; nums.length; i++) { maxEndingHere = Math.max(maxEndingHere+nums[i],nums[i]); max = Math.max(maxEndingHere,max); } return max; } } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-15-3Sum]]></title>
    <url>%2F2016%2F06%2F22%2FLeetCode-15-3Sum%2F</url>
    <content type="text"><![CDATA[Given an array S of n integers, are there elements a , b , c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Note: The solution set must not contain duplicate triplets. For example, given array S = [-1, 0, 1, 2, -1, -4], A solution set is: [ [-1, 0, 1], [-1, -1, 2] ] 题意：找到给定数组中的所有的和为0的三个数的组合，而且结果不允许重复。 思路： 首先将给定序列排序，用于后面的查找 每一组解有三个数，所以遍历给定序列的时候，设置三个索引：left,mid和right。 初始left=0, 对于 left from 0 to length-1: mid=left+1,rigth=序列长度length-1 当mid&lt;rigth时： 根据三者对应位置的值的和sum=arr[left]+arr[mid]+arr[rigth]来判断： sum&gt;0:则right左移 sum&lt;0:则mid右移 sum==0:记录下来，right左移；mid右移 python代码实现： class Solution(object): def threeSum(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[List[int]] &quot;&quot;&quot; result = [] left = 0 nums.sort() length = len(nums) while left &lt; length - 2: mid = left + 1 right = length - 1 while mid &lt; right: if nums[left] + nums[mid] + nums[right] &gt; 0: right -= 1 elif nums[left] + nums[mid] + nums[right] &lt; 0: mid += 1 else: result.append([nums[left], nums[mid], nums[right]]) mid += 1 right -= 1 while mid &lt; right and nums[mid] == nums[mid - 1]: mid += 1 while mid &lt; right and nums[right] == nums[right + 1]: right -= 1 left += 1 while left &lt; length - 2 and nums[left] == nums[left - 1]: left += 1 return result 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-9-Palindrome Number]]></title>
    <url>%2F2016%2F06%2F22%2FLeetCode-9-Palindrome%20Number%2F</url>
    <content type="text"><![CDATA[Determine whether an integer is a palindrome. Do this without extra space. 判断一个整数是否是回文数。 思路：求出数字abcd的逆序的数值dcba，如果是回文数的话，那么abcd==dcba。 时间复杂度:O(n) python代码： class Solution(object): def isPalindrome(self, x): &quot;&quot;&quot; :type x: int :rtype: bool &quot;&quot;&quot; temp = x revert_x = 0 while temp &gt; 0: revert_x = revert_x*10 + temp % 10 temp //= 10 return revert_x == x 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-1- Two Sum]]></title>
    <url>%2F2016%2F06%2F22%2FLeetCode-1-%20Two%20Sum%2F</url>
    <content type="text"><![CDATA[Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9, return [0, 1]. 简言之，查找给定数组内两个数，使得两数和为给定的target 思路： 遍历给定数组，用一个哈希表存放已经遍历过的值，key是nums中的值，value是其位置索引。 对于当前遍历的nums[i]，查找哈希表中是否存在target-nums[i]，若存在，则返回二者索引，否则将(key=nums[i],value=i)放入哈希表中，继续遍历 时间复杂度：O(n) python代码如下，已AC: class Solution(object): def twoSum(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: List[int] &quot;&quot;&quot; dictMap = {} for index, value in enumerate(nums): if target - value in dictMap: return [dictMap[target - value] , index ] dictMap[value] = index 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Struts2]]></title>
    <url>%2F2016%2F05%2F11%2F%E6%B5%85%E8%B0%88Struts2%2F</url>
    <content type="text"><![CDATA[学过SSH框架很长一段时间了，一直没有很系统的总结一下，这里先简单谈谈Struts2。 为什么要用Struts2？ 这里列举一些 Servlet的缺点 ： 1、每写一个servlet在web.xml中都要做相应的配置。如果有多很servlet，会导致web.xml内容过于繁多。 2、这样的结构不利于分组开发。 3、在servlet中，doGet方法和doPost方法有HttpServletRequest和HttpServletResponse参数。这两个参数与容器相关，如果想在servlet中作单元测试，则必须初始化这两个参数。 4、如果一个servlet中有很多个方法，则必须采用传递参数的形式，分解到每一个方法中。 而而而而而而而而而而。。。。先了解一下Struts2是什么。 Struts2是一个遵循MVC的Web层框架。 先看一下基于Web的 MVC三层架构： 这是一个MVC三层架构的基本模式，三层架构中的显示层这里是B/S结构的Web应用。而MVC就是 Model、View、Controller 。 说好的Struts2是一个Web层的MVC框架呢？在Struts2中MVC是什么呢？ Struts2利用过滤器，拦截客户端的请求。客户端发送请求，经过struts2的过滤器，将HttpServletRequest参数和HttpServletResponse参数封装，利用java反射机制将请求分派给映射的Action。根据Action的执行结果，转向其他Action或jsp页面 Struts2 的Action实现了与Servlet API的解耦，使得在Action里面不需要再直接去引用和使用HttpServletRequest与HttpServletResponse等接口。因而使得Action的单元测试更加简单，而且强大的类型转换也使得我们少做了很多重复的工作。 下面看一下Struts2的原理图： 具体过程大致如下： 1、客户端向Servlet容器（例如Tomcat）发送请求 2、这个请求经过一系列的过滤器（Filter） 3、接着FilterDispatcher（现已过时）被调用，FilterDispatcher询问ActionMapper来决定这个请是否需要调用某个Action 4、如果ActionMapper决定需要调用某个Action，FilterDispatcher把请求的处理交给ActionProxy 5、ActionProxy通过Configuration Manager询问框架的配置文件，找到需要调用的Action类 6、ActionProxy创建一个ActionInvocation的实例。 7、ActionInvocation实例使用命名模式来调用，在调用Action的过程前后，涉及到相关拦截器（Intercepter）的调用。(此处采用了AOP，一系列的拦截器即通知，Action的方法为切入点) 8、Action执行完毕，ActionInvocation负责根据struts.xml中的配置找到对应的返回结果。返回结果通常是（但不总是，也可 能是另外的一个Action链）一个需要被表示的JSP或者FreeMarker的模版。在表示的过程中可以使用Struts2 框架中继承的标签。在这个过程中需要涉及到ActionMapper 在上述过程中所有的对象（Action，Results，Interceptors，等）都是通过ObjectFactory来创建的。 FilterDispatcher是早期struts2的过滤器，2.1.3后使用StrutsPrepareAndExecuteFilter。StrutsPrepareAndExecuteFilter，prepare进行配制的导入；execute表示进行过滤，指doFilter方法，即将request请求，转发给对应的 action去处理。 上面是Struts2的基本原理，下面看一下Struts2使用主要涉及的几个方面： 拦截器，验证，类型转换，属性驱动、模型驱动，OGNL 。 拦截器 Struts2自带的拦截器有35个之多。例如：输入验证是由名为validation拦截器处理的，如果禁用该拦截器，输入验证将停止工作；文件上传依靠名为fileUpload的拦截器。 Struts2自带的默认拦截器足以满足绝大多数的应用程序的需要，但也可以自定义拦截器。 自定义拦截器 1、编写一个类，实现com.opensymphony.xwork2.interceptor.Interceptor 2、主要实现public String intercept(ActionInvocation invocation) throws Exception{}方法 3、拦截器定义好后，要在配置文件中进行注册： &lt;interceptors&gt; &lt;interceptor name=&quot; interceptorName&quot; class=&quot;className&quot;/&gt; &lt;/interceptors&gt; 4、配置文件中的动作，通过 &lt; interceptor-ref name =” interceptorName “ &gt;&lt;/ interceptor-ref &gt; 使用该拦截器. 注意：一旦动作中使用了自定义的拦截器，那么默认的就不起作用了。一般应该采用如下的做法： &lt;interceptor-ref name=&quot;defaultStack&quot;&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name=&quot; interceptorName&quot;&gt;&lt;/interceptor-ref&gt; 多个动作类都要使用的话，可以通过package来进行组合。 验证 有时候对于从客户端传来的数据需要验证，例如登录页面，验证用户名不能为空，密码也不能为空，并且长度不能小于6位数。 验证的方法有分为以下几种： 1、编程方式 动作类中的所有方法进行验证： 步骤： a、动作类继承ActionSupport b、覆盖调用public void validate() 方法 c、在validate方法中，编写不符合要求的代码判断，并调用父类的addFieldError(String fieldName,String errorMessage) 如果 fieldError （存放错误信息的Map）有任何的元素，就是验证不通过，动作方法不会执行。Struts2框架会返回到name=input的result d、在name=input指定的页面上使用struts2的标签显示错误信息。&lt;s:fielderror/&gt; 动作类中指定的方法进行验证： 编写步骤与上面相同，验证方法书写有要求： public void validateXxx() Xxx代表的是要验证的动作方法名，其中要把动作方法名的首字母变为大写。 2、基于XML配置文件的方式 ①动作类中的所有方法进行验证： 在动作类的包中，建立一个名称为： 动作简单类名-validation.xml ，比如要验证的动作类名是UserAction UserAction-validation.xml，内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE validators PUBLIC &quot;-//OpenSymphony Group//XWork Validator 1.0.3//EN&quot; &quot;http://www.opensymphony.com/xwork/xwork-validator-1.0.3.dtd&quot;&gt; &lt;validators&gt; &lt;field name=&quot;username&quot;&gt; &lt;!-- 内置验证器都是定义好的，在xwork-core.jar com.opensymphony.xwork2.validator.validators包中的default.xml文件中 --&gt; &lt;field-validator type=&quot;requiredstring&quot;&gt;&lt;!-- 不能为null或者&quot;&quot;字符串，默认会去掉前后的空格 --&gt; &lt;message&gt;用户名不能为空&lt;/message&gt; &lt;/field-validator&gt; &lt;/field&gt; &lt;/validators&gt; ②动作类中指定的方法进行验证: 配置文件的名称书写有一定要求： 动作类名-动作名（配置文件中的动作名）-validation.xml 例如UserAction-user_add-validation.xml 3、自定义基于XML的验证器 a、编写一个类，继承FieldValidatorSupport类。 b、在public void validate(Object object)编写你的验证逻辑，不符合要求的就向fieldErrors中放消息 c、一定注册验证器才能使用 在WEB-INF/classes目录下建立一个名称为validators.xml的配置文件，内容如下： &lt;validators&gt; &lt;validator name=&quot;strongpassword&quot; class=&quot;wz.validators.StrongPasswordValidator&quot;/&gt; &lt;/validators&gt; d、日后就可以像使用Struts2提供的16个验证器方式去使用了。 属性驱动和模型驱动 属性驱动 条件： 1、页面中name的属性和action中的属性必须保持一致。 2、 Action中的属性必须有get和set方法。 3、满足这两个条件就实现了属性驱动。 过程： 1、 当执行所有的拦截器的时候，当前请求的action已经放在了对象栈栈顶。 2、 放在对象栈的对象的特点是其属性能够直接访问。 3、 也就是说当执行ParameterInterceptor拦截器的时候，action的所有的属性在栈顶。 4、 所以只需要给栈顶的action的属性赋值就可以了。 5、 而ParameterInterceptor拦截器正好完成了此功能。 模型驱动 假设在完成网站的某项功能时，在后台需要得到20多个属性。如果用action中的属性获取值，就要在action中会写20个属性以及其set和get方法。这样会导致action中的代码结构不是很好。 模型驱动很好的解决了这个问题。使用javaBean对象来封装请求参数，实现ModelDriven接口并定义模型成员域即可。 例如： public class ModelDriverAction extends ActionSupport implements ModelDriven&lt;User&gt;{ private User model = new User(); public User getModel() { return this.model; } public String execute(){ return &quot;modeldriver&quot;; } } 当浏览器提交对当前Action的请求时，先经过拦截器。其中有一个拦截器为ModelDrivenInterceptor，从这个源代码可以看出，这个拦截器的作用就是获取实现了ModelDriver接口的action的模型驱动。在这里为user。然后把模型驱动利用push方法压入到对象栈栈顶。这样就能直接通过属性进行回显和赋值了。 到底是用属性驱动和是模型驱动呢？ (1)最好统一整个系统中的Action使用的驱动模型，即要么都是用属性驱动，要么都是用模型驱动。 (2)如果DB中的持久层的对象与表单中的属性都是一一对应的话，那么就使用模型驱动，代码要整洁很多。 (3)如果表单的属性不是一一对应的话，那么就应该使用属性驱动，否则，你的系统就必须提供两个Bean，一个对应表单提交的数据，另一个用与持久层。 类型转换 从属性驱动的角度考虑，中如果属性中要求接受的不是String类型，而是其他类型呢？struts2将做自动的转化。 客户端表单的每一项输入之可能是一个String或一个String数组。在服务器端，必须先把这些String值转换为特定的数据类型，才能进行相应的处理把请求参数映射到动作属性的工作由Parameters拦截器负责，它是defaultStack拦截器栈的一员。所有的请求参数都是String类型，但并非所有的动作属性都是String类型，所以每一种非String类型的动作属性需要对相关的请求参数进行类型转换。有些Struts2可以自动转化，而有些需要我们手动编写转换的代码。 具体方式： 1、编写一个类， 继承 com.opensymphony.xwork2.conversion.impl. DefaultTypeConverter 2、覆盖掉其中的 public Object convertValue (Map&lt;String, Object&gt; context, Object value,Class toType) context： OGNL表达式的上下文value： 实际的值。用户输入的都是字符串，但他是一个String数组。toType： 目标类型 3、注册类型转换器 3.1局部类型转换器：只对当前的Action有效 具体做法：在动作类相同的包中，建立一个名称是“动作类名-conversion.properties”的配置文件，文件中增加以下内容：要验证的字段=验证器的类全名。例如：birthday=wz.convertor.DateConvertor 3.2全局类型转换器：对所有的Action都有效 具体做法：在WEB-INF/classes目录下，建立一个名称为”xwork-conversion.properties”的配置文件，文件中增加以下内容：目标类型全名=验证器的类全名。例如：java.util.Date=cn.itcast.convertor.DateConvertor 注意：如果转换失败，Struts2框架会寻找name=input的结果页面 OGNL OGNL表达式是 (Object-Graph Navigation Language) 是对象图形化导航语言。OGNL是一个开源的项目，struts2中默认使用OGNL表达式语言来显示数据。与serlvet中的el表达式的作用是一样的。 提起OGNL就不得不提ValueStack了。ValueStack是一个接口，在struts2中使用OGNL表达式实际上是使用实现了ValueStack接口的类 OgnlValueStack ,这个类是OgnlValueStack的基础。 ValueStack贯穿整个action的生命周期。每一个action实例都拥有一个ValueStack对象。其中保存了当前action对象和其他相关对象。 Struts2把ValueStack对象保存中名为struts.valueStack的request域中。 当struts接受一个请求时，会迅速创建ActionContext，ValueStack，action。然后把action存放进ValueStack，所以action的实例变量可以被OGNL访问 ActionContext.getContext()从ThreadLocal中得到本线程的ActionContext对象 actionContext 对象可以获取 context 、application、session、valueStack等对象。后三者其实是从context中取出的。 ActionContext的成员域 context 是 OgnlContext 对象，即ValueStack中的context对象 context对象中存放 request、session、application、parameters、attr 等map以及ValueStack等对象 context map与valueStack的关系： 1、context中有一个键值对，key=com.opensymphony.xwork2.util.ValueStack.ValueStack，value=valueStack，即valueStack 2、valueStack中成员域包括CompoundRoot root和OgnlCotext context;。没错，就是上面的context。 3、而ActionContext中的成员域context，就是上面的context。 下面是ActionContext中context对象的内容，注意看地址。 暂时就这么多吧。以上 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Web框架</category>
      </categories>
      <tags>
        <tag>Web框架</tag>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[探究JVM——垃圾回收]]></title>
    <url>%2F2016%2F05%2F01%2F%E6%8E%A2%E7%A9%B6JVM%E2%80%94%E2%80%94%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[垃圾回收主要考虑三件事情： 哪些内存需要回收？什么时候回收？如何回收？ 一、哪些内存需要回收？ 堆内存 ：对于JVM 来说，垃圾回收主要是针对堆内存中的对象实例。 方法区 ：垃圾收集行为在方法区是比较少出现的，一般来说，这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是必要的。 二、什么时候回收？ 在堆里面存放着Java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象之中哪些还“存活”着，哪些已经“死去”（即不可能再被任何途径使用的对象）。那么，怎么判断呢？ 引用计数算法(Reference Counting)很多教科书上给出的算法是这样的：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。 引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法，但是，至少主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。 举个栗子：看下面代码(示例代码来自《深入理解Java虚拟机》) /** *testGC（）方法执行后，objA和objB会不会被GC呢？ */ public class ReferenceCountingGC{ public Object instance=null； private static final int_1MB=1024*1024； /** *这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否被回收过 */ private byte[]bigSize=new byte[2*_1MB]； public static void testGC（）{ ReferenceCountingGC objA=new ReferenceCountingGC（）； ReferenceCountingGC objB=new ReferenceCountingGC（）； objA.instance=objB； objB.instance=objA； objA=null； objB=null； //假设在这行发生GC,objA和objB是否能被回收？ System.gc（）； } } 上述代码中的testGC（）方法：对象objA和objB都有字段instance，赋值令objA.instance=objB及objB.instance=objA，除此之外，这两个对象再无任何引用，实际上这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。 下面介绍一种算法: 可达性分析算法 #### 可达性分析算法(Reachability Analysis)在主流的商用程序语言（Java、C#等）的主流实现中，都是称通过可达性分析来判定对象是否存活的。 这个算法的基本思路就是通过一系列的称为“ GC Roots ”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为 引用链 （Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个 对象不可达 ）时，则证明此对象是不可用的。 继续举栗子,如下图所示，对象object 5、object 6、object 7虽然互相有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 那么问题就来了，即使在可达性分析算法中不可达的对象，也并非是“非死不可”的。 要真正宣告一个对象死亡，至少要经历两次标记过程： ①如果对象在进行可达性分析后发现 没有与GC Roots相连接的引用链 ，那它将会被 第一次标记 并且进行一次 筛选 ，筛选的条件是此对象 是否有必要执行finalize（） 方法： 当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。 如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。 这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize（）方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。 ②finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize（）中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。 finalize()方法应尽量避免使用，它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。 关于方法区的回收 Java虚拟机规范中不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%～95%的空间，而永久代的垃圾收集效率远低于此。 永久代的垃圾收集主要回收两部分内容： 废弃常量 和 无用的类 。 回收废弃常量与回收Java堆中的对象非常类似： 以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。 类需要同时满足下面3个条件才能算是“无用的类”： ①该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 ②加载该类的ClassLoader已经被回收。 ③该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose：class以及-XX：+TraceClassLoading、-XX：+TraceClassUnLoading查看类加载和卸载信息，其中-verbose：class和-XX：+TraceClassLoading可以在Product版的虚拟机中使用，-XX：+TraceClassUnLoading参数需要FastDebug版的虚拟机支持。 在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 三、如何回收？ 下面是几种常见的垃圾收集算法： 标记-清除算法(Mark-Sweep)最基础的收集算法，算法分为“ 标记 ”和“ 清除 ”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，(标记过程在上面对象标记判定时已经提过了)。 之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 它的主要不足有两个： ①效率问题 ，标记和清除两个过程的效率都不高； ②空间问题 ，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记—清除算法的执行过程如图所示 #### 复制算法（Copying）为了解决效率问题，一种称为“复制”的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。 复制算法的执行过程如图所示 研究表明，新生代中的对象98%是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是 将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor 。 当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 HotSpot虚拟机默认Eden和Survivor的大小比例是 8:1 ，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，“标记-整理”算法的示意图如图所示。 #### 分代收集算法当前商业虚拟机的垃圾收集都采用“ 分代收集 ”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。 一般是把Java堆分为 新生代 和 老年代 ，这样就可以根据各个年代的特点采用最适当的收集算法。 新生代中 ，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用 复制算法 ，只需要付出少量存活对象的复制成本就可以完成收集。 老年代中 ，因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“ 标记—清理 ”或者“ 标记—整理 ”算法来进行回收。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[探究JVM——运行时数据区]]></title>
    <url>%2F2016%2F04%2F30%2F%E6%8E%A2%E7%A9%B6JVM%E2%80%94%E2%80%94%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[最近在读《 深入理解Java虚拟机 》，收获颇丰，记录一下，部分内容摘自原书。 Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。Java虚拟机所管理的内存将会包括以下几个运行时数据区域，如图所示： 其中 程序计数器 、 VM栈 、 native栈 为线程隔离的， 堆(Heap) 和 方法区(Method Aera,or Non-Heap) 为线程共享的。至于常量池，自JDK 1.7的HotSpot VM后，把原本放在方法区的字符串常量池移出。 下面来一个个介绍各个区域： 1.程序计数器(Program Counter Register)程序计数器 是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。 在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“ 线程私有 ”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。此内存区域是 唯一一个 在Java虚拟机规范中 没有规定任何OutOfMemoryError 情况的区域。 2.Java虚拟机栈(Java Virtual Machine Stacks)与程序计数器一样，Java虚拟机栈也是 线程私有 的，它的生命周期与线程相同。 虚拟机栈描述的 是Java 方法执行 的内存模型 ：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 通常会认为内存区分为 堆内存 （Heap） 和 栈内存 （Stack） ，所指的“栈”就是现在讲的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 局部变量表 存放了编译期可知的各种 基本数据类型 （boolean、byte、char、short、int、float、long、double） 、 对象引用 （reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置） 和 returnAddress类型 （指向了一条字节码指令的地址） 。 其中64位长度的long和double类型的数据会占用2个局部变量空间 （Slot） ，其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 StackOverflow ：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常 OOM ：如果虚拟机栈可以 动态扩展 （当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈） ，如果扩展时无法申请到足够的内存，就会抛出 OutOfMemoryError 异常。 3.本地方法栈(Native Method Stack)与VM栈所作用非常相似，区别是VM栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。 在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 StackOverflow ：同虚拟机栈 OOM ：同虚拟机栈 以上都是线程私有的内存区域，下面是线程共享内存区域： 1.Java堆(Heap)Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。 此内存区域的唯一目的就是 存放对象实例 ，几乎所有的对象实例都在这里分配内存。对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。这一点在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。 Java堆是 垃圾收集器管理的主要区域 ，因此很多时候也被称做“GC堆”（Garbage Collected Heap）。 从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以Java堆中还可以细分为： 新生代 和 老年代 ；再细致一点的话新生代中分为 Eden空间 、 From Survivor空间、To Survivor空间 等。 从内存分配的角度来看，线程共享的Java堆中可能划分出多个 线程私有的分配缓冲区（ Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是 可扩展的 ，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 OOM ：如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 2.方法区(Method Area)用于存储已被虚拟机加载的 类信息、常量、静态变量 、即时编译器编译后的 代码 等数据。 虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆） ，目的应该是与Java堆区分开来。 永久代 ：对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区称为“永久代”（Permanent Generation），本质上两者并 不等价 ，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。对于其他虚拟机（如BEA JRockit、IBM J9等）来说是 不存在永久代 的概念的。 根据官方发布的路线图信息，现在也有放弃永久代并逐步改为采用Native Memory来实现方法区的规划了，在目前已经发布的JDK 1.7的HotSpot中，已经把原本放在永久代的字符串常量池移出。 方法区和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是必要的。 OOM ：根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 3.运行时常量池(Runtime Constant Pool)运行时常量池是 方法区的一部分 。 Class文件中 除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是 常量池 （Constant Pool Table），用于存放编译期生成的 各种字面量和符号引用 ，这部分内容将在类加载后进入方法区的运行时常量池中存放。 Java虚拟机对Class文件每一部分（自然也包括常量池）的格式都有严格规定，每一个字节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行，但对于运行时常量池，不同的提供商实现的虚拟机可以按照自己的需要来实现这个内存区域。不过，一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。 运行时常量池相对于Class文件常量池的另外一个重要特征是 具备动态性 ，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性利用得比较多的是String类的intern（）方法。 OOM ：既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 除此之外，还有一部分内存区域： 直接内存(Direct Memory)直接内存并 不是虚拟机运行时数据区的一部分 ，也不是Java虚拟机规范中定义的内存区域，字面上的意思，是 本机的直接内存 。这部分内存也被频繁地使用。 在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 本机直接内存的分配 不会受到Java堆大小的限制 ，但还是会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。 OOM ：配置虚拟机参数时，根据实际内存设置-Xmx等参数信息时，经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。 以上]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OS存储器管理(三) 虚拟存储器]]></title>
    <url>%2F2016%2F03%2F14%2FOS%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86(%E4%B8%89)%20%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[基本概念与实现 1）局部性原理 在一段时间内，运行的作业程序仅访问（涉及到）一部分作业代码，即不会涉及整个地址空间。即在一段时间间隔内，仅装入一部分代码,作业照样能正常运行 2）虚拟存储器的引入 作业（进程）运行时，仅装入其代码的一部分到物理内存，待需要时再装入其余部分，同时还可将不再运行的部分调出物理内存。变相地扩充了内存容量,即实现了虚拟存储器。 虚拟内存 ①虚拟内存将内存抽象成一个巨大的、统一的存储数组，进而将用户看到的逻辑内存与物理内存分开 ②只要部分程序需要放在内存中就能使程序执行 ③逻辑地址空间可以比物理地址空间大 ④允许地址空间被多个进程共享 ⑥允许更多进程被创建 虚拟地址空间 当处理器读或写入内存位置时，它会使用虚拟地址。作为读或写操作的一部分，处理器将虚拟地址转换为物理地址。通过虚拟地址访问内存有以下优势 ①程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 ②程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。 ③不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 进程可用的虚拟地址范围称为该进程的 虚拟地址空间 。每个用户模式进程都有其各自的专用虚拟地址空间。 对于 32 位进程，虚拟地址空间通常为 2 GB，范围从 0x00000000 至 0x7FFFFFFF。对于 64 位进程，虚拟地址空间为 8 TB，范围从 0x000’00000000 至 0x7FF’FFFFFFFF。一系列虚拟地址有时称为一系列“虚拟内存” 虚拟内存可以用以下方式来实现 ①覆盖与交换技术 ②请求页式调度 ③请求段式调度 ①覆盖与交换技术 ②请求页式调度 算法思想 ： 作业分页(page)，内存分块(帧,frame)，页与块的大小相等。先装入部分页到物理内存，待运行需要时再调入新的页，淘汰旧的页（交换） 只在页面需要时，才把它们载入物理内存：需要更少的输入输出，更小的内存，更快的响应，更多的用户 有效-无效位 ： 页表中的每一项与一有效无效位与之关联。（1表示该页在物理内存中，0表示不在物理内存） 有效无效位初始为0 当进程试图访问那些尚未调入到物理内存的页时，对标记为无效的页面的访问会产生页错误陷阱（page-fault trap，缺页） 当有些页不在内存中时的页表： 缺页(中断) 1.检查进程的页表，以确定该引用是合法还是非法的地址访问。 2.如果引用非法，那么终止进程。如果引用有效但是尚未调入页面，引起缺页中断。 3.找到一个空闲块（从空闲块链表中取一个） 4.调度一个磁盘操作，以便将所需要的页调入刚分配的块 5.当磁盘读操作完成后，修改进程的内部表和页表，以表示该页已在内存中。 6.重新开始因非法地址陷阱而中断的指令。进程现在能访问所需的页，就好像它似乎总在内存中。 处理缺页的步骤： 处理缺页的流程： 那么。。没有空闲块时该如何处理？ 页替换： 在内存中找到一些不再使用的页，将它换出。 页面置换 给原有的缺页中断服务程序增加页置换，可以防止内存的过度分配（over-allocating）。 使用修改位（脏位）来降低页传输的开销 － 只有被修改过的页才写回至磁盘。 页置换分开了逻辑内存与物理内存 － 采用这种机制，小的物理内存能为程序员提供巨大的虚拟内存。 页置换的基本方法 1.查找所需页在磁盘上的位置； 2.查找一空闲块； 如果有空闲块，那么就使用它； 如果没有空闲块，那么就使用页置换算法以选择一个“牺牲”块（victim frame）； 将“牺牲”块的内容写到磁盘上；修改页表； 3.将所需页读入（新）空闲块；修改页表； 4.重启用户进程； 页面置换算法 主要追求最低的缺页 常用的页面置换算法模拟：见文章 页面调度算法模拟 块分配 每个进程需要最低数量的页 例如：IBM 370至少需要6页用来处理SS MOVE指令 指令是多字节指令，可能跨越2页 要移动的字符的块和要移动到目的的区域也可能都要跨页。 两种主要的分配方案： 固定分配，优先级分配 固定分配 平均分配：如100块，5个进程，则给每个进程20块 比例分配：根据进程的大小按比例分配 特点：每个进程所分配的数量会随着多道程序的级别而有所变化；优先级进程与低优先级进程在这种分配方式下没有任何区别。 优先级分配 按优先级比例而非进程的大小来分配 如果进程 Pi 产生了一个缺页，那么： 从自身的块中选择用于替换 从比自身优先级低的进程中选取块用于替换 全局置换 ：允许一个进程从所有块集合中选择一个置换块，而不管该块是否已分配给其他进程；一个进程可以从另一个进程中取块。 局部置换 ：要求每个进程仅从其自己的分配块中进行选择 系统颠簸(抖动) 抖动：进程一直忙于将页面换进换出。 如果一个进程没有足够的页，那么缺页率就会非常高。这会导致CPU使用率低，这时OS认为必须提高多道程序的程度，因此，新的进程会加入到系统中来。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>存储管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OS存储器管理(二)]]></title>
    <url>%2F2016%2F03%2F13%2FOS%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[离散分配 分页(Paging)， 分段，段页式 一、分页 一个进程的物理地址可以是非连续的； 将物理内存分成固定大小的块，称为块（frame）； 将逻辑内存分为同样大小的块，称为页（page）； 将连续的页分配并存放到不连续的若干内存块中； 建立页表，记录每一页对应的存储块的块号，将逻辑地址转换为物理地址。 将产生内部碎片 地址转换方法 将逻辑地址转换为虚拟地址： CPU生成的地址分成以下两部分： 1.页号(p)：页号作为页表中的索引。页表中包含每页所在物理内存的基地址。 2.页偏移(d)：与页的基地址组合就形成了物理地址，就可送交物理单元。 逻辑内存和物理内存的分页模型: 例如： 将逻辑地址转换为物理地址需要寄存器来支持，地址转换体系结构如下： 地址变换机构如下： 假定一页大小为1K(1024B)，考察逻辑地址2056，地址变换过程工作原理如下所示： 转换过程分析：逻辑地址机内表示（以16位为例） 无需计算，只需用块号代替高位的页号，就可立即得到对应的物理地址 例如： 页表的实现 1.页表保存在内存中 2.页表基寄存器（PTBR）指向页表 3.页表长度寄存器（PTLR）指示页表的大小 4.在这种方式下，每次数据/指令的访问需要访问两次内存。一次访问页表，另一次访问数据/指令 5.两次内存访问问题可以用特别的快速查找硬件缓冲（TLB，称为快表或联想存储器或关联内存或翻译后备缓冲器）来解决。 带TLB的分页硬件原理如下： 页表结构： ①层次化分页 ②Hash页表 ①层次化分页 1.将逻辑地址空间分成多个页表 2.一种简单的方法是两层分页法 示意图如下： 两层分页方法实例： 逻辑地址(32位机器，页大小为4K)分成以下两部分：页号(20位)，页偏移(12位) 页表又分成页，所以页号又进一步分成：10位页号，10位页偏移 因此，逻辑地址表示如下： ②Hash页表 1.处理超过32位地址空间的常用方法是使用Hash页表。 2.逻辑地址中的逻辑页号被放入hash页表中。hash页表的每一项都包括一个链接组的元素，这些元素hash成同一位置（碰撞）。 3.逻辑页号与链表中的每 一个元素的第一个域相比较。如果匹配，那么对应的块号就用来形成位置地址。如果不匹配，那么就对链表中的下一个域进行页码比较。 Hash页表实例: 二、分段 支持用户观点的内存管理方法 程序是若干段的集合：主程序，子程序，函数，方法，对象，局部变量，全局变量，堆栈，符号表，数组 用户角度的程序： 段的逻辑视角： 段的体系结构： 逻辑地址由两个元素组成： &lt;段号，偏移&gt; 段表：将二维的用户定义地址映射为一维物理地址。段表的每个条目都有段基地址和段界限。 基地址：包含段的起始地址 界限：指定段的长度 段表基地址寄存器（STBR）指向内存中的段表的位置 段表长度寄存器（STLR）指示程序所用的段的个数 段号S小于STLR的时候才是有效的 段硬件实现： 分段实例： 三、交换 进程可以暂时从内存中交换出来到备份存储上，当需要再执行时再调回到内存中。 备份存储 —— 通常是快速磁盘。这必须足够大，以便容纳所有用户的内存映象拷贝，它也必须提供对这些内存映象的直接访问。 换入、换出 － 是交换策略的一个变种，被用于基于优先权的调度算法中。如果一个更高优先级进程来了且需要服务，内存管理可以交换出低优先级的进程，以便可以装入和执行更高优先级的进程。当更高优先级进程执行完后，低优先级进程可以交换回内存以继续执行。 交换时间的主要部分是转移时间。总的转移时间与所交换的内存空间直接成正比。 交换的修改版本在许多系统中被采用。（如UNIX, Linux及Windows) 交换示意图： 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>存储管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server存储过程编程]]></title>
    <url>%2F2016%2F03%2F05%2Fsql%20server%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[存储过程 是一组完成特定功能的SQL 语句集合，经编译后存储在数据库中。 存储过程作为一个单元进行处理并以一个名称来标识。它能向用户返回数据、向数据库表中写入或修改数据等操作。 用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。 存储过程的作用 执行速度快; 减少网络流量; 作为一种安全机制。通过设置用户只可能使用存储过程访问数据，限制用户不能直接操作数据库中的敏感数据，以保障数据的安全性; 屏蔽T-SQL命令，提供交互查询的客户接口，增加数据库应用的方便性。 存储过程和函数的异同 本质上没区别。 不同： 函数只能返回一个变量的限制。而存储过程可以返回多个。 函数是可以嵌入在SQL中使用的,可以在select中调用，而存储过程不行。 存储过程的种类 1. 系统存储过程 系统存储过程由系统提供，在安装SQL Server 2008 后自动装入，定义在系统数据master中，其存储过程名前缀是sp_。 扩展存储过程 扩展存储过程用windows动态链接库实现，任何能够创建动态链接库的编程工具都可以用于创建扩展存储过程的dll，这就使得扩展存储过程的功能不收SQL语句的限制。其存储过程名前缀是xp_。 3.用户自定义存储过程 用户自定义存储过程是在用户数据库中创建的存储过程，用以完成特定的数据库操作任务，也称为用户存储过程。本地存储过程通常只能应用于创建它的数据库，并且存储过程名不能使用sp_前缀，以免系统误解。 永久存储过程 临时存储过程 前缀“#”:局部临时存储过程 前缀“##”：全局临时存储过程 例如： SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER ON GO /*上两句是 SQL-92 设置语句，使 SQL Server 2000/2005/2008 遵从 SQL-92 规则。 --当 SET QUOTED_IDENTIFIER 为 ON 时，标识符可以由双引号分隔， 而文字必须由单引号分隔。当 SET QUOTED_IDENTIFIER 为 OFF 时， 标识符不可加引号，且必须符合所有 Transact-SQL 标识符规则。 SQL-92 标准要求在对空值进行等于 (=) 或不等于 (&lt;&gt;) 比较时取值为 FALSE。 当 SET ANSI_NULLS 为 ON 时，即使 column_name 中包含空值， 使用 WHERE column_name = NULL 的 SELECT 语句仍返回零行。 即使 column_name 中包含非空值，使用 WHERE column_name &lt;&gt; NULL 的 SELECT 语句仍会返回零行。 --当 SET ANSI_NULLS 为 OFF 时，等于 (=) 和不等于 (&lt;&gt;) 比较运算符不遵从 SQL-92 标准。使用 WHERE column_name = NULL 的 SELECT 语句返回 column_name 中包含空值的行。使用 WHERE column_name &lt;&gt; NULL 的 SELECT 语句返回列中包含非空值的行。此外，使用 WHERE column_name &lt;&gt; XYZ_value 的 SELECT 语句返回所有不为 XYZ_value 也不为 NULL 的行。 */ ----------------------- SET ANSI_NULLS ON --用于和NULL的比较，如：null=null在off时会返回true,在on时为false SET QUOTED_IDENTIFIER ON -- go use test go ----------------------------------------------------------------- /*系统存储过程*/ EXEC sp_who --显示当前用户、会话和进程的信息 EXEC sp_who sa EXEC sp_helpdb test --显示指定数据库的信息 EXEC sp_monitor --显示sql server的统计信息, --比如上次运行sp_monitor的时间， --当前运行sp_monitor的时间，cpu处理sql server工作所用的秒数等信息 EXEC sp_help --显示数据库对象信息 EXEC sp_help student --显示存储过程的参数及其数据类型 exec sp_helptext student --显示存储过程的定义 exec sp_depends sc --显示和存储过程相关的数据库对象 exec sp_stored_procedures --显示当前数据库中的存储过程列表 go 创建存储过程 CREATE PROC[EDURE ] procedure_name [ {@parameter data_type} [ = default] [OUTPUT] ] [,…n] [with {recompile|encryption|recompile,encryption}] [FOR REPLICATION] AS sql_statement […n ] 其中： @parameter ：过程中的参数。在该语句中可以声明一个或多个参数。用户必须在执行过程时提供每个所声明参数的值，使用@符号作为第一个字符来指定参数名称。 data_type ：参数的数据类型。 Default ：参数的默认值。 OUTPUT ：表明参数是返回参数。 Recompile : 该过程在运行时编译 例如： /*普通存储过程*/ /*例: 创建存储过程maxgrade，输出所有学生的最高分：*/ create procedure maxgrade as begin set nocount on -- 使返回的结果中不包含受Transact-SQL语句影响的行数的信息。 select max(grade) as &apos;最高分&apos; from sc end go select * from sc exec maxgrade go -- drop proc maxgrade ----------------------------------------------------------------------------------- use test /*临时存储过程*/ /*创建临时存储过程#s_g，检索所有学生的成绩记录，包括学号、姓名、所选课程号和成绩：*/ create procedure #s_g as select student.sno,student.sname,sc.cno,sc.grade from student,sc where student.sno=sc.sno order by student.sno go exec #s_g --执行该存储过程： go ---------------------------------------------------------------------------------------------- /*加密存储过程*/ /*创建加密存储过程s_a，查询学生的平均年龄*/ create procedure s_a with encryption as select avg(sage) from student go exec s_a exec sp_helptext s_a exec sp_helptext maxgrade go 执行存储过程 执行存储过程使用EXECUTE语句，其格式为： [ [ EXEC [ UTE ] ] { [ @return_status =] { procedure_name| @procedure_name_var} [ [ @parameter = ] { value|@variable[OUTPUT] | [DEFAULT]}] [ , …n ] [with recompile]} 各个参数的含义： @return_status 保存存储过程的返回状态 procedure_name 调用的存储过程的名称 @parameter 过程参数 Value 过程参数的值 @variable 用来保存参数或返回参数的变量 OUTPUT 指定存储过程必须返回的一个参数 DEFAULT 默认参数值 存储过程的参数 1. 使用参数 带参数的存储过程的一般格式如下： CREATE PROCEDURE 存储过程名( 参数列表 ) AS SQL语句 例如： /*带参数的存储过程*/ /*创建存储过程insert_sc向表中插入一条记录*/ CREATE PROCEDURE insert_sc(@sno int,@cno int,@grade int) AS INSERT INTO sc(sno,cno,grade) VALUES (@sno,@cno,@grade) GO declare @a int --保存存储过程返回的状态； exec @a=insert_sc 1,3,100 --带参数的存储过程的执行方式一 select @a select * from sc --或 exec insert_sc @sno=2,@cno=3,@grade=99 --带参数的存储过程的执行方式二 select * from sc drop proc insert_sc go 2. 使用默认参数 在设计存储过程时，可以为参数提供一个默认值，默认值必须为常量或者NULL。其一般格式如下： CREATE PROCEDURE 存储过程名( 参数1=默认值1, 参数2=默认值2,… ) AS SQL语句 在调用存储过程时，如果不指定对应的实参值，则自动用对应的默认值代替。 例如： /*在存储过程中使用默认值*/ create proc select_student(@sno int=1) as select student.sno,student.sname,sc.cno,sc.grade from student,sc where student.sno=@sno and student.sno=sc.sno go exec select_student --不指定参数调用，则使用默认参数值1 exec select_student 2 --指定参数调用 drop proc select_student go 3. 使用返回参数 在创建存储过程时，可以定义返回参数。在执行存储过程时，可以将结果给返回参数。返回参数用OUTPUT进行说明。 例如： /*例:创建一个存储过程average，它返回两个参数@st_name和@st_avg， 分别代表了姓名和平均成绩，即查询指定学号的学生的姓名和平均成绩*/ create procedure average (@st_sno int, @st_sname char(10) output, @st_avg float output) as select @st_sname=student.sname, @st_avg=avg(sc.grade) from student,sc where student.sno=sc.sno and student.sno=@st_sno group by student.sname go --执行以上存储过程average，查询学号为“1”的学生姓名和平均分： declare @st_sname char(10), @st_avg float exec average 2,@st_sname output, @st_avg output select @st_sname as &apos;姓名&apos;, @st_avg as &apos;平均分&apos; --或select &apos;平均分&apos;=@st_avg go --drop proc average go 4. 存储过程的返回值 存储过程在执行后都会返回一个整型值（称为“返回代码”），指示存储过程的执行状态。 如果执行成功，返回0；否则返回-1～-99之间的数值（例如-1表示找不到对象，-2表示数据类型错误，-5表示语法错误等）。 也可以使用RETURN语句指定一个返回值。 例如： /*存储过程在执行后都会返回一个整型值，如成功执行返回0；如失败则返回-1至-99*/ /*也可以使用return语句来指定一个返回值*/ /*例: 创建存储过程maxgrade，输出所有学生的最高分：*/ create procedure maxgrade1 as begin set nocount on -- 使返回的结果中不包含受Transact-SQL语句影响的行数的信息。 select max(grade) as &apos;最高分&apos; from sc end go declare @ret_int int --保存返回值 exec @ret_int=maxgrade1 --执行该存储过程 print @ret_int drop proc maxgrade1 在调用存储过程时的两种传递参数的方式： 方式一： EXEC 存储过程名 实参列表 方式二： EXEC 存储过程名 参数1=值1,参数2=值2,… 例如： /*例: 创建存储过程test_ret根据输入的参数来判断返回值：*/ create proc test_ret(@input_int int=0) as begin if @input_int=0 return 0 --输入的参数等于0，则返回0 if @input_int&gt;0 return 1000 --输入的参数大于0，则返回1000 if @input_int&lt;0 return -1000 --输入的参数大于0，则返回-1000 end declare @ret_int int --保存返回值 exec @ret_int=test_ret 1 --执行该存储过程 print &apos;返回值&apos; print &apos;--------&apos; print @ret_int declare @ret_int int --保存返回值 exec @ret_int=test_ret 0 print @ret_int declare @ret_int int --保存返回值 exec @ret_int=test_ret -1 print @ret_int drop proc test_ret 查看、修改和删除存储过程 使用SQL Server管理控制器查看或修改存储过程 使用sp_helptext存储过程来查看存储过程的定义信息 使用SQL Server管理控制器删除存储过程 使用DROP PROCEDURE删除存储过程 例如： /*修改存储过程*/ /*修改存储过程s_a，查询学生的最大年龄，不加密了！*/ alter procedure s_a as select max(sage) from student go exec s_a exec sp_helptext s_a go ---------------------------------------------------------------------------------------------- /*删除存储过程*/ drop procedure s_a /*例:编写一个程序，先创建一个存储过程studproc，输出95031班的所有学生， 利用sysobjects和syscommnts两个系统表输出该存储过程的id和text列。 然后利用ALTER PROCEDURE语句修改该存储过程，将其改为加密方式，最后在输出该存储过程的 id和text列。*/ use school go create procedure studproc as select * from student where sclass=&apos;95031&apos; go --通过以下语句输出studproc存储过程的id和text列 select sysobjects.id,syscomments.text from sysobjects,syscomments where sysobjects.name=&apos;studproc&apos; and sysobjects.type=&apos;p&apos; and sysobjects.id=syscomments.id --修改该存储过程： alter procedure studproc with encryption as select * from student where sclass=&apos;95031&apos; go --再通过以下语句输出studproc存储过程的id和text列 select sysobjects.id,syscomments.text from sysobjects,syscomments where sysobjects.name=&apos;studproc&apos; and sysobjects.type=&apos;p&apos; and sysobjects.id=syscomments.id --------------------------------- /*例: 更名用户存储过程studproc1为studproc*/ use school go exec sp_rename studproc,studproc1 --------------------------------- /*使用DROP PROCEDURE语句删除用户存储过程stud_degree和stud1_degree。*/ USE school GO DROP PROCEDURE stud_degree,stud1_degree GO 存储过程示例： /*示例： 下面的存储过程从四个表的联接中返回所有作者（提供了姓名）、 出版的书籍以及出版社。该存储过程不使用任何参数。*/ CREATE PROCEDURE au_info_all AS SELECT au_lname, au_fname, title, pub_name FROM authors a INNER JOIN titleauthor ta ON a.au_id = ta.au_id INNER JOIN titles t ON t.title_id = ta.title_id INNER JOIN publishers p ON t.pub_id = p.pub_id GO /*该存储过程可以通过以下方法执行：*/ EXECUTE au_info_all -- Or EXEC au_info_all /*如果该过程是批处理中的第一条语句，则可使用：*/ au_info_all --------------------------------- /*下面的存储过程从四个表的联接中只返回指定的作者（提供了姓名）、出版的书籍以及出版社。 该存储过程接受与传递的参数精确匹配的值。*/ USE pubs IF EXISTS (SELECT name FROM sysobjects WHERE name = &apos;au_info&apos; AND type = &apos;P&apos;) DROP PROCEDURE au_info GO USE pubs GO CREATE PROCEDURE au_info @lastname varchar(40), @firstname varchar(20) AS SELECT au_lname, au_fname, title, pub_name FROM authors a INNER JOIN titleauthor ta ON a.au_id = ta.au_id INNER JOIN titles t ON t.title_id = ta.title_id INNER JOIN publishers p ON t.pub_id = p.pub_id WHERE au_fname = @firstname AND au_lname = @lastname GO /*au_info 存储过程可以通过以下方法执行：*/ EXECUTE au_info &apos;Dull&apos;, &apos;Ann&apos; -- Or EXECUTE au_info @lastname = &apos;Dull&apos;, @firstname = &apos;Ann&apos; -- Or EXECUTE au_info @firstname = &apos;Ann&apos;, @lastname = &apos;Dull&apos; -- Or 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 触发器]]></title>
    <url>%2F2016%2F03%2F03%2Fsql%20server%20%E8%A7%A6%E5%8F%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[触发器 是一种特殊类型的存储过程。触发器可包含复杂的T-SQL语句。触发器不能通过名称被直接调用，也不允许设置参数。它是建立在触发事件上的。 触发器可以强制执行一定的业务规则，以保持数据完整性、检查数据有效性、实现数据库管理任务和一些附加功能。 触发器的分类： DML、 DDL、 登录触发器 创建触发器需要指定的选项： 1.触发器的名称。 2.在其上定义触发器的表。 3.触发器将何时激发。 4.激活触发器的数据修改语句。 5.执行触发操作的编程语句。 CREATE TRIGGER语句基本语法格式如下： CREATE TRIGGER 触发器名称 ON {表名 | 视图名} [with encryption] { { {FOR | AFTER | INSTEAD OF} {[DELETE] [,][INSERT] [,] [UPDATE]} AS sql_statement […n ] } 其中： AFTER 指定触发器只有在触发 SQL 语句中指定的所有操作都已成功执行后才激发。所有的引用级联操作和约束检查也必须成功完成后，才能执行此触发器。如果仅指定 FOR 关键字，则 AFTER 是默认设置。 INSTEAD OF 指定执行触发器而不是执行触发 SQL 语句，从而替代触发语句的操作。 /*在student表上创建触发器， 在用户插入、修改和删除记录时，都会自动显示表中的内容：*/ use test go create trigger trig_1 on student after insert,delete,update as begin set nocount on select * from student end insert student(sno) values(5) delete student where sno=5 exec sp_helptext trig_1 --查看触发器内容 exec sp_helptrigger student --查看表上的触发器的属性 select * from sysobjects where xtype=&apos;TR&apos; --查看数据库中已有的触发器 drop trigger trig_1 inserted表和deleted表 触发器执行的时候，产生两个临时表： inserted表 和 deleted表 。它们的结构和所在的表的结构相同，可使用这两个表测试某些数据修改的效果和设置触发器操作的条件，但不能对表中的数据进行更改。 deleted表用于存储DELETE和UPDATE语句所影响的行的副本。在执行delete或update语句时，行从触发器表中删除，并传输到deleted表中。 inserted表用于存储INSERT和UPDATE语句所影响的行的副本。在插入和更新时，新建行被同时添加到inserted表和触发器表中。Inserted表中的行是触发器表中新行的副本。 在对具有触发器的表（触发器表）进行操作时，有： 执行INSERT操作，插入到触发器表中的新行被插入到inserted表中。 执行DELETE操作，从触发器表中删除的行被插入到deleted表中。 执行UPDATE操作，先从触发器表中删除旧行，然后再插入新行。删除的旧行插入到deleted表中；更改后的新行被插入到inserted 表中。 使用DML触发器 1. INSERT和UPDATE触发器 当向表中插入或者更新记录时，INSERT或者UPDATE触发器被激活。一般情况下，这两种触发器常用来检查插入或者修改后的数据是否满足要求。 INSERT触发器被触发时，新的记录增加到触发器的对应表中，并且同时也添加到一个inserted表中。 修改一个记录等于插入了一个新的记录并且删除一个旧的记录。当在一个有UPDATE触发器的表中修改记录时，表中原来的记录被移动到deleted表中，修改过的记录插入到了插入表中，触发器可以参考deleted表和inserted表以及被修改的表，以确定如何完成数据库操作。 2. DELETE触发器 DELETE触发器通常用于下面的情况： 防止那些确实要删除，但是可能会引起数据一致性问题的情况，一般是用于那些用作其他表的外部键记录。 用于级联删除操作。 例如： /*例：下例说明inserted表和deleted表的作用*/ if exists(select name from sysobjects where name=&apos;trig_2&apos; and type=&apos;TR&apos;) drop trigger trig_2 go create trigger trig_2 on student after update --update触发器 as print &apos;inserted表&apos; select * from inserted print &apos;deleted表&apos; select * from deleted go set nocount on update student set sname=&apos;关二&apos; where sno=2 --drop trigger trig_2 create trigger trig_3 on student after insert --insert触发器 as print &apos;inserted表&apos; select * from inserted print &apos;deleted表&apos; select * from deleted go insert student values(100,&apos;刘一百&apos;,&apos;男&apos;,25) drop trigger trig_3 create trigger trig_4 on student after delete --delete触发器 as print &apos;inserted表&apos; select * from inserted print &apos;deleted表&apos; select * from deleted go delete student where sno=100 drop trigger trig_4 修改触发器 语法格式： ALTER TRIGGER trigger_name ON ( table | view ) { { ( FOR | AFTER | INSTEAD OF ) } { [ DELETE ] [ , ] [ INSERT ] [ , ] [ UPDATE ] } AS sql_statement […n ] } DDL触发器使用 例如： /*DDL触发器*/ /*在test数据库上创建一个DDL触发器safe， 用来防止数据库中的任一表被修改或删除。*/ create trigger safetest on database --数据库DDL触发器 after drop_table,alter_table as begin raiserror(&apos;不能修改表结构&apos;,16,2) rollback end go --执行以下程序，观察结果 alter table student add nation char(10) disable trigger safetest on database drop trigger safetest on database --------------------------------------------------------- /*在服务器上创建一个DDL触发器tablecreat， 用来防止在服务器上创建数据库*/ create trigger trig_last on all server after create_database as begin raiserror(&apos;不能创建新的数据库&apos;,16,2) rollback end go --执行以下程序，观察结果 create database test_trig disable trigger trig_last on all server drop trigger trig_last on all server 删除触发器 使用SQL Server Management Studio删除触发器 使用DROP TRIGGER语句来删除触发器。其语法格式如下： DROP TRIGGER { trigger } [ , …n ] 触发器禁用和启用 例如： /*触发器禁用和启用*/ /*禁用sc表上的触发器trig_g。*/ alter table sc disable trigger trig_g disable trigger trig_g on sc go /*启用sc表上的触发器trig_g。*/ alter table sc enable trigger trig_g enable trigger trig_g on sc go --执行以下程序，观察结果 insert into sc values(1,100,1,-50) select * from sc 触发器具体应用 例如： /*具体应用*/ /*创建触发器trig3， 当删除student表中的学生记录时， 应该同时删除sc表中对应的记录*/ create trigger trig_5 on student for delete as delete sc where sc.sno in(select sno from deleted) go select * from student select * from sc go /*exec sp_help score --查看其中外键 alter table score --删除外键 drop CONSTRAINT FK_score_course alter table score drop CONSTRAINT FK_score_student*/ delete student where sno=3 go select * from student select * from sc ------------------------------------------------------------- create trigger trig_g on sc after insert,update as begin declare @g int select @g=grade from inserted if @g&lt;0 begin select &apos;成绩必须&gt;=0&apos; rollback end end go --执行以下程序，观察结果 insert into sc values(1,10,1,50) select * from sc /*例: 建立一个修改触发器trigno， 该触发器防止用户修改表student的学号*/ create trigger trigno on student after update as if update(sno) begin raiserror(&apos;不能修改学号&apos;,16,2) rollback end go --执行以下程序，观察结果 update student set sno=&apos;2&apos; where sno=&apos;1&apos; select * from student ------------------------------------------------------ /*INSTEAD OF触发器*/ /*例：在student表上创建一个INSTEAD OF触发器trig_6， 当用户插入数据时注意观察触发器的执行。*/ create trigger trig_6 on student instead of insert as select * from student go --执行以下程序，观察结果 insert into student(sno,sname) values(&apos;300&apos;,&apos;白扯&apos;) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[T-SQL 查询、修改数据表]]></title>
    <url>%2F2016%2F03%2F02%2FT-SQL%20%E6%9F%A5%E8%AF%A2%E3%80%81%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[T-SQL修改表数据 INSERT语句 语法： INSERT[TOP(expression) [PERCENT]][INTO]{ | rowset_function_limited[ WITH ( &lt;Table_Hint_Limited&gt; [ …n ] ) ] /指定表提示/| view_name } /视图名/{[(column_list) ] /指定列名/[ ]{VALUES /指定列名的取值/{DEFAULT | NULL | expression}[1…n]) /列值的构成形式/|derived_table|execute_statement } } /结果集/|DEFAULT VALUES /所有列均取默认值/ 例子： /*插入单个元组*/ /*向student表中插入一个学生记录（‘200’，‘曾雷’，‘女’，‘1978-2-3’，‘05001’）*/ USE test INSERT INTO student_1 VALUES(100,&apos;曾雷&apos;,&apos;女&apos;,&apos;1995-2-3&apos;,20) /*查询student表，查看结果*/ select * from student_1 ----------------------------------------------------------------------------------- /*向student表中插入一个学生记录（‘201’，‘孙浩’，‘男’，‘1977-8-4’，NULL）*/ INSERT INTO student_1(sno,sname,ssex,sbirthday,sage) VALUES(200,&apos;孙浩&apos;,&apos;男&apos;,&apos;1996-8-4&apos;,null) select * from student_1 delete from student_1 where sno=200 INSERT INTO student_1(sno,sname,ssex,sbirthday) VALUES(200,&apos;孙浩&apos;,&apos;男&apos;,&apos;1996-8-4&apos;) ----------------------------------------------------------------------------------- /*插入元组集合*/ /*将student_1表中的相关数据插入到student表中*/ select * from student select * from student_1 insert into student(sno,sname,ssex,sage) select sno,sname,ssex,sage from student_1 /*向student表中添加两个新生*/ INSERT INTO student_1(sno,sname,ssex,sbirthday,sage) VALUES(300,&apos;王明&apos;,&apos;男&apos;,&apos;1996-8-4&apos;,19),(400,&apos;赵强&apos;,&apos;男&apos;,&apos;1996-4-1&apos;,19) ----------------------------------------------------------------------------------- /*向自增列添加数据*/ create table testidentity( id int identity, words varchar(10)) insert into testidentity values(&apos;a&apos;) --标识列不指定 insert into testidentity values(&apos;b&apos;) --指定除了标识列外的列 set IDENTITY_INSERT testidentity on insert into testidentity(id,words) values(10,&apos;c&apos;) --指定标识列 set IDENTITY_INSERT testidentity off insert into testidentity values(&apos;d&apos;) select * from testidentity UPDATE语句 语法： UPDATE｛table_name｜view_name｝SET column_name = {expression | DEFAULT | NULL}[1…n]where where_clause 例子： /*将sc表中的成绩小于60的加5。*/ UPDATE sc SET grade=grade+5 WHERE grade&lt;70 /*将张三选修1号课程的成绩置零。*/ UPDATE sc SET grade=0 WHERE cno=1 and sno in (select sno from student where sname=&apos;张三&apos;) /*将学号为1的学生的姓名改为张三十，年龄改小2岁。*/ UPDATE student SET sname=&apos;张三十&apos;,sage=sage-2 --同时更新多列 WHERE sno=1 select * from student ----------------------------------------------------------------------------------- /*使用top表达式*/ UPDATE top(2) student SET sage=sage-2 UPDATE top(50) percent student SET sage=sage-2 DELETE语句 语法： DELETE table_nameWHERE search_condition 例子： /*删除student表中学号为200的记录*/ select * from student select * from sc DELETE student WHERE sno=&apos;200&apos; /*删除张三的选修1号课程的选课记录*/ DELETE sc WHERE cno=1 and sno in (select sno from student where sname=&apos;张三&apos;) ----------------------------------------------------------------------------------- /*TRANCATE*/ /*TRUNCATE TABLE table_name*/ /*一次删除表中所有数据，即清空表， 但表的结构及约束保持不变，且该操作不记录日志，无法恢复，使用时必须慬慎。*/ /*删除student_1表中的记录*/ TRUNCATE TABLE student_1 select * from student_1 T-SQL查询数据 SELECT 语句语法： SELECT select_list[INTO new_table]FROM table_source[WHERE search_condition][GROUP BY group_by_expression][HAVING search_condition][ORDER BY order_expression [ASC | DESC]] 简单查询例子： /*查询列*/ /*查询student表中所有记录的sname、ssex和sage列*/ SELECT sname,ssex,sage FROM student /*查询有选课记录的课程cno*/ select distinct cno --避免重复项 from sc /*查询有85分以上成绩的课程cno*/ SELECT DISTINCT cno FROM sc WHERE grade&gt;85 /*查询student表的所有记录*/ SELECT * FROM student SELECT sno as &apos;学号&apos;,sname as &apos;姓名&apos;,ssex as &apos;性别&apos; FROM student /*返回部分结果top*/ select top(1) * from student select top(1) * from student where ssex=&apos;女&apos; select top(1) with ties * from student order by sage select top(50) percent * from student /*计算列*/ select sno,sname,2015-sage as &apos;出生年月&apos; from student select sno,cno,grade*1.1 from sc ----------------------------------------------------- /*选择查询 查询sc表中成绩大于60的所有记录*/ SELECT * FROM sc WHERE grade&gt;60 /*查询sc表中1号课程成绩大于60的所有记录*/ SELECT * FROM sc WHERE cno=2 and grade&gt;60 /*查询score表中成绩在60～80之间的所有记录*/ SELECT * FROM sc WHERE grade between 60 and 80 /*查询sc表中成绩为85、86或88的记录*/ SELECT * FROM sc WHERE grade in(85,86,88) /*字符串匹配*/ /* % 匹配任意字符 _ 匹配单个字符 [] 匹配括号中的任意一个字符 [^]或[!]匹配没有出现在括号中的单个字符 escape换码字符 */ select * from student /*查询student表中姓张的或性别为“女”的学生记录*/ SELECT * FROM student WHERE sname like &apos;张%&apos;or ssex=&apos;女&apos; /*查询student表中姓李的学生*/ SELECT * FROM student WHERE sname like &apos;李%&apos; SELECT * FROM student WHERE sname like &apos;[李]%&apos; SELECT * FROM student WHERE sname like &apos;李_&apos; SELECT * FROM student WHERE sname like &apos;[^李]%&apos; SELECT * FROM student WHERE sname not like &apos;[李]%&apos; SELECT * FROM student WHERE sname like &apos;%[四]%&apos; /*查询sc表中没成绩的记录*/ SELECT * FROM sc WHERE grade is null SELECT * FROM sc WHERE grade is not null /*查询结果排序*/ SELECT * FROM sc order by grade SELECT * FROM sc order by cno,grade desc /*分组查询*/ /*group by group_by_expression[with rollup|cube]* having search_condition with rollup 只返回第一个分组条件制定的列的统计行; 而with cube除返回group by制定的列外,还返回按组统计的行*/ SELECT cno,AVG(grade) FROM sc group by cno SELECT cno,AVG(grade) FROM sc group by cno having AVG(grade)&gt;60 SELECT cno,tno,AVG(grade) FROM sc group by cno,tno SELECT cno,tno,AVG(grade) FROM sc group by cno,tno with rollup select AVG(grade) from sc 高级查询例子： /*嵌套查询*/ use test /*使用IN或NOT IN*/ select sname from student where sno in (select sno from sc where cno=2) select sname from student where sno not in (select sno from sc where cno=2) /*比较运算符的子查询*/ select sno,grade from sc sc1 where sc1.cno=1 and sc1.grade=(select sc2.grade from sc sc2 where sc2.cno=1 and sc2.sno=1) select * from sc select sno,grade from sc sc1 where sc1.cno=1 and sc1.grade&gt;(select sc2.grade from sc sc2 where sc2.cno=1 and sc2.sno=1) select sno from sc where cno=1 and grade&gt;all(select grade from sc where sno=1) select sno from sc where cno=1 and grade&gt;(select max(grade) from sc where sno=1) select student.sno,sname,cno,grade from sc as a,student where student.sno=a.sno and --不相关子查询 grade&gt;(select avg(grade) from sc b where b.cno=a.cno) /*exists*/ SELECT sname FROM student WHERE EXISTS (SELECT * FROM sc WHERE student.sno=sc.sno and sc.cno=2) SELECT sname FROM student WHERE not EXISTS (SELECT * FROM sc WHERE student.sno=sc.sno and sc.cno=2) /*多层嵌套查询 查询最高分的学生姓名*/ select * from student where not exists (select * from course where not exists (select * from sc where sc.sno=student.sno and sc.cno=course.cno)) select sname from student where sno in (select sno from sc where grade= (select max(grade) from sc)) go select * from sc select * from student /*DELETE、UPDATE和INSERT语句中的子查询*/ ------------------------------------------------------------ /*联接查询*/ use test /*查询学生的姓名，选课号及成绩*/ select sname,cno,grade from student,sc where student.sno=sc.sno select sname,cname,grade from student,sc,course --多表连接 where student.sno=sc.sno and sc.cno=course.cno select sname,cno,grade from student inner join sc on(student.sno=sc.sno) --内连接 select student.sname,sc.cno,sc.grade from student left join sc on (student.sno=sc.sno) --左向外连接 select student.sname,sc.cno,sc.grade from student right join sc on (student.sno=sc.sno) --右向外连接 select student.sname,sc.cno,sc.grade from student full outer join sc on (student.sno=sc.sno) --完全外部连接 select student.sno,sc.sno,sc.cno,sc.grade from student cross join sc --交叉连接 select student.sno,sc.sno,sc.cno,sc.grade from student cross join sc --带限定条件的交叉连接 where student.sno&lt;2 select c1.cno,c2.cname from course c1,course c2 --自连接 where c1.cpno=c2.cno -------------------------------------------------------------------------- /*无法使用ntext、text或image列上直接连接表， 但是使用substring函数在ntext、text或image列上间接联接表，如*/ select * from student join sc on substring(student.mytext,1,2)=substring(sc.mytext,1,2) ------------------------------ /*使用UNION运算符组合多个结果 查询所有作者和客户的号码和名称*/ select sno,sname from student where sno=1 union select sno,sname from student where sno=2 go --------------------------- /*在查询的基础上创建新表 将查询得到的学生学号、姓名、课程和分数输入到新建的表score1中， 再显示该新表的记录*/ select student.sno,avg(grade) as 平均成绩 into avggrade --该表自动生成 from student inner join sc on (student.sno=sc.sno) group by student.sno select * from avggrade drop table avggrade 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 事务处理]]></title>
    <url>%2F2016%2F02%2F18%2Fsql%20server%20%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[事物处理 事务是SQL Server中的单个逻辑单元，一个事务内的所有SQL语句作为一个整体执行，要么全部执行，要么都不执行。 事务有4个属性，称为ACID（原子性、一致性、隔离性和持久性） 原子性 事务必须是原子工作单元。对于其数据修改，要么全都执行，要么全都不执行。 一致性 事务在完成时，必须使所有的数据都保持一致状态。 隔离性 由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。 持久性 事务完成之后，它对于系统的影响是永久性的。 事务分类 按事务的启动和执行方式，可将事务分为3类： 1.显示事务 ：显式地定义启动和结束的事务。 2.自动提交事务 ：自动提交模式是SQL Server的默认事务管理模式。每个Transact-SQL语句在完成时，都被提交或回滚。如果一个语句成功地完成，则提交该语句；如果遇到错误，则回滚该语句。 3.隐性事务 ：当连接以隐性事务模式进行操作时，SQL Server将在提交或回滚当前事务后自动启动新事务。无须描述事务的开始，只须提交或回滚每个事务。隐性事务模式形成连续的事务链。 1.显示事务 显示事务需要显示地定义事务的启动和结束。 它是通过 BEGIN TRANSACTION 、 COMMIT TRANSACTION 、 ROLLBACK TRANSACTION 、 SAVE TRANSACTION 等Transact-SQL语句来完成的。 启动事务： BEGIN TRANSACTION 。 结束事务： COMMIT TRANSACTION 。例如： use test go /*启动一个事务向student表中插入一个记录*/ begin transaction insert into student values(100,&apos;陈浩&apos;,&apos;男&apos;,19) commit tran select * from student go 回滚事务： ROLLBACK TRANSACTION 。例如： /*启动一个事务向student表中删除一个记录，然后回滚该事务*/ begin transaction delete student where sno=100 rollback select * from student --由于回滚该事务，因此student表中没有插入记录。 go 在事务内设置保存点： SAVE TRANSACTION 。 保存点是如果有条件的取消事务的一部分，事务可以返回的位置。例如： /*在事务内设置保存点*/ begin transaction mytran --启动事务 select * from student save transaction s1 --设置保存点。 insert into student values(200,&apos;王洪&apos;,&apos;男&apos;,22) --插入另一个学生的记录 rollback transaction s1 --事务回滚到保存点s1 commit transaction go select * from student --陈浩插入到表中而王洪没有插入到表中 不能用于事务的操作： 操作 | 相应的SQL语句 —|— 创建数据库 | CREATE DATABASE 修改数据库 | ALTER DATABASE 删除数据库 | DROP DATABASE 恢复数据库 | RESTORE DATABASE 加载数据库 | LOAD DATABASE 备份日志文件 | BACKUP LOG 恢复日志文件 | RESTORE LOG 更新统计数据 | UPDATE STATISTICS 授权操作 | GRANT 复制事务日志 | DUMP TRANSACTION 磁盘初始化 | DISK INIT 更新使用sp_configure系统存储过程更改的配置选项的当前配置值 | RECONFIGURE 2.自动提交事务 SQL Server没有使用BEGIN TRANSACTION语句启动显式事务，或隐性事务模式未打开，将以自动提交模式进行操作。 当提交或回滚显式事务或者关闭隐性事务模式时，SQL Server将返回到自动提交模式。 3.隐式事务 隐性事务模式设置为打开之后，当SQL Server首次执行某些Transact-SQL语句时，都会自动启动一个事务，而不需要使用 BEGIN TRANSACTION 语句。 启动新事务的Transact-SQL语句包括： 在发出 COMMIT 或 ROLLBACK 语句之前，该事务一直保持有效。在第一个事务被提交或回滚之后，下次当连接执行这些语句的任何语句时，SQL Server都将自动启动一个新事务。 隐性事务模式可以通过使用SET语句来打开或者关闭，其语法格式为： SET IMPLICIT_TRANSACTIONS { ON | OFF } 隐性事务模式打开时，用户必须在该事务结束时显式提交或回滚。 隐性事务模式将保持有效，直到执行 SET IMPLICIT_TRANSACTIONS OFF 语句使连接返回到自动提交模式。 例如： /*演示在将IMPLICIT_TRANSACTIONS设置为ON时显式或隐式启动事务。 使用@@trancount函数返回当前连接的活动事务数。 */ set nocount on print cast(@@trancount as char(5)) create table table1(a int) insert table1 values(1) go print cast(@@trancount as char(5)) print &apos;使用显式事务&apos; begin tran insert table1 values(2) print &apos;当前连接的活动事务数：&apos;+cast(@@trancount as char(5)) commit tran print &apos;当前连接的活动事务数：&apos;+cast(@@trancount as char(5)) go print &apos;设置 implicit_transactions为on&apos; set implicit_transactions on go print &apos;使用隐式事务&apos; insert into table1 values(4) --这里不需要begin tran语句来定义事务的启动 print &apos;当前连接的活动事务数：&apos;+ cast(@@trancount as char(5)) commit tran print &apos;当前连接的活动事务数：&apos;+ cast(@@trancount as char(5)) go drop table table1 set implicit_transactions off /*BEGIN TRANSACTION 语句使 @@TRANCOUNT 递增 1。 ROLLBACK TRANSACTION 将 @@TRANCOUNT 递减为 0， 但 ROLLBACK TRANSACTION savepoint_name 语句并不影响 @@TRANCOUNT 值。COMMIT TRANSACTION 将 @@TRANCOUNT 递减 1。*/ 分布式事务 跨越两个或多个服务器上的数据库的事务就是分布式事务。 与本地事务的不同在于事务的提交（2pc） 控制分布式事务的T-SQL语句包括： begin distributed transaction 、 commit transaction \ commit work 、 rollback transaction \ rollback work 数据的锁定 并发问题包括： 修改丢失 ； 脏读 ； 不可重复读 ； 幻读 事务的隔离级别： 未提交读 ； 提交读 ； 可重复读 ； 可串行读 SQL SERVER 2005中的锁： 共享锁 ； 排它锁 ； 更新锁 ； 意向锁 ； 架构锁 封锁技术需要解决的问题： 死锁 锁的若干自定义操作： 1.通过Set lock_timeout 设置事务被阻塞的 最长时间；通过 @@lock_timeout 查看。例如： /*查看@@lock_timeout*/ print @@lock_timeout --LOCKTIMEOUT 的缺省值是 -1,这意味着将没有锁超时 set lock_timeout 1800 print @@lock_timeout 2. 定义事务隔离级别（4种） set transaction isolation level … 。 3. 锁定提示。例如： /*在select，insert，update和delete等语句中使用表级锁定提示*/ set transaction isolation level serializable begin tran select * from student with(tablock) exec sp_lock commit tran select object_name(1013578649) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OS存储器管理(一)]]></title>
    <url>%2F2016%2F01%2F24%2FOS%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[存储器的层次： 分为 寄存器 、 主存（内存） 和 辅存（外存） 三个层次。 主存 ： 高速缓冲存储器、主存储器、磁盘缓冲存储器， 主存又称为可执行存储器； 辅存 ： 固定磁盘存储器、可移动的外部存储器； 其可长期保存数据，但不能被处理器直接访问。 此处针对的是在OS层面上对主存（内存）的管理。 内(主)存储器管理的主要功能： ① 逻辑地址到物理地址的转换 ② 内存（主存）空间的分配与回收 ③ 内存信息（数据）的共享与保护 ④ 内存的逻辑扩充（虚拟存储器的实现） 一个用户程序在运行之前需要经历若干步骤，为了执行，程序应被调入内存并放在进程内： 在这些步骤中，地址可能有不同的表示形式： 符号（源程序中），可重定位的地址（目标模块），绝对地址（内存映像） 逻辑地址 ：目标代码的相对编址。由CPU生成，也称为虚拟地址 物理地址 ：内存存储单元的编址，内存单元的实际地址 逻辑地址空间 ：目标代码用逻辑地址编址对应的区域 内存存储空间 ：内存若干存储单元用物理地址编址对应的区域 重定位 ：逻辑地址转换为物理地址的操作（过程） 接下来，将指令与数据捆绑到内存地址，可以在以下步骤的任何一步中执行： 编译时 ：MS-DOS的COM格式程序 加载时 ：编译器生成可重定位代码 执行时 ：进程在执行时可以从一个内存段移到另一内存段，那么捆绑必须延迟到执行时才进行。 运行时从虚拟地址映射到物理地址的硬件设备称为 内存管理单元(MMU) 用户进程所生成的地址在送交内存之前，都将加上重定位寄存器的值。 用户程序处理的是逻辑地址，它不会看到真实的物理地址 。 原理图如下： 例如： 重定位的方式： 静态重定位 ：目标代码装入内存时，一次性进行逻辑地址到物理地址的地址转换。 动态重定位 ：目标代码装入内存时，先不进行地址转换（即原代码装入），在执行时,再实施地址转换。 内存分配的方式 ： 连续分配 和 非连续分配 内存通常分为两个区域： 一个用于驻留 操作系统 ，常与中断向量一起放在 低内存 另一个用于 用户进程 ，常放在 高内存 。 一、连续分配 四种方式： ①单一连续区分配 ②固定分区分配 ③可变（动态）分区分配 ④可重定位分区分配 ①单分区分配方法（Single-partition allocation ） 重定位寄存器方案 用来保护用户进程之间，用户进程与操作系统之 间不会相互修改代码与数据 重定位寄存器 包含了最小的物理地址； 界限寄存器 包含了逻辑地址的范围，每个逻辑地址必须小于界限寄存器 ②固定分区分配 算法思想 内存可用区划分成若干个大小固定的存区，每个存区分别装入一道作业的代码（数据）。 算法实现 建立分区说明表，记录各分区大小、地址及分配情况 例如： 分区号 | 分区大小 | 起始地址 | 状态 —|—|—|— 1 | 12k | 20k | 已分配 2 | 32k | 32k | 已分配 3 | 64k | 64k | 已分配 4 | 128k | 128k | 空闲 5 | | | 分配：查分区说明表，找到一个足够大的空闲分区分配之； 回收：将回收分区对应的分区说明表状态改为“空闲”。 优点：内存可同时装入多道作业代码，算法实现简单； 缺点：存在浪费（分区一次性全部分配出去）；会产生内部碎片。 ③动态存储分配问题 算法思想：事先不划分分区，待作业需要分配内存时，再按需分配划分分区（分区的大小及个数不固定）。 数据结构:空闲分区表或空闲分区链表 —- &gt; 记录空闲分区的大小、地址等 空闲分区链表状况： 分配 ：查空闲分区链表，找到第一个足够大的分区，将其一分为二分配之； 分配策略（算法） ：首次适应算法，循环首次适应算法，最佳适应算法，最差适应算法 回收 ：先将回收分区与相邻空闲分区合并再修改空闲分区链表。 回收算法 ：前邻接合并，后邻接合并，前、后邻接合并，不邻接处理 优、缺点 按需分配，可解决浪费问题；分配算法复杂，会产生外部碎片； 邻接合并系统开销大。 碎片问题 碎片:可变分区分配过程中形成的若干个非常小的无法再利用的小分区，形成外部碎片 碎片 分为 外部碎片 和 内部碎片 。 处理碎片的方法： 1.紧缩（compaction，拼接）：用来降低外部碎片移动内存内容，以便所有空闲空间合并成一整块。 如果重定位是动态的，是在运行时进行的，那么就能采用紧缩 2.另一种可能解决外部碎片问题的方法是允许物理地址空间为非连续，这样只要有物理内存就可为进程分配：分页或分段 ④可重定位分区分配 算法思想 在可变分区分配算法的基础上，采用动态重定位方式装入程序（数据）。当无足够大的分区供分配时，若总的空闲存储容量够用，则将各分区中的内容向内存一端移动（紧凑），使另一端形成一个大的空闲分区，然后再分配。 例：前例若要为作业10分配120k的存储空间，因无足够大分区（总空闲容量290k），则先进行合并处理： 内存的非连续分配方式见下篇。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>存储管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[页面调度算法模拟]]></title>
    <url>%2F2016%2F01%2F23%2F%E9%A1%B5%E9%9D%A2%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%A8%A1%E6%8B%9F%2F</url>
    <content type="text"><![CDATA[模拟实现的算法：FIFO，Optimal（最佳置换），LRU，Clock，改进的Clock算法 一、先入先出（FIFO）: 最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即先进入内存的页，先退出内存。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。 这种算法只是在按线性顺序访问地址空间时才是理想的，否则效率不高。因为那些常被访问的页，往往在主存中也停留得最久，结果它们因变“老”而不得不被置换出去。 FIFO的另一个缺点是，它会产生Belady现象,即在增加存储块的情况下，反而使缺页中断率增加了。 模拟算法如下： package paging; import java.util.LinkedList; /** * FIFO(先进先出)页面置换算法 * * @author wz * @date 15/11/30. */ public class FIFO { private LinkedList&lt;Integer&gt; memoryBlock; void pageReplacement(int[] pageString, int memBlockNum) { memoryBlock = new LinkedList&lt;&gt;(); int pageFaultCount = 0, pageReplaceCount = 0; for (int i = 0; i &lt; pageString.length; i++) { if (memoryBlock.contains(pageString[i])) continue; if (memoryBlock.size() &gt;= memBlockNum) { memoryBlock.pollFirst(); // memoryBlock.set(0, pageString[i]); pageReplaceCount++; } memoryBlock.add(pageString[i]); pageFaultCount++; } System.out.println(&quot;缺页中断率: &quot;+pageFaultCount/(double)pageString.length); System.out.println(&quot;页面置换次数: &quot;+pageReplaceCount); } } 二、Optimal（最佳置换） 这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。这个算法唯一的一个问题就是它无法实现。当缺页发生时，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较。 当请求页面不在内存中时，选择已在内存中的永不使用的或者是在最长时间内不再被访问的页面置换出去，将请求的页面换入。 模拟算法如下： package paging; import java.util.LinkedList; /** * Optimal(最佳)置换算法 * * @author wz * @date 15/11/30. */ public class Optimal { private LinkedList&lt;Integer&gt; memoryBlock; void pageReplacement(int[] pageString, int memBlockNum) { memoryBlock = new LinkedList&lt;&gt;(); int maxDistIndex,willVisit,replaceIndex = -1; int pageFaultCount = 0, pageReplaceCount = 0; for (int i = 0; i &lt; pageString.length; i++) { if (memoryBlock.contains(pageString[i])) continue; if (memoryBlock.size() &gt;= memBlockNum) { // 查找最长时间内不被访问的页 maxDistIndex = -1; for (int j = 0; j &lt; memBlockNum; j++) { willVisit = 0; for (int k = i+1; k &lt; pageString.length; k++) { if (memoryBlock.get(j) == pageString[k]) { if (k &gt; maxDistIndex){ maxDistIndex = k; replaceIndex = j; } willVisit = 1; break; } } if (willVisit == 0){ replaceIndex = j; break; } } memoryBlock.set(replaceIndex, pageString[i]); pageReplaceCount++; } else memoryBlock.add(pageString[i]); pageFaultCount++; } System.out.println(&quot;缺页中断率: &quot;+pageFaultCount/(double)pageString.length); System.out.println(&quot;页面置换次数: &quot;+pageReplaceCount); } } 三、最近最久未使用（LRU）算法当请求页面不在内存中时，将最近最久未用的页面置换出去。用栈来存储内存中的页面，将栈底页面换出，将请求页面换入压入栈顶。 LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。LRU算法是经常采用的页面置换算法，并被认为是相当好的，但是存在如何实现它的问题。LRU算法需要实际硬件的支持。其问题是怎么确定最后使用时间的顺序，对此有两种可行的办法：1.计数器。最简单的情况是使每个页表项对应一个使用时间字段，并给CPU增加一个逻辑时钟或计数器。每次存储访问，该时钟都加1。每当访问一个页面时，时钟寄存器的内容就被复制到相应页表项的使用时间字段中。这样我们就可以始终保留着每个页面最后访问的“时间”。在置换页面时，选择该时间值最小的页面。这样做，[1] 不仅要查页表，而且当页表改变时（因CPU调度）要 维护这个页表中的时间，还要考虑到时钟值溢出的问题。2.栈。用一个栈保留页号。每当访问一个页面时，就把它从栈中取出放在栈顶上。这样一来，栈顶总是放有目前使用最多的页，而栈底放着目前最少使用的页。由于要从栈的中间移走一项，所以要用具有头尾指针的双向链连起来。在最坏的情况下，移走一页并把它放在栈顶上需要改动6个指针。每次修改都要有开销，但需要置换哪个页面却可直接得到，用不着查找，因为尾指针指向栈底，其中有被置换页。 此处使用栈，模拟算法如下： package paging; import java.util.LinkedList; /** * LRU(最近最久未使用)页面置换算法 * * @author wz * @date 15/11/30. */ public class LRU { private LinkedList&lt;Integer&gt; memoryBlock; void pageReplacement(int[] pageString, int memBlockNum) { memoryBlock = new LinkedList&lt;&gt;(); int pageFaultCount = 0, pageReplaceCount = 0; for (int i = 0; i &lt; pageString.length; i++) { if (memoryBlock.contains(pageString[i])){ memoryBlock.addLast(memoryBlock.remove(memoryBlock.indexOf(pageString[i]))); continue; }else if (memoryBlock.size() &gt;= memBlockNum) { memoryBlock.pollFirst(); pageReplaceCount++; } memoryBlock.addLast(pageString[i]); pageFaultCount++; } System.out.println(&quot;缺页中断率: &quot;+pageFaultCount/(double)pageString.length); System.out.println(&quot;页面置换次数: &quot;+pageReplaceCount); } } 四、Clock算法 当某一页首次装入内存中时，则将该页框的使用位设置为1；当该页随后被访问到时（在访问产生缺页中断之后），它的使用位也会被设置为1。 当请求页面不在内存中时，查找内存中的页面，每当遇到一个使用位为1的页框时，就将该位重新置为0；如果在这个过程开始时，缓冲区中所有页框的使用位均为0时，则选择遇到的第一个页框置换；如果所有页框的使用位均为1时，则指针在缓冲区中完整地循环一周，把所有使用位都置为0，再次循环遍历，置换第一个遇到的使用位为0的页面。 模拟算法如下： package paging; import java.util.LinkedList; /** * 简单Clock置换算法 * * @author wz * @date 15/11/30. */ public class Clock { private LinkedList&lt;Integer&gt; memoryBlock; private int[] accessed; void pageReplacement(int[] pageString, int memBlockNum) { memoryBlock = new LinkedList&lt;&gt;(); accessed = new int[memBlockNum]; int pageFaultCount = 0, pageReplaceCount = 0; for (int i = 0; i &lt; pageString.length; i++) { if (memoryBlock.contains(pageString[i])){ accessed[memoryBlock.indexOf(pageString[i])] = 1; continue; }else if (memoryBlock.size() &gt;= memBlockNum) { for (int j = 0; j &lt; accessed.length;j++) { accessed[j] ^= 1; //取反 if(accessed[j]==1){ memoryBlock.set(j,pageString[i]); break; } if (j == accessed.length-1) j = -1; } pageReplaceCount++; } else{ memoryBlock.addLast(pageString[i]); accessed[memoryBlock.size()-1] = 1; } pageFaultCount++; } System.out.println(&quot;缺页中断率: &quot;+pageFaultCount/(double)pageString.length); System.out.println(&quot;页面置换次数: &quot;+pageReplaceCount); } } 五、改进的Clock算法 在将一个页面换出时，如果该页已被修改过，便须将它重新写到磁盘上；但如果该页未被修改过，则不必将它拷回磁盘。同时满足这两条件的页面作为首先淘汰的页。由访问位A和修改位M可以组合成下面四种类型的页面： 1.（A=0，M=0）：表示该页最近既未被访问、又未被修改，是最佳淘汰页。 2. （A=0，M=1）：表示该页最近未被访问，但已被修改，并不是很好的淘汰页。 3. （A=1，M=0）：最近已被访问，但未被修改，该页有可能再被访问。 4. （A=1，M=1）：最近已被访问且被修改，该页有可能再被访问. 在进行页面置换时，其执行过程可分成以下三次遍历： （1）从指针所指示的当前位置开始，扫描循环队列，寻找A=0且M=0的第一类页面，将所遇到的第一个页面作为所选中的淘汰页。在第一次扫描期间不改变访问位A。 （2）如果第一步失败，即查找一周后未遇到第一类页面，则开始第二轮扫描，寻找A=0且M=1的第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有经过的页面的访问位置0。 （3）如果第二步也失败，即未找到第二类页面，则将指针返回到开始的位置，并将所有的访问位复0。然后，重复第一步，如果仍失败，必要时再重复第二步，此时就一定能够找到被淘汰的页。 模拟算法如下： package paging; import java.util.LinkedList; /** * 改进的Clock置换算法 * * @author wz * @date 15/11/30. */ public class ClockImprove { private LinkedList&lt;Integer&gt; memoryBlock; private int[] accessed; private int[] modified; void pageReplacement(int[] pageString, int[] modifyStatus, int memBlockNum) { int index; memoryBlock = new LinkedList&lt;&gt;(); accessed = new int[memBlockNum]; modified = new int[memBlockNum]; int pageFaultCount = 0, pageReplaceCount = 0; for (int i = 0; i &lt; pageString.length; i++) { if (memoryBlock.contains(pageString[i])){ index = memoryBlock.indexOf(pageString[i]); accessed[index] = 1; if (modified[index]==0) modified[index]=modifyStatus[i]; continue; } else if (memoryBlock.size() &gt;= memBlockNum) { index=-1; while (true){ for (int j = 0; j &lt; accessed.length; j++) { if (accessed[j] == 0 &amp;&amp; modified[j]==0){ index=j; break; } } if (index &gt;= 0) break; for (int j = 0; j &lt; accessed.length; j++) { if (accessed[j] == 0 &amp;&amp; modified[j]==1){ index = j; break; } accessed[j]=0; } if (index &gt;= 0) break; } memoryBlock.set(index,pageString[i]); pageReplaceCount++; } else{ memoryBlock.addLast(pageString[i]); index = memoryBlock.size()-1; } accessed[index] = 1; modified[index]=modifyStatus[i]; pageFaultCount++; } System.out.println(&quot;缺页中断率: &quot;+pageFaultCount/(double)pageString.length); System.out.println(&quot;页面置换次数: &quot;+pageReplaceCount); } } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>存储管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理机进程调度模拟]]></title>
    <url>%2F2015%2F12%2F27%2F%E5%A4%84%E7%90%86%E6%9C%BA%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E6%A8%A1%E6%8B%9F%2F</url>
    <content type="text"><![CDATA[一、进程调度 无论是在批处理还是分时系统中，用户进程数一般都多于处理机数、这将导致它们互相争夺处理机。另外，系统进程也同样需要使用处理机。这就要求进程调度程序按一定的策略，动态地把处理机分配给处于就绪队列中的某一个进程，以使之执行。进程调度属于处理机调度。 处理机调度分为三个层次： 高级调度 ：(High-Level Scheduling)又称为长程调度、作业调度，它决定把外存上处于后备队列中的作业调入内存运行，为他们创建进程、分配必要的资源，放入就绪队列 低级调度 ：(Low-Level Scheduling)又称为短程调度、进程调度，它决定把就绪队列的某进程获得处理机，并由分派程序将处理机分配给被选中的进程 中级调度 ：(Intermediate-Level Scheduling)又称为在虚拟存储器中引入，在内、外存对换区进行进程对换，把外存上那些已经预备运行条件的就绪进程再重新调入内存，放入就绪队列。 二、常用调度算法模拟 首先创建一个进程控制块(PCB)的类: package controlblock; /** * 进程控制块 * * @author wz * * @date 2015年11月10日 */ public class PCB { private int pid; private double priority; private int arriveTime; private int needTime; public PCB(int pid,int arriveTime,int needTime){ this.pid = pid; this.arriveTime = arriveTime; this.needTime = needTime; } public PCB(int pid, double priority, int arriveTime, int needTime) { super(); this.pid = pid; this.priority = priority; this.arriveTime = arriveTime; this.needTime = needTime; } public int getPid() { return pid; } public double getPriority() { return priority; } public void setPriority(double priority) { this.priority = priority; } public int getArriveTime() { return arriveTime; } public int getNeedTime() { return needTime; } public void setNeedTime(int needTime) { this.needTime = needTime; } } 1.先到先服务(first-come first-served,FCFS)调度算法 先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 模拟算法如下： package process.schedule; import java.util.Comparator; import java.util.Iterator; import java.util.LinkedList; import controlblock.PCB; /** * 先到先服务进程调度 * * @author wz * * @date 2015年11月10日 */ public class FCFS { protected LinkedList&lt;PCB&gt; processQueue; public FCFS() { processQueue = new LinkedList&lt;PCB&gt;(); } public void schedule() { sortByArriveTime(processQueue); int currentTime = 0; int arriveTime; PCB process; Iterator&lt;PCB&gt; iter = processQueue.iterator(); while (iter.hasNext()) { process = iter.next(); arriveTime = process.getArriveTime(); System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,&quot;); System.out.print(&quot;到达时间：&quot; + process.getArriveTime() + &quot;,&quot;); System.out.print(&quot;需要时间:&quot; + process.getNeedTime() + &quot;,&quot;); if (arriveTime &gt; currentTime) currentTime = arriveTime; System.out.print(&quot;开始时间：&quot; + currentTime + &quot;,&quot;); currentTime += process.getNeedTime(); System.out.println(&quot;结束时间：&quot; + currentTime); iter.remove(); } } public void addProcess(int pid, int arriveTime, int needTime) { processQueue.push(new PCB(pid, arriveTime, needTime)); } /** * 对进程队列按到达时间排序 * * @param processQueue */ private &lt;T&gt; void sortByArriveTime(LinkedList&lt;PCB&gt; processQueue) { processQueue.sort((p1, p2) -&gt; { Integer p1Time = p1.getArriveTime(); Integer p2Time = p2.getArriveTime(); return p1Time.compareTo(p2Time); }); } } 具体思想是用随机数生成多个PCB对象，放入FCFS的进程队列processQueue中，调度算法首先按照进程的到达时间递增排序，然后再从进程队列中依次取出进程，计算其开始时间、结束时间。 2.短作业优先(short job first,SJF)调度算法 短作业(进程)优先调度算法(SJF)，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。 模拟算法如下： package process.schedule; import java.util.Comparator; import java.util.LinkedList; import controlblock.PCB; import dispatcher.Dispatcher; /** * 短作业优先调度 * * @author wz * * @date 2015年11月10日 */ public class SJF{ protected LinkedList&lt;PCB&gt; processQueue; public SJF() { processQueue = new LinkedList&lt;PCB&gt;(); } public void schedule() { sortByArriveTime(processQueue); PCB process, tempProcess; int arriveTime, needTime, minIndex, minNeedTime, currentTime = 0; while (!processQueue.isEmpty()) { process = processQueue.pollFirst(); arriveTime = process.getArriveTime(); needTime = process.getNeedTime(); if (currentTime &lt; arriveTime) currentTime = arriveTime; minIndex = -1; minNeedTime = Dispatcher.getMaxNeedTime() + 2; // 要执行进程时，挑选已到达的需要作业时间最短的进程 for (int i = 0; i &lt; processQueue.size(); i++) { tempProcess = processQueue.get(i); if (tempProcess.getArriveTime() &gt; currentTime + needTime) break; // 到达时间相同，挑选最短作业为当前作业 if (tempProcess.getArriveTime() == arriveTime &amp;&amp; tempProcess.getNeedTime() &lt; needTime) { processQueue.set(i, process); process = tempProcess; tempProcess = processQueue.get(i); needTime = process.getNeedTime(); } if (tempProcess.getNeedTime() &lt; minNeedTime) { minIndex = i; minNeedTime = tempProcess.getNeedTime(); } } // 将最短作业放入队首 if (minIndex != -1) { tempProcess = processQueue.remove(minIndex); processQueue.addFirst(tempProcess); } System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,到达时间：&quot; + process.getArriveTime() + &quot;,需要时间:&quot; + process.getNeedTime() + &quot;,开始时间：&quot; + currentTime + &quot;,&quot;); currentTime += needTime; System.out.println(&quot;结束时间：&quot; + currentTime); } } public void addProcess(int pid, int arriveTime, int needTime) { PCB process = new PCB(pid, arriveTime, needTime); processQueue.push(process); } /** * 对进程队列按到达时间排序 * * @param processQueue */ private &lt;T&gt; void sortByArriveTime(LinkedList&lt;PCB&gt; processQueue) { processQueue.sort((p1, p2) -&gt; { Integer p1Time = p1.getArriveTime(); Integer p2Time = p2.getArriveTime(); return p1Time.compareTo(p2Time); }); } } 具体思想是用随机数生成多个PCB对象，放入SJF的进程队列processQueue中，然后： ①调度算法首先按照进程的到达时间递增排序，然后在队列不为空的情况下执行② ②队首PCB出队(本次要执行的作业) ③遍历进程队列，若有到达时间与出队PCB相同，则找出所需作业时间最短的作业，两者交换。(确保当前作业为最短作业) ④找出已出队进程的执行结束时间前到达的所有作业中所需作业时间最短作业程(查找下一个要执行的作业)，放入队首 ⑤计算已出队进程(本次的最短作业)运行的开始时间、结束时间。 ⑥若队列不为空，执行②，否则结束 3.高响应比优先调度算法(Heigest Response Ratio Next,HRRN) 在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证，容易出现饥饿现象。为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为： 由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先权又相当于响应比RP。据此，又可表示为： 模拟算法如下： package process.schedule; import java.util.Comparator; import java.util.LinkedList; import controlblock.PCB; /** * 高响应比优先调度 * * @author wz * * @date 2015年11月10日 */ public class HRRN { protected LinkedList&lt;PCB&gt; processQueue; public HRRN() { processQueue = new LinkedList&lt;PCB&gt;(); } public void schedule() { sortByArriveTime(processQueue); PCB process, tempProcess; int arriveTime, needTime, maxIndex, currentTime = 0; double respRatio, maxPriority = 0; while (!processQueue.isEmpty()) { process = processQueue.pollFirst(); arriveTime = process.getArriveTime(); needTime = process.getNeedTime(); if (currentTime &lt; arriveTime) currentTime = arriveTime; maxIndex = -1; maxPriority = -1; // 当前进程执行完后，挑选已到达的响应比最高的进程 for (int i = 0; i &lt; processQueue.size(); i++) { tempProcess = processQueue.get(i); if (tempProcess.getArriveTime() &gt; currentTime + needTime) break; respRatio = (currentTime + needTime - tempProcess.getArriveTime()) / (double) tempProcess.getNeedTime() + 1; tempProcess.setPriority(respRatio); if (respRatio &gt; maxPriority) { maxIndex = i; maxPriority = respRatio; } } // 将响应比最高的进程放入队首 if (maxIndex != -1) { tempProcess = processQueue.remove(maxIndex); processQueue.addFirst(tempProcess); } System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,响应比：&quot; + process.getPriority() + &quot;,到达时间：&quot; + process.getArriveTime() + &quot;,需要时间:&quot; + process.getNeedTime() + &quot;,开始时间：&quot; + currentTime + &quot;,&quot;); currentTime += needTime; System.out.println(&quot;结束时间：&quot; + currentTime); } } public void addProcess(int pid, int arriveTime, int needTime) { PCB process = new PCB(pid, arriveTime, needTime); processQueue.push(process); } /** * 对进程队列按到达时间排序 * * @param processQueue */ private &lt;T&gt; void sortByArriveTime(LinkedList&lt;PCB&gt; processQueue) { processQueue.sort((p1, p2) -&gt; { Integer p1Time = p1.getArriveTime(); Integer p2Time = p2.getArriveTime(); return p1Time.compareTo(p2Time); }); } } 具体思想是用随机数生成多个PCB对象，放入HRRN的进程队列processQueue中，然后： ①按照进程的到达时间递增排序，在队列不为空的情况下执行② ②队首PCB出队(本次要执行的作业) ③遍历进程队列中已出队作业的执行结束时间前到达的所有作业，计算响应比，找出最高响应比的作业，放入队首 ④ 计算已出队进程(本次的响应比最高的作业)运行的开始时间、结束时间。 ⑤若队列不为空，执行②，否则结束 4.时间片轮转法(round robin,RR) 在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。 模拟算法如下： package process.schedule; import java.util.Comparator; import java.util.LinkedList; import controlblock.PCB; /** * 时间片轮转调度 * * @author wz * * @date 2015年11月10日 */ public class RR { protected LinkedList&lt;PCB&gt; processQueue; private static final int TIME_SLICE = 5; public RR() { processQueue = new LinkedList&lt;PCB&gt;(); } public void schedule() { sortByArriveTime(processQueue); PCB process; int currentTime = 0; int arriveTime; int needTime; while (!processQueue.isEmpty()) { process = processQueue.pollFirst(); needTime = process.getNeedTime(); arriveTime = process.getArriveTime(); System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,&quot;); System.out.print(&quot;到达时间：&quot; + process.getArriveTime() + &quot;,&quot;); System.out.print(&quot;还需要时间:&quot; + process.getNeedTime() + &quot;,&quot;); if (currentTime &lt; arriveTime) currentTime = arriveTime; System.out.print(&quot;开始时间：&quot; + currentTime + &quot;,&quot;); if (TIME_SLICE &lt; needTime) { currentTime += TIME_SLICE; System.out.println(&quot;进程中断时间：&quot; + currentTime); process.setNeedTime(needTime - TIME_SLICE); for (int i = 0; i &lt; processQueue.size(); i++) { if (processQueue.get(i).getArriveTime() &gt; currentTime) { processQueue.add(i, process); break; } else if (i == processQueue.size() - 1) { processQueue.add(process); break; } } } else { currentTime += needTime; System.out.println(&quot;结束时间：&quot; + currentTime); } } } public void addProcess(int pid, int arriveTime, int needTime) { processQueue.push(new PCB(pid, arriveTime, needTime)); } /** * 对进程队列按到达时间排序 * * @param processQueue */ private &lt;T&gt; void sortByArriveTime(LinkedList&lt;PCB&gt; processQueue) { processQueue.sort((p1, p2) -&gt; { Integer p1Time = p1.getArriveTime(); Integer p2Time = p2.getArriveTime(); return p1Time.compareTo(p2Time); }); } } 具体思想是用随机数生成多个PCB对象，放入RR的进程队列processQueue中，然后： ①按照进程的到达时间递增排序，在队列不为空的情况下执行② ②队首PCB出队(本次要执行的作业) ③为已出队进程分配时间片，计算运行的开始时间、中断时间或结束时间。 ④若出队进程没有执行完，则将该PCB插入到进程队列中当前进程中断时间前所到达的作业的最后 ⑤若队列不为空，执行②，否则结束 5.优先级调度算法(priority-scheduling algorithm,PSA) 此算法常被用于批处理系统中，作为作业调度算法，也作为多种 操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分为 抢占式(Preemptive Mode) 和 非抢占式(Nonpreemptive Mode) 。 这里的调度算法采用 抢占式(Preemptive Mode) 优先级调度。 在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi&gt;Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。 模拟算法如下： package process.schedule; import controlblock.PCB; import java.util.LinkedList; import java.util.List; /** * 优先权调度(抢占式) * * @author wz * * @date 2015年11月10日 */ public class PSA { protected LinkedList&lt;PCB&gt; processQueue; public PSA() { processQueue = new LinkedList&lt;&gt;(); } public void schedule() { sortByArriveTime(processQueue); PCB process, tempProcess; int arriveTime, needTime, runTime, currentTime = 0; while (!processQueue.isEmpty()) { process = processQueue.pollFirst(); arriveTime = process.getArriveTime(); if (currentTime &lt; arriveTime) currentTime = arriveTime; for (int i = 0; i &lt; processQueue.size(); i++) { needTime = process.getNeedTime(); tempProcess = processQueue.get(i); if (tempProcess.getArriveTime() &gt; currentTime + needTime) break; // 当前进程执行至被高优先级进程抢占 if (tempProcess.getPriority() &lt; process.getPriority()) { if (tempProcess.getArriveTime() != currentTime) { processQueue.remove(i); System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,优先级：&quot; + (int) process.getPriority() + &quot;,到达时间：&quot; + process.getArriveTime() + &quot;,需要时间:&quot; + process.getNeedTime() + &quot;,开始时间：&quot; + currentTime + &quot;,&quot;); runTime = tempProcess.getArriveTime() - currentTime; process.setNeedTime(needTime - runTime); currentTime += runTime; System.out.println(&quot;进程中断时间：&quot; + currentTime); processQueue.addFirst(process); process = tempProcess; } else { processQueue.set(i, process); process = tempProcess; tempProcess = processQueue.get(i); // needTime = process.getNeedTime(); } } else { subSortByPriority(processQueue, 0, i + 1); } } System.out.print(&quot;进程：&quot; + process.getPid() + &quot;,优先级：&quot; + (int) process.getPriority() + &quot;,到达时间：&quot; + process.getArriveTime() + &quot;,需要时间:&quot; + process.getNeedTime() + &quot;,开始时间：&quot; + currentTime + &quot;,&quot;); currentTime += process.getNeedTime(); System.out.println(&quot;结束时间：&quot; + currentTime); } } public void addProcess(int pid, int priority, int arriveTime, int needTime) { processQueue.push(new PCB(pid, priority, arriveTime, needTime)); } /** * 对进程队列按到达时间排序 * * @param processQueue */ private &lt;T&gt; void sortByArriveTime(LinkedList&lt;PCB&gt; processQueue) { processQueue.sort((p1, p2) -&gt; { Integer p1Time = p1.getArriveTime(); Integer p2Time = p2.getArriveTime(); return p1Time.compareTo(p2Time); }); } /** * 对指定子队列按优先级排序 * * @param processQueue * @param fromIndex * @param toIndex */ private void subSortByPriority(LinkedList&lt;PCB&gt; processQueue, int fromIndex, int toIndex) { List&lt;PCB&gt; subQueue = processQueue.subList(fromIndex, toIndex); subQueue.sort((p1, p2) -&gt; { Double p1Priority = p1.getPriority(); Double p2Priority = p2.getPriority(); return p1Priority.compareTo(p2Priority); }); } } 具体思想是用随机数生成多个PCB对象，放入PSA的进程队列processQueue中，然后： ①按照进程的到达时间递增排序，在队列不为空的情况下执行② ②队首PCB出队(第一个到达的作业或优先级最高的作业) ③遍历进程队列，查找当前PCB结束时间前到达的所有PCB，若优先级高于当前执行的作业，执行④，否则执行⑤ ④此时 当前作业执行至被高优先级作业抢占。 计算当前作业本次运行的开始时间、中断时间，并放入队首(优先级高的放在队首，当前执行作业是目前已查找到的优先级次高的作业)，将③查找到的高优先级的作业出队，成为当前执行的作业(高优先级作业抢占处理机)。然后继续执行③向后遍历 ⑤对队列中已经遍历的PCB按优先级递减就地排序(保证已到达进程按优先级递减排列)。若未遍历完，继续执行③向后遍历 ⑥计算当前进程本次执行的开始时间、结束时间。 ⑦若队列不为空，执行②，否则结束 暂时就写了这几种调度算法的模拟，下面是生成随机PCB测试的代码： package dispatcher; import java.util.Random; import process.schedule.FCFS; import process.schedule.HRRN; import process.schedule.PSA; import process.schedule.RR; import process.schedule.SJF; /** * 分派程序 * * @author wz * * @date 2015年11月10日 */ public class Dispatcher { private static final int MAX_ARRIVE_TIME = 5; private static final int MAX_NEED_TIME = 10; private static final int MAX_PROCESS_NUM = 5; private static final int MAX_PRIORITY = 10; private final static int MAX_PID = 10000; public static void main(String[] args) { FCFSSchedule(); SJFSchedule(); RRShedule(); PSAShedule(); HRRNShedule(); } /** * 高响应比优先调度 */ private static void HRRNShedule() { HRRN hrrn = new HRRN(); HRRN ps = hrrn; Random random = new Random(); for (int i = 0; i &lt; MAX_PROCESS_NUM; i++) { ps.addProcess(random.nextInt(MAX_PID), random.nextInt(MAX_ARRIVE_TIME), random.nextInt(MAX_NEED_TIME) + 1); } ps.schedule(); } /** * 优先权调度(抢占式) */ private static void PSAShedule() { PSA ps = new PSA(); Random random = new Random(); for (int i = 0; i &lt; MAX_PROCESS_NUM; i++) { ps.addProcess(random.nextInt(MAX_PID), random.nextInt(MAX_PRIORITY), random.nextInt(MAX_ARRIVE_TIME), random.nextInt(MAX_NEED_TIME) + 1); } ps.schedule(); } /** * 时间片轮转调度 */ private static void RRShedule() { RR ps = new RR(); Random random = new Random(); for (int i = 0; i &lt; MAX_PROCESS_NUM; i++) { ps.addProcess(random.nextInt(MAX_PID), random.nextInt(MAX_ARRIVE_TIME), random.nextInt(MAX_NEED_TIME) + 1); } ps.schedule(); } /** * 先到先服务 */ private static void FCFSSchedule() { FCFS ps = new FCFS(); Random random = new Random(); for (int i = 0; i &lt; MAX_PROCESS_NUM; i++) { ps.addProcess(random.nextInt(MAX_PID), random.nextInt(MAX_ARRIVE_TIME), random.nextInt(MAX_NEED_TIME) + 1); } ps.schedule(); } /** * 短作业优先调度 */ private static void SJFSchedule() { SJF ps = new SJF(); Random random = new Random(); for (int i = 0; i &lt; MAX_PROCESS_NUM; i++) { ps.addProcess(random.nextInt(MAX_PID), random.nextInt(MAX_ARRIVE_TIME), random.nextInt(MAX_NEED_TIME) + 1); } ps.schedule(); } public static int getMaxNeedTime() { return MAX_NEED_TIME; } } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>进程调度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归与分治之棋盘覆盖问题]]></title>
    <url>%2F2015%2F11%2F26%2F%E9%80%92%E5%BD%92%E4%B8%8E%E5%88%86%E6%B2%BB%E4%B9%8B%E6%A3%8B%E7%9B%98%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在一个2^k * 2^k个方格组成的棋盘中,若有一个方格与其他方格不同,则称该方格为一特殊方格,且称该棋盘为一个特殊棋盘。 显然特殊方格在棋盘上出现的位置有4^k种情形.因而对任何k≥0,有4^k种不同的特殊棋盘。 下图所示的特殊棋盘为 k=2 时 16 个特殊棋盘中的一个。 在棋盘覆盖问题中，要用下图中 4 中不同形态的 L 型骨牌覆盖一个给定的特殊棋牌上除特殊方格以外的所有方格，且任何 2 个 L 型骨牌不得重叠覆盖。 易知，在任何一个 2^k * 2^k 的棋盘中，用到的 L 型骨牌个数恰为 (4^k-1)/3 。 求解棋盘问题，可利用分治的策略。当 k&gt;0 时，将 2^k 2^k 棋盘分割为 4 个 2^(k-1) 2^(k-1) 子棋盘，如下图所示。 特殊方格必位于 4 个子棋盘之一，其余 3 个子棋盘中无特殊方格。用一个 L 型骨牌覆盖这 3 个较小的棋盘的汇合处，如图所示，将这 3 个无特殊方格的子棋盘转化为特殊棋盘，从而将原问题化为 4 个较小规模的棋盘覆盖问题。递归的使用 这种分割，直至棋盘简化为 1x1 棋盘。 python实现代码如下： # coding =gbk # tr左上角行号，tc左上角列号。dr特殊方格行号，dc特殊方格列号 def chessboard(board, size, tr, tc, dr, dc): if size &lt;= 1: return global tile tile += 1 current_tile = tile size //= 2 if dr &lt; tr + size and dc &lt; tc + size: chessboard(board, size, tr, tc, dr, dc) else: board[tr + size - 1][tc + size - 1] = current_tile chessboard(board, size, tr, tc, tr + size - 1, tc + size - 1) if dr &gt;= tr + size and dc &lt; tc + size: chessboard(board, size, tr + size, tc, dr, dc) else: board[tr + size][tc + size - 1] = current_tile chessboard(board, size, tr + size, tc, tr + size, tc + size - 1) if dr &lt; tr + size and dc &gt;= tc + size: chessboard(board, size, tr, tc + size, dr, dc) else: board[tr + size - 1][tc + size] = current_tile chessboard(board, size, tr, tc + size, tr + size - 1, tc + size) if dr &gt;= tr + size and dc &gt;= tc + size: chessboard(board, size, tr + size, tc + size, dr, dc) else: board[tr + size][tc + size] = current_tile chessboard(board, size, tr + size, tc + size, tr + size, tc + size) tile = 0 chessboard_size = 4 board = [[0 for x in range(chessboard_size)] for y in range(chessboard_size)] chessboard(board, chessboard_size, 0, 0, 1, 0) board = [[row[i] for row in board] for i in range(len(board[0]))] for lst in board: print(lst) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>递归</tag>
        <tag>分治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 使用函数辅助查询]]></title>
    <url>%2F2015%2F11%2F26%2Fsql%20server%20%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0%E8%BE%85%E5%8A%A9%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[函数是所有语言系统下都具备的内部数据处理过程，SQL SERVER也同样内置了许多函数。在SQL SERVER中，函数是由一个或多个T-SQL语句组成的子程序。利用函数可以简化数据的处理操作。 函数分为 内置函数 和 用户定义函数 两种。用户定义函数接受零个或多个输入参数，并返回标量值或表。 一、数据类型转换函数 1、CAST(expression, AS date_type) 将表达式值转换为指定的数据类型。 例如： SELECT CAST ( ‘ 2015-10-15 ‘ AS datetime ) SELECT CAST ( GETDATE () AS char ) SELECT CAST ( ‘ 123 ‘ AS int ) 2、CONVERT(date_type[(length)], expression[,style]) 与CAST函数相似， date_type(length) 规定目标数据类型。 style 规定日期/时间的输出格式。 下表为日期型与字符型转换时 style的取值。 例如： SELECT CONVERT ( char , GETDATE (), 101 ) style取值 无世纪值 | style取值 有世纪值 | 标准 | 输入/输出 —|—|—|—| 0或100 | 默认值 | mm dd yyyy hh:miAM(或)PM 1 | 101 | 美国 | mm/dd/yyyy 2 | 102 | ANSI | mm dd yyyy hh:miAM(或)PM | 9或109 | 默认值＋毫秒 | mm-dd-yy 10 | 110 | 美国 | yymmdd 12 | 112 | ISO | 二、 日期函数 1、GETDATE() 该函数返回当前系统日期时间。 例如： SELECT GETDATE () 返回结果：2009-02-22 23:05:52.483 2 、DATEPART(datepart,date_expression) 返回日期表达式值的指定部分， 返回值为数值型数据。 例如： SELECT DATEPART ( YEAR , GETDATE ()) SELECT DATEPART ( MONTH , GETDATE ()) SELECT DATEPART ( DAY , GETDATE ()) date型数据日期部分的可能取值: datepart | 缩 写 | 说 明 —|—|— year | yy, yyyy | 年 quarter | qq, q | 季度 month | mm, m | 月 Day of year | dy, y | 一年中的第几天 day | dd, d | 一月中的第几天 week | wk, ww | 一年中的第几周 hour | hh | 小时 minute | mi, n | 分 second | ss, s | 秒 millisecond | ms | 千分之一秒 3、DATENAME(datepart,date_expression) 该函数返回日期表达式值的指定部分的名称, 返回值为字符型数据。例如： SELECT DATENAME ( YEAR , GETDATE ()) SELECT DATENAME (WEEKDAY, GETDATE ()) 4、DATEADD(datepart, interge_expression, date_expression ) 该函数返回日期表达式值的指定部分， 加上整数表达式值后的日期时间。 SELECT DATEADD ( day , 10 , GETDATE ()) 5、DATEDIFF(datepart, date_expression1, date_expression2) 该函数返回日期表达式1的值和日期表达式2的 值在指定部分的差值。例如： 1 DECLARE @t1 datetime,@t2 datetime 2 SET @t1=GETDATE() 3 WAITFOR delay &apos;00:00:02&apos; 4 SET @t2=GETDATE() 5 SELECT DATEDIFF(SECOND,@t1, @t2) 6、DAY(date_expression) 该函数返回日期表达式值的“日”部分。 例如： SELECT DAY ( GETDATE ()) 7、MONTH(date_expression) 该函数返回日期表达式值的“月”部分。 例如： SELECT MONTH ( GETDATE ()) 8、YEAR(date_expression) 该函数返回日期表达式值的“年”部分。 例如： SELECT YEAR ( GETDATE ()) 9、getutcdate 返回当前utc时间(世界标准时间)。 例如： select getutcdate() 三、 聚合函数 1、COUNT([ALL | DISTINCT]expression | * ) 2、AVG( ), MAX( ), MIN( ), SUM( ) 3、VAR( ), VARP( ), STDEV( ), STDEVP( ) 四、 数学函数 1、ABS(numeric_expression) 该函数返回表达式值（bit型除外）的绝对值，返回值的数据类型与原数据类型一致。 例如： SELECT ABS ( - 3.0 ), ABS ( 2.0 ), ABS ( 0.0 ) 2、AVG([ALL|DISTINCT]numeric_expression) 该函数返回查询出的一组数据的平均值。 例如： SELECT AVG (grade) from score where cno = 1 3、COUNT([ALL | DISTINCT]expression | * ) 该函数返回查询出的表达式数。 例如： SELECT count (grade) from score where cno = 1 4、CEILING(numeric_expression) 返回最小的大于或等于表达式值的整数值。 例如： SELECT CEILING ($ 99.99 ), CEILING ($ - 99.99 ) , CEILING ($ 0.0 ) 5、FLOOR(numeric_expression) 返回最大的小于或等于表达式值的整数值。 例如： SELECT FLOOR ($ 99.99 ), FLOOR ($ - 99.99 ) , FLOOR ($ 0.0 ) 6、RAND([integer_expression]) 该函数返回一个位于0与1之间的随机数。表达式值作为产生随机数的起始值，返回值为浮点型数。 例如： DECLARE @number smallint SET @number=1 WHILE (@number&lt;=3) BEGIN SELECT RAND(@number) SET @number=@number+1 END GO 7、ROUND(numeric_expression, int_expression1, [integer_expression2]) 当 int_expression1 为正数时，numeric_expression 四舍五入为 int_expression1所指定的小数位数。 当 int_expression1为负数时，numeric_expression 则按 int_expression1所指定的位数在小数点的左边四舍五入. 当 int_expression2 非零时，表示用int_expression1表示的精度对numeric_expression进行截短。 SELECT ROUND （ 2456.12582 , 3 ） 返回结果为2456.12600。 SELECT ROUND （ 2456.12582 , 3 , 1 ） 返回值为2456.12500。 ROUND ( 748.58 , - 1 ) 返回值为750.00 ROUND ( 748.58 , - 2 ) 返回值为700.00 ROUND ( 748.58 , - 4 ) 返回值为0 五、 字符串函数 1、ASCII(chracter_expression) 返回字符的ASCII码值，返回值为整型数据。 例如： SELECT ASCII ( ‘ a ‘ ), ASCII (‘Z’) 返回结果为：97 90 2、CHAR（inter_expression） 该函数返回ASCII码值代表的字符。 例如： SELECT CHAR ( 97 ), CHAR ( 90 ) 返回结果为：a Z 3、LEN(charater_expression) 该函数返回字符串的长度，即字符的个数， 注意1个汉字计为一个字符。 例如： SELECT len ( ‘ 张三 ‘ ), len ( ‘ abc ‘ ) 返回结果为：2 3 4、DATALENGTH(expression) 返回表达式所占用的字节数， 常用于查看变长数据类型的长度。 select datalengh(‘ 100 ’), datalength ( 100 ) 5、LEFT(chracter_expression, integer_expression) 返回字符串从左边开始指定个数的字符。 select LEFT ( ‘ sdf ‘ , 1 ) +LEFT ( ‘ qlsdf ‘ , 2 ) 6、RIGHT(chracter_expression, integer_expression) 返回字符串从右边开始指定个数的字符。 7、SUBSTRING(chracter_expression, begin_integer_expression, lenth_integer_expression ) 返回字符串在起始位置开始的指定长度的子串。 例如： SELECT SUBSTRING ( ‘ traffic ‘ , 3 , 4 ) 8、UPPER(chracter_expression) 该函数返回字符的大写形式。 例如： SELECT upper ( ‘ traffic’) 9、LOWER(chracter_expression) 该函数返回字符的小写形式。 10、SPACE(integer_expression) 该函数返回指定长度的空格字符串。 SELECT ‘ 放假 ‘ + SPACE ( 6 ) + ‘ 美呀！ ‘ 11、REPLICATE(chracter_expression, integer_expression) 该函数将字符串复制指定的遍数。 例如： SELECT REPLICATE (‘SQL’, 3 ) 返回结果为：SQLSQLSQL 12、STUFF(chracter_expression1, begin_integer_expression,length, chracter_expression2) 该函数将字符串1从开始位置到结束位置中的 字符删去然后将字符串2填充进去。 SELECT STUFF (‘SQlver’, 3 , 1 ,’L Ser’) 13、REVERSE(chracter_expression) 该函数返回字符串的反序字符串。 SELECT REVERSE (‘SQL’) 14、LTRIM(chracter_expression) 该函数返回删除字符串左端空格后的字符串。 SELECT LEN (‘ SQL‘), LEN ( LTRIM (‘ SQL‘)) 15、RTRIM(chracter_expression) 该函数返回删除字符串右端空格后的字符串。 16、STR(float_expression[ integer_expr ession1[,integer_expression2]]) 该函数返回浮点表达式值的字符串形式。 表达式1为字符串长度，表达式2为小数位数。 若无表达式2，默认为0； 若无表达式1，默认为浮点数的整数部分长度。 例如： SELECT STR( **123.456** ), STR( **123.456** , **4** , **1** ),STR( **123.456** , **6** , **4** ) 返回结果为：123 123 123.46 六、 判定函数 1、ISDATE(expression) 该函数判断表达式是否为一个合法的日期型 数据，是则返回1，否则返回0。 1 IF ISDATE(&apos;2009-05-12 10:19:41.177&apos;)= **1** PRINT &apos;VALID&apos; 2 ELSE 3 PRINT &apos;INVALID&apos; 2、ISNUMERIC(expression) 该函数判断表达式是否为一个合法的数值型 数据（包括整数型、数值型和浮点型）， 是则返回1，否则返回0。 SELECT ISNUMERIC ( 56.6 ) SELECT ISNUMERIC ( ‘ hello ‘ ) 3、ISNULL(expression1,expression2) 该函数判断表达式1的值是否为NULL， 是则返回表达式2的值， 不是则返回表达式1的值。例如： SELECT SNO,CNO, ISNULL (grade, 0 ) FROM SCORE 4、NULLIF(expression1,expression2) 该函数判断表达式1的值是否与表达式2的值相等，是则返回NULL，否则返回表达式1的值。 SELECT NULLIF (‘ABc’,’AB’) SELECT NULLIF (‘AB’,’AB’) 七、 用户自定义函数 1、标量值函数的定义 CREATE FUNCTION [所有者名.]函数名 ([{形式参数[AS]类型[=默认值]}[,…n]]) RETURNS 返回值类型 [AS] BEGIN 函数体 RETURN 标量表达 END 参数说明： 1) 形式参数的数据类型为系统的基本标量类型，不能为timestamp类型、用户定义数据类型和非标量类型 （如cursor和table）。 2) 返回值类型为系统的基本标量类型，但text、ntext、image和timestamp除外。 3) 函数体由T-SQL语句序列构成。 4) 函数返回标量表达式的值。 2、表值函数的定义 CREATE FUNCTION [所有者名.] 函数名([{形式参数[AS]类型[=默认值]}[,…n]]) RETURNS TABLE [AS] RETURN [(select语句)] 参数说明： 1)形式参数的数据类型为系统的基本标量类型，不能为timestamp类型、用户定义数据类型和非标量类型 （如cursor和table）。 2) TABLE关健字指定此函数返回一个表. 3) 函数返回select语句的结果。 当调用用户自定义函数时，必须提供函数名和参数，标量函数可以在SELECT语句中调用，或用EXEC语句执行调用，调用形式分别为：所有者名.函数名（实参1, 实参2, …实参n） 其中用EXEC语句调用时参数次序可与定义时不同，表型函数只能通过SELECT语句调用。 可有两种方法删除用户已定义的函数即用命令方式和界面方式， 命令格式为： DROP FUNCTION {[owner_name]function_name}[,…n] 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server T-SQL 基础]]></title>
    <url>%2F2015%2F11%2F18%2Fsql%20server%20T-SQL%20%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[SQL语言按照用途可以分为如下3类： ① DDL(Data Definition Language) 数据定义语言： 定义修改和删除数据库、表、索引和视图等 ② DML(Data Manipulation Language) 数据处理语言： 对数据进行查询(SELECT)、插入(INSERT)、删除(DELETE)、更新(UPDATE)等 ③ DCL(Data Control Language) 数据控制语言： 对数据库对象的权限管理和事务管理 一、T-SQL语法基础 1.标识符 在SQL Server中，标识符就是指用来定义服务器、数据库、数据库对象和变量等的名称。 ①.常规标识符 常规标识符是指符合标识符的格式规则不需要使用分隔符进行分隔的标识符。 标识符的格式规则，如： Select * from book where bname = “C程序” 中的book和bname。 命名规则： 1）第一个字符：字母、_、@和# 2）后续字符可以是字母、数字、@、$、#或_ 3）标识符不可以是保留字 4）不允许嵌入空格或其他特殊字符 5）字符数在1-128之间。 特殊意义的标识符： 1）以@开始的标识符表示局部变量 2）以@@开始的标识符表示全局变量 3）以#开始的标识符表示临时表或过程 4）以##开始的标识符表示全局临时对象 ②. 分隔标识符 分隔标识符在下列情况下使用： 当在对象名称或对象名称的组成部分中使用保留字时 当使用未被列为合法标识符的字符时 T-SQL使用的两种分隔符： 1） 双引号（”） 。（当QUOTED_IDENTIFIER设为ON时有效） 例如： SELECT * FROM “ My Table “ 2） 方括号（[ ]） 。 例如： SELECT * FROM [ My Table ] 分隔标识符的格式规则 2.常量 常量是指在程序运行过程中值始终不变的值。 3.变量 在SQL Server中，变量分为局部变量和全局变量 1）局部变量 前面有一个@字符，由用户定义和使用。 2）全局变量 名称前面有两个@字符，由系统定义和维护。 1） 局部变量 局部变量由用户定义，仅在声明它的批处理、存储过程或者触发器中有效。 局部变量的定义： DECLARE { @local_variable data_type }[,…n] 注：变量不能是text、ntext或image数据类型 例： DECLARE @grade int ， @sex char ( 2 ) 给变量赋值，可用set或select语句，如： Set @local_variable=expression Select {@local_variable=expression} [,…n] 例如： DECLARE @grade int,@sex char(2) set @grade=60 select @sex=&apos;女‘ select @grade, @sex 2）全局变量 全局变量记录了SQL Server的各种状态信息，它们不能被显示地赋值或声明，而且不能被用户定义。 4.运算符 运算符是一种符号，用来指定要在一个或多个表达式中执行的操作。 SQL Server提供的运算符：算术运算符，赋值运算符，按位运算符，比较运算符，逻辑运算符，字符串运算符，一元运算符 赋值运算符: = 算术运算符: + - * / % 字符串连接运算符： + 比较运算符: &gt; &lt; = &gt;= &lt;= != &lt;&gt; !&lt; !&gt; 逻辑运算符: NOT AND OR BETWEEN EXISTS IN LIKE SOME ANY ALL 一元运算符：+ 正 -负 ~位反 按位运算符: &amp; 按位与 |按位或 ^按位异或 运算符优先级: +（正）、-（负）、～（按位NOT） *、/、% +（加）、+（连接）、-（减） =、&gt;、&lt;、&gt;=、&lt;=、&lt;&gt;、!=、!&gt;、!&lt; ^（按位异或）、&amp;（按位与）、|（按位或） NOT AND ALL、ANY、BETWEEN、IN、LIKE、OR、 =（赋值） 5.流程控制语句 控制流语句是用来控制程序执行流程的语句，使用控制流语句可以在程序中组织语句的执行流程，提高编程语言的处理能力。 T-SQL提供控制流关键字，用于控制语句、语句块和存储过程的执行流。 控制流语句 | 说明 —|— BEGIN…END | 定义语句块 IF…ELSE | 条件处理语句，如果条件成立，执行IF语句； 否则执行ELSE语句 CASE | 分支语句 WHILE | 循环语句 GOTO | 无条件跳转语句 RETURN | 无条件退出语句 WAITFOR | 延迟语句 BREAK | 跳出循环语句 CONTINUE | 重新开始循环语句 ① BEGIN…END语句 BEGIN…END语句用于将多个Transact-SQL语句组合为一个逻辑块。 语法格式为： BEGIN { sql语句|语句块 } END 下面几种情况经常要用到BEGIN和END语句： WHILE循环需要包含语句块。 CASE语句的分支包含语句块。 IF或ELSE子句需要包含语句块。 ② IF…ELSE语句 使用IF…ELSE语句，可以有条件地执行语句。其语法格式如下： IF Boolean_expression {sql语句|语句块} [ELSE {sql语句|语句块}] ③CASE语句 使用CASE语句可以进行多个分支的选择。CASE具有两种格式： 简单CASE格式：将某个表达式与一组表达式进行比较以确定结果。 搜索CASE格式：计算一组布尔表达式以确定结果。 注： CASE语句只能用于SQL语句的一部分，不能独立成句。 1）简单CASE格式 其语法格式如下： CASE input_expression WHEN when_expression THEN result_expression […n] [ELSE else_result_expression] END 注： input_expression和每个when_expression的数据类型必须相同或隐形转换。 如果未找到匹配值，也没有else子句，则返回null。 2）搜索CASE格式 其语法格式如下： CASE WHEN Boolean_expression THEN result_expression […n] [ELSE else_result_expression] END 注：如果Boolean_expression表达式的值为true，则返回then后的表达式，然后跳出case语句。 ④ WHILE语句 WHILE语句可以重复执行若干SQL语句。 其语法格式如下： WHILE Boolean_expression {sql语句|语句块} [BREAK] {sql语句|语句块} [CONTINUE] ⑤GOTO语句 GOTO语句可以实现无条件的跳转。其语法格式为： GOTO lable ⑥ RETURN语句 使用RETURN语句，可以从查询或过程中无条件退出。可在任何时候用于从过程、批处理或语句块中退出，而不执行位于RETURN之后的语句。 语法格式为： RETURN [integer_expression] 其中：integer_expression为一个整数值，是return语句要返回的值。 ⑦ WAITFOR语句 使用WAITFOR语句，可以在指定的时间或者过了一定时间后，执行语句块、存储过程或者事务。 其语法格式为： WAITFOR {DELAY ‘time’ | TIME ‘time’} ⑧try…catch语句 实现错误处理功能。 其语法格式为： Begin try {sql_statement|sql_block} End try Begin catch {sql_statement|sql_block} End catch 6.注释 SQL Server的两种注释字符： ① –（双连字符） 这些注释字符可与要执行的代码处在同一行，也可另起一行。从双连字符开始到行尾均为注释。 ② /…/（正斜杠-星号对） 从开始注释对（/）到结束注释对（/）之间的全部内容均视为注释部分。可对多行注释。 7.游标的使用 游标包括以下两个部分： ①游标结果集 定义该游标的SELECT语句返回的行的集合。 ②游标位置 指向这个集合中某一行的指针。 游标的典型使用过程 ： 1） 声明游标 声明游标使用DECLARE CURSOR语句，格式如下： DECLARE cursor_name [ SCROLL ] CURSOR FOR select_statement [ FOR { READ ONLY | UPDATE [ OF column_name [ , …n ] ] } ] 其中： cursor_name：所定义游标名称。 SCROLL：指定所有的提取选项（FIRST、LAST、PRIOR、NEXT、RELATIVE、ABSOLUTE）均可用。如果未指定 SCROLL，默认 NEXT。 lselect_statement：是定义游标结果集的标准 SELECT 语句。 UPDATE [OF column_name [,…n]]：定义游标内可更新的列。如果指定 OF column_name [,…n] 参数，则只允许修改所列出的列。如果在 UPDATE 中未指定列的列表，则可以更新所有列。 2） 打开游标 打开游标使用OPEN语句，其语法格式如下： OPEN { { [ GLOBAL ] cursor_name } | cursor_variable_name } 其中： GLOBAL：指定 cursor_name 为全局游标。 cursor_name：已声明的游标的名称。如果全局游标和局部游标都使用 cursor_name 作为其名称，那么如果指定了 GLOBAL，cursor_name 指的是全局游标，否则 cursor_name 指的是局部游标。 cursor_variable_name：游标变量的名称，该名称引用一个游标。 3）从打开的游标中提取行 格式： FETCH [ [ NEXT | PRIOR | FIRST | LAST | ABSOLUTE { n | @nvar } | RELATIVE { n | @nvar } ] FROM ] { { [ GLOBAL ] cursor_name } | @cursor_variable_name } [ INTO @variable_name [ , …n ] ] 其中： NEXT：返回紧跟当前行之后的结果行。 PRIOR：返回紧临当前行前面的结果行。 FIRST：返回游标中的第一行并将其作为当前行。 LAST：返回游标中的最后一行并将其作为当前行。 ABSOLUTE {n | @nvar}：如果 n 或 @nvar 为正数，返回从游标头开始的第 n 行并将返回的行变成新的当前行。如果 n 或 @nvar 为负数，返回游标尾之前的第 n 行并将返回的行变成新的当前行。如果 n 或 @nvar 为 0，则没有行返回。 RELATIVE {n | @nvar}：如果 n 或 @nvar 为正数，返回当前行之后的第 n 行并将返回的行变成新的当前行。如果 n 或 @nvar 为负数，返回当前行之前的第 n 行并将返回的行变成新的当前行。如果 n 或 @nvar 为 0，返回当前行。 GLOBAL：指定 cursor_name 指的是全局游标。 cursor_name：要从中进行提取的开放游标的名称。 @cursor_variable_name：游标变量名，引用要进行提取操作的打开的游标。 INTO @variable_name[,…n]：允许将提取操作的列数据放到局部变量中。 @@FETCH_STATUS()函数 该函数报告上一个FETCH语句的状态，其取值和含义如表所示。 取值 | 含义 —|— 0 | FETCH语句成功 -1 | FETCH语句失败或此行不在结果集中 -2 | 被提取的行不存在 @@ROWCOUNT 全局变量 用来提供游标活动信息，它返回受上一语句影响的行数。 4）关闭游标 关闭游标使用CLOSE语句，其语法格式如下： CLOSE { { [ GLOBAL ] cursor_name } | cursor_variable_name } 5） 释放游标 释放游标将释放所有分配给此游标的资源。格式为： DEALLOCATE { { [ GLOBAL ] cursor_name } | @cursor_variable_name } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
        <tag>T-SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 2008 数据库的完整性约束]]></title>
    <url>%2F2015%2F11%2F14%2Fsql%20server%202008%20%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AE%8C%E6%95%B4%E6%80%A7%E7%BA%A6%E6%9D%9F%2F</url>
    <content type="text"><![CDATA[一、数据库完整性概述 1.数据库的完整性： ①数据库的完整性是指数据的正确性和相容性 ②数据库完整性是防止不合语义或不正确的数据进入数据库 ③完整性体现了是否真实地反映现实世界 例: 学生的年龄必须是整数，取值范围为14-29； 学生的性别只能是男或女； 学生的学号一定是唯一的； 学生所在的系必须是学校开设的系； 2.DBMS维护数据库完整性的机制： ①提供定义完整性约束条件的机制 DBMS应提供定义数据库完整性约束条件，并把它们存入数据库中。 ②提供完整性检查的方法 检查数据是否满足完整性约束条件的机制称为完整性检查。一般在INSERT、UPDATE、DELETE语句执行后开始检查。 3.违约处理 DBMS若发现用户的操作违背了完整性约束条件，就采取一定的动作以保证数据的完整性，如拒绝执行该操作，或级联执行其他操作。 二、缺省(默认值)和规则 缺省 和 规则 来源于由Sybase开发的S默认值QL Server，在老版本的SQL Server或者升级版本中都有缺省和规则的使用。 缺省 是为列提供数据的一种方式，如果用户进行INSERT操作时不为列输入数据，则使用缺省值。 规则 是当用户进行INSERT或uPDATE操作时，对输入列中的数据设定的取值范围，是实现域完整性的方式之一。 缺省与规则有以下特点： (1)缺省与规则是数据库对象，它们是独立于表和列而建立的。 (2)缺省与规则建立后与列或数据类型产生关联，列和数据类型就具有了缺省与规则的属性。 (3)缺省与规则定义后，可以重复使用，可以绑定到多个列或数据类型上。 (4)缺省与规则不随表同时调入内存，当用到时才被调入内存，这可能会使程序执行出现延时。 缺省和规则对象通常 只在它所创建的数据库中有效， 不是ANSI标准， 一般不提倡使用。 应尽可能使用约束，任何可以使用缺省与规则的地方都有可以使用约束。 1. 缺省 在SQL Server中，有两种使用默认值的方法： ①在创建表时，指定默认值。 用SQL Server Management Studio创建表时在设计表时指定默认值，可以在输入字段名称后，设定该字段的默认值。 或使用CREATE TABLE语句中的DEFAULT子句指定默认值。 ②使用CREATE DEFAULT语句创建默认对象后，使用存储过程sp_bindefault将该默认对象绑定到列上。 默认值对象是单独存储的，删除表的时候，DEFAULT约束会自动删除，但是默认值对象不会被删除。 创建默认值对象后，需要将其绑定到某列或者用户自定义的数据类型上。 主要操作： ①创建默认值对象 ②绑定默认值对象 ③解除默认值对象的绑定 ④查看默认值对象 ⑤删除默认值对象 ①创建默认对象 可以使用CREATE DEFAULT语句创建默认对象。其语法格式如下： CREATE DEFAULT default AS constant_expression 例如： create default d_grade as 1 ②绑定默认对象 默认对象创建后不能使用，必须首先将其绑定到某列或者用户自定义的数据类型上。其使用语法格式如下： sp_bindefault [@defname = ] ‘default’, [@objname = ] ‘object_name’ [, [@futureonly = ] ‘futureonly_flag’] 其中： [, [@futureonly = ] ‘futureonly_flag’]仅在此之后将默认值绑定到用户定义的数据类型时才使用。 例如： exec sp_bindefault ‘ d_grade ‘ , ‘sc.grade ‘ ③解除默认对象的绑定 解除绑定可以使用sp_unbindefault存储过程。其语法格式如下： sp_unbindefault [@objname = ] ‘object_name’ 例如： exec sp_unbindefault ‘sc.grade ‘ ④查看默认对象 exec sp_help d_grade exec sp_helptext d_grade ⑤删除默认对象 在删除默认对象之前，首先要确认默认对象已经解除绑定。删除默认对象使用DROP DEFAULT语句。其语法格式如下： DROP DEFAULT {default} [,…n] 例如： drop default d_grade 2.规则 规则用以限制存储在表中或用户自定义数据类型的值，是独立的数据库对象。 将规则绑定到列或用户自定义数据类型时，规则才起作用。 表中的每列或每个用户定义数据类型只能和一个规则绑定。但每列可应用多个CHECK约束。 如果要删除规则，应确定规则已经解除绑定。 ①创建规则 CREATE RULE语句，其语法格式如下： CREATE RULE rulename AS condition_expression 其中各参数含义如下： rulename 是新规则的名称。 condition_expression 是定义规则的条件。 例如： create rule r_grade as @grade &lt;= 100 and @grade &gt;=0 ②绑定规则 使用sp_bindrule存储过程，语法格式为： sp_bindrule [@rulename = ] ‘rulename’, [@objname = ] ‘object_name’ 例如： exec sp_bindrule ‘ r_grade ‘ , ‘ sc.grade‘ 注意： 规则不能绑定到text、image或timestamp列。 如果规则与绑定的列不兼容，SQL Server将在插入值时返回错误信息。 未解除绑定的规则，如果再次将一个新的规则绑定到列，旧的规则将自动被解除，只有最近一次绑定的规则有效 如果列中包含CHECK约束，则CHECK约束优先。 ③解除规则的绑定 使用sp_unbindrule存储过程。语法格式如下： sp_unbindrule [@objname = ] ‘object name’ [,[@futureonly = ] ‘futureonly_ lag’] 例如： exec sp_unbindrule ‘ sc.grade ‘ ④ 删除规则 首先要 解除规则的绑定，然后才能删除绑定 例如： drop rule r_grade 三、约束 SQL Server 2008提供的强制数据完整性的机制： ①PRIMARY KEY 约束 ②FOREIGN KEY 约束 ③UNIQUE 约束 ④CHECK 约束 ⑤NOT NULL（非空性） ⑥IDENTITY 约束 使用约束优先于使用触发器、规则和默认值 查询优化器使用约束定义生成高性能的查询执行计划 ①PRIMARY KEY 约束： 可以在下面情况下使用： (1)作为表定义的一部分在创建表时创建。 (2)添加到尚没有PRIMARY KEY约束的表中（一个表只能有一个PRIMARY KEY约束）。 (3)如果已有PRIMARY KEY约束，则可对其进行修改或删除。 特点： (1)每个表都应有一个主键，主键值唯一。 (2)主键内的任何列不能为空（null）。 (3)要使用TRansact-SQL修改PRIMARY KEY，必须先删除现有的PRIMARY KEY约束，然后再重新创建。 (4)创建表时指定主键，sql server会自动创建一个名为“PK_”且后跟表名的主键索引。如果不指定索引类型，则默认为聚集索引。该索引只能在删除与它保持联系的表或主键约束时才能删除。 ②FOREIGN KEY约束 标识表之间的关系，用于强制参照完整性，为表中一列或多列提供参照完整性。 FOREIGN KEY约束也可以参照自身表中的其他列（例如：学生表中的“班长学号”列参照“学号”列），这种参照称为自参照。 FOREIGN KEY约束可以在下面情况下使用： (1)作为表定义的一部分在创建表时创建。 (2)如果现有表的某列与另一个表已有的PRIMARY KEY约束或UNIQUE约束相关联，则可向现有表添加FOREIGN KEY约束。 (3)对已有的FOREIGN KEY约束进行修改或删除。 使用FOREIGN KEY约束，应注意的几个问题： (1)每个表最多可以有253个FOREIGN KEY约束。 (2)FOREIGN KEY约束只能参照同一个数据库中的表，而不能参照其他数据库中的表。 (3)FOREIGN KEY子句中的列数目和每个列指定的数据类型必须和REFERENCES子句中的列相同。 (4)FOREIGN KEY约束不能自动创建索引。 (5)在临时表中，不能使用FOREIGN KEY约束。 (6)如果一个外键没有对应的主键值，则不能插入带该值的行。 ③UNIQUE约束 (1)UNIQUE约束在列集内强制执行值的唯一性。 (2)对于UNIQUE约束中的列，表中不允许有两行包含相同的非空值。 (3)SQL Server创建了UNIQUE约束后会自动创建UNIQUE索引来强制UNIQUE约束的唯一性要求。 (4)如果插入重复行，SQL Server将返回错误信息。 (5)向表中的现有列添加UNIQUE约束时，默认情况下SQL Server 2008检查列中的现有数据确保除NULL外的所有值均唯一。 (6)UNIQUE约束与主键约束的区别： 主键也强制执行唯一性，但主键不允许空值，而且每个表中主键只能有一个，但UNIQUE列可以有多个，可以取空值。 (7)UNIQUE约束优先于唯一索引。 ④CHECK约束 (1)CHECK约束通过限制用户输入的值来加强域完整性。 (2)它指定应用于列中输入的所有值的布尔（取值为TRUE或FALSE）搜索条件，拒绝所有不取值为TRUE的值。 (3)可以为每列指定多个CHECK约束。 ⑤IDENTITY约束 自动编号约束又称作标识列，采用数字编号的方式依次增加一个增量。是为那些数字顺序递增的列准备的约束，可以自动完成数值添加。 (1)标识种子 (2)标识增量 (3)标识列的数据类型 四、完整性约束命名子句 完整性约束命名子句的格式： CONSTRAINT &lt;完整性约束条件名&gt;[PRIMARY KEY短语|FOREIGN KEY 短语|CHECK短语] 例：建立学生登记表Student2，要求学号在10000至99999之间，姓名不能取空值，年龄小于30，性别‘男’或‘女’： CREATE TABLE Student2( sno int CONSTRAINT C1 CHECK (sno BETWEEN 10000 AND 99999), sname CHAR(8) CONSTRAINT C2 NOT NULL, sage int CONSTRAINT C3 CHECK (sage&lt;30), ssex VARCHAR(2) CONSTRAINT C4 CHECK (ssex IN (&apos;男&apos;, &apos;女&apos;)), CONSTRAINT SK PRIMARY KEY(Sno) ); 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 2008 操作数据表]]></title>
    <url>%2F2015%2F11%2F13%2Fsql%20server%202008%20%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[SQL Server表 表的类型： ①临时表 临时表可用来处理中间数据或者用临时表 与其它连接共享进行中的工作。临时表只 能放在tempdb中。 私有临时表（#） 全局临时表（##） ②系统表 用来存储所有数据库对象、数据类型、约束、 配置选项等相关信息的表。 属性的数据类型 1.基本数据类型: ①精确数字类型 ②近似数字类型 ③Unicode字符类型 ④二进制类型 ⑤日期和时间类型 ⑥字符串类型 其他 2.用户自定义的数据类型: ①数据类型的名称 ②所基于的系统内置数据类型 ③是否允许为空 可以使用系统存储过程管理自定义的数据类型 sp_addtype [@typename=] type, [@phystype=] system_data_type [], [@nulltype=] ‘null_type’ 例如： sp_addtype phone1, ‘ char(11) ‘ , ‘ not null ‘ 使用系统存储过程删除自定义的数据类型 例如： sp_droptype phone1 创建数据表 1.使用SQLSMS创建 2.使用SQL语句创建 create table tabel_name ( colomn_name data_type [identity [(seed,increment)] [&lt;colunm_constraint&gt;]]) 例如： create table sc( sno char(5), cno char(3), grade int check(grade&gt;=0 and grade&lt;=100), primary key(sno,cno) ) 修改表 1.修改表名 ①使用SQLSMS重命名 ②使用系统存储过程 sp_rename [ @objname = ] ‘object_name’ , [ @newname = ] ‘new_name’ 例如 ： sp_rename ‘ sc ‘ , ‘ 选课 ‘ 2.修改表的属性 3.属性列 ①在表设计器中修改、增加和删除列 ②使用T-SQL语句修改和删除列，例如 alter table 选课 add grade1 int alter table 选课 drop column grade1 删除表 1.使用SQLSMS删除 2.使用SQL语句删除 例如： drop table 选课 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归与分治之快速排序]]></title>
    <url>%2F2015%2F11%2F13%2F%E9%80%92%E5%BD%92%E4%B8%8E%E5%88%86%E6%B2%BB%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[分治法 就是把一个大问题分解为多个类型相同的子问题，最后把这些子问题的解合并起来就是问题的解。 快速排序（Quicksort） 是对冒泡排序的一种改进，采用了分治的思想。 快排的基本思想： 通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，当待排序列数据个数为1时，自然是有序的，以此达到整个数据变成有序序列。 具体算法步骤： 对于待排序列，在一趟排序前，从待排序列中随机选取一个数据作为枢轴量， 使所有小于枢轴量的数据位于其左面，所有大于枢轴量的数据位于其右面， 然后再依次用该方法对其左面、右面的序列进行排序。 当待排序列个数为1时，代表该部分已经完成排序。 递归可完成整个序列的排序。 python代码实现如下： # coding=gbk import random import time __author__ = &apos;ice&apos; def quick_sort(arr, start, end): if start &lt; end: divide = partition(arr, start, end) quick_sort(arr, start, divide - 1) quick_sort(arr, divide + 1, end) def partition(arr, start, end): swap(arr, start, random.randint(start, end)) divide_value = arr[start] left = start right = end while left &lt; right: while arr[right] &gt; divide_value and right &gt; left: right -= 1 arr[left] = arr[right] while arr[left] &lt; divide_value and left &lt; right: left += 1 arr[right] = arr[left] arr[left] = divide_value return left def swap(arr, i, j): temp = arr[i] arr[i] = arr[j] arr[j] = temp array = [1, 5, 6, 8, 4, 3] start_time = time.clock() quick_sort(array, 0, len(array) - 1) end_time = time.clock() print(&apos;花费时间：&apos; + str(end_time - start_time)) print(array) # 花费时间：3.706176599885165e-05 # [1, 3, 4, 5, 6, 8] 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>分治法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法之背包问题]]></title>
    <url>%2F2015%2F11%2F13%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E4%B9%8B%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪心算法不是对所有问题都能得到整体最优解，关键是贪心策略的选择，选择的贪心策略必须具备无后效性，即某个状态以前的过程不会影响以后的状态，只与当前状态有关。 完全背包问题： 给定 n 个物品和一个容量为 C 的背包，物品 i 的重量是 Wi, 其价值为 Vi, 背包问题是如何选择入背包的物品，使得装入背包的物品的总价值最大，与 0-1 背包的区别是，在完全背包问题中， 可以将物品的一部分装入背包，但不能重复装入 。 设计算法的思路很简单，计算物品的单位价值，然后尽可能多的将单位重量价值高的物品放入背包中。 python实现代码如下： # coding=gbk # 完全背包问题，贪心算法 import time __author__ = &apos;ice&apos; class goods: def __init__(self, goods_id, weight=0, value=0): self.id = goods_id self.weight = weight self.value = value # 不适用于0-1背包 def knapsack(capacity=0, goods_set=[]): # 按单位价值量排序 goods_set.sort(key=lambda obj: obj.value / obj.weight, reverse=True) result = [] for a_goods in goods_set: if capacity &lt; a_goods.weight: break result.append(a_goods) capacity -= a_goods.weight if len(result) &lt; len(goods_set) and capacity != 0: result.append(goods(a_goods.id, capacity, a_goods.value * capacity / a_goods.weight)) return result some_goods = [goods(0, 2, 4), goods(1, 8, 6), goods(2, 5, 3), goods(3, 2, 8), goods(4, 1, 2)] start_time = time.clock() res = knapsack(6, some_goods) end_time = time.clock() print(&apos;花费时间：&apos; + str(end_time - start_time)) for obj in res: print(&apos;物品编号:&apos; + str(obj.id) + &apos; ,放入重量:&apos; + str(obj.weight) + &apos;,放入的价值:&apos; + str(obj.value), end=&apos;,&apos;) print(&apos;单位价值量为:&apos; + str(obj.value / obj.weight)) # 花费时间：2.2807240614677942e-05 # 物品编号:3 ,放入重量:2,放入的价值:8,单位价值量为:4.0 # 物品编号:0 ,放入重量:2,放入的价值:4,单位价值量为:2.0 # 物品编号:4 ,放入重量:1,放入的价值:2,单位价值量为:2.0 # 物品编号:1 ,放入重量:1,放入的价值:0.75,单位价值量为:0.75 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql server 2008 基础知识]]></title>
    <url>%2F2015%2F11%2F13%2Fsql%20server%202008%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[一、配置管理器 1.管理服务 使用配置管理器可以启动、停止、重新启动、继续或暂停服务。 服务器和客户端网络协议 2.SQLSMS 简介： SQLSMS是一个集成环境，用于访问、配置、管理和开发SQL Server的所有组件。 注册服务器： 为客户机确定一台SQL Server数据库所在的机器，及服务器。 4.Sqlcmd工具 sqlcmd通过OLE DB与服务器进行通信，使用sqlcmd工具可以在命令提示符窗口中输入T-SQL语句，调用系统过程和脚本文件。 T-SQL脚本文件是一个文本文件，可以包含T-SQL语句、sqlcmd命令以及脚本变量的组合。 5.其它管理工具 business intelligence development studio 数据库引擎优化顾问 Sql server profiler Reporting services 二、系统数据库 1. master数据库 master数据库是SQL Server 2008中最重要的数据库。记录了SQL Server实例的所有系统级信息。如： SQL Server初始化信息、登录帐户和系统配置设置、所有数据库文件的位置。 如果master数据库不可用，则SQL Server无法启动。master数据库始终有一个可用的最新的master数据库备份。 2. tempdb数据库 tempdb数据库是一个临时数据库，用于保存临时对象或中间结果集，满足临时存储要求。 tempdb数据库在SQL Server每次启动时都重新创建。临时表和临时存储过程在连接断开时自动除去，而且当系统关闭后将没有任何连接处于活动状态。 每次启动数据库引擎时， tempdb数据库会重置为其初始大小，在SQL Server运行时，该库会根据需要自动增长。 3. model数据库 model数据库是创建所有数据库的模板。当创建数据库时，新数据库的第一部分通过复制model数据库中的内容创建，剩余部分由空白页填充。 如果修改model数据库，之后创建的所有数据库都将继承这些修改，即model数据库中的所有用户定义的对象都将复制到所有新创建的数据库中。可以向model数据库中添加任何对象如：表、视图、存储过程等），以便将这些对象包含到所有新创建的数据库中。 model数据库一直存储在SQL Server系统中。 4. msdb数据库 msdb数据库供 SQL Server 代理程序调度警报和作业以及记录操作员时使用。 三、数据库的组成 1. 数据库对象 表 视图 索引 存储过程和触发器 用户和角色 2. 数据库文件 SQL Server 2005数据库有3种类型的文件： 主数据文件 次要数据文件 日志文件 ①主数据文件 主数据文件用来存放数据，它还包含其它数据库文件的指针，它是数据库的起点。 它包含一些系统表，这些表记录数据库对象及其他文件的位置信息。 一个数据库必须有且只有一个主数据文件，主数据文件的扩展名为.MDF。 在SQL Server 2008中，数据库所有文件的位置都记录在数据库的主文件中和master数据库中。 ②次要数据文件 次要数据文件也用来存放数据。如果主数据文件可包括数据库中的所有数据就不需要次数据文件，如果主数据文件太大或要扩展到多个磁盘，则需次要数据文件。 一个数据库可有多个或没有次要数据文件，次要数据文件的扩展名为.NDF ③事务日志文件 事务是用户定义的一个数据库操作序列。这些操作要么全做要么全不做。 事务日志文件用来存放事务日志。即存储所有事务和由这些事务引起的数据库的变化，用于恢复数据库。 一个数据库有一个或多个事务日志文件，日志文件的扩展名为.LDF 3. 文件组 文件组用于文件的分配和管理，有两种类型： 主文件组: 主文件组包含主数据文件和任何没有明确分配给其他文件组的其他文件。系统表的所有页均分配在主文件组中。 用户定义文件组 : 用户定义文件组是通过在CREATE DATABASE或ALTER DATABASE语句中使用FILEGROUP关键字指定的任何文件组。 数据库文件应遵循的原则： 一个数据库均有一个文件组被指定为默认文件组。未指定则主文件组为默认文件组。 如果创建表或索引时未指定文件组，则将假定所有页都从默认文件组分配。一次只能有一个文组为默认文件组。 一个数据文件只能属于一个文件组。 日志文件不能属于文件组。 四、创建和删除数据库 1. 创建数据库: 使用SQLSMS工具创建 使用T-SQL创建 2. 删除数据库: 使用SQLSMS工具删除 使用T-SQL删除 五、分离和附加数据库 1.分离数据库 将数据库从实例中删除，但是其数据库文件和事务日志文件保持不变。 附加数据库 将分离后的数据库添加到SQL SERVER实例中。 六、SQL脚本 使用SQL脚本可以创建数据库结构、重建数据库，或将它作为移动数据库的工具。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql server 2008</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划之 0-1背包问题及改进]]></title>
    <url>%2F2015%2F10%2F31%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%200-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E5%8F%8A%E6%94%B9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[有N件物品和一个容量为V的背包。第i件物品的重量是w[i]，价值是v[i]。求解将哪些物品装入背包可使这些物品的重量总和不超过背包容量，且价值总和最大。在选择装入背包的物品时，对于每种物品i，只能选择装包或不装包，不能装入多次，也不能部分装入，因此成为0-1背包问题。 形式化描述为：给定n个物品，背包容量C &gt;0,重量 第i件物品的重量w[i]&gt;0, 价值v[i] &gt;0 , 1≤i≤n.要求找一n元向量(X 1 ,X 2 ,…,X n ,), X i ∈{0,1}, 使得 ∑（w[i] Xi） ≤C,且∑ v[i] Xi达最大.即一个特殊的整数规划问题。 数学描述为： 求解最优值： 设最优值m(i,j)为背包容量为j、可选择物品为i，i+1，……，n时的最优值(装入包的最大价值)。所以原问题的解为 m(1，C) 将原问题分解为其子结构来求解。要求原问题的解m(1，C)，可从m(n，C)，m(n-1，C)，m(n-2，C)…..来依次求解，即可装包物品分别为（物品n）、（物品n-1，n）、（物品n-2，n-1，n）、……、（物品1，物品2，……物品n-1，物品n）。最后求出的值即为最优值m(1，C)。 若求m(i,j)，此时已经求出m(i+1,j)，即第i+1个物品放入和不放入时这二者的最大值。 对于此时背包剩余容量 j=0,1,2,3……C ，分两种情况： (1)当 w[i] &gt; j ，即第i个物品重量大于背包容量j时， m(i,j)=m(i+1,j) (2)当 w[i] &lt;= j ，即第i个物品重量不大于背包容量j时，这时要判断物品i放入和不放入对m的影响。 若 不放入物品i ，则此时m(i,j)=m(i+1,j) 若 放入物品i ，此时背包剩余容量为 j-w[i]，在子结构中已求出当容量k=0,1,2……C 时的最优值m(i+1,k)。所以此时m(i,j)=m(i+1,j-w[i])+v[i]。 取上述二者的最大值，即 m(i,j) = max{ m(i+1,j)，m(i+1,j-w[i])+v[i] } 总结得出状态转移方程为： 该算法的python代码实现： # 0-1背包问题 __author__ = &apos;ice&apos; # 背包容量0~capacity,不是0~capacity-1 def knapsack(weight, value, capacity): if len(weight) != len(value): print(&quot;parameter err!&quot;) return obj_num = len(weight) result = [[] for x in range(obj_num)] divide = min(weight[-1], capacity) result[-1] = [0 for x in range(divide)] result[-1].extend(value[-1] for x in range(divide, capacity + 1)) for i in reversed(list(range(1, obj_num - 1))): divide = min(weight[i], capacity) for j in range(divide): result[i].append(result[i + 1][j]) for j in range(divide, capacity + 1): result[i].append(max(result[i + 1][j], result[i + 1][j - weight[i]] + value[i])) result[0] = {capacity: result[1][capacity]} if weight[0] &lt;= capacity: result[0][capacity] = max(result[1][capacity], result[1][capacity - weight[0]] + value[0]) vector = [0 for x in range(obj_num)] capacity_temp = capacity for i in range(obj_num - 1): if result[i][capacity_temp] != result[i + 1][capacity_temp]: vector[i] = 1 capacity_temp -= weight[i] if capacity_temp == 0: vector[-1] = 0 else: vector[-1] = 1 return {&apos;total_value&apos;: result[0][capacity], &apos;select&apos;: vector} 但是 ，但是！！该算法有两个明显的缺点：1，基于上述代码，因为数组索引的需要，要求所给物品重量为整数。2，当背包容量C很大时，算法所需计算时间较多。当C&gt;2^n时，需要Ω(n*2^n)计算时间。 所以 ，所以！！改进算法如下： 对于函数m(i,j)的值，当i确定，j为自变量时，是单调不减的跳跃式增长，如图所示。而这些跳跃点取决于在（物品i，物品i+1，……物品n）中选择放入哪些物品使得在放入重量小于容量 j (0&lt;=j&lt;=C)的情况下m取得最大值。对于每一个确定的i值，都有一个对应的跳跃点集 P i ={ ( j , m(i,j) ) ，……}。j始终小于等于C (1)开始求解时，先求 P i ，初始时P n+1 ={(0，0)}，i=n+1，由此按下列步骤计算P i-1 ，P i-2 ……P 1 ，即P n ，P n-1 ，……P 1 (2)求 Q i ，利用P i 求出m（i，j-w[i-1]）+v[i-1]，即P i 当放入物品i-1后的变化后的跳跃点集Q i ={ ( j+w[i-1], m(i,j)+v[i-1] ) ，……}，在函数图像上表现为所有跳跃点横轴坐标右移w[i-1]，纵轴坐标上移v[i-1]。 (3)求 P i-1 ，即求P i ∪Q i 然后再去掉 受控跳跃点 后的点集。此处有个 受控跳跃点 的概念：若点(a,b)，(c,d)∈Pi∪Qi，且a&lt;=c，b&gt;d，则(c,d)受控于(a,b)，所以(c,d)∉P i-1 。去掉受控跳跃点，是为了求得在物品i-1放入后m较大的点，即 使m取最优值的跳跃点。 由此计算得出P n ，P n-1 ，……，P 1 。求得P 1 的最后那个跳跃点即为所求的最优值m(1,C)。 举个栗子 ： n=5，c=10，w={2，2，6，5，4}，v={6，3，5，4，6}。跳跃点的计算过程如下： 初始时 p[6]={(0,0)} 因此， q[6]=p[6]⊕(w[5],v[5])={(4,6)} p[5]={(0,0),(4,6)} q[5]=p[5]⊕(w[4],v[4])={(5,4),(9,10)} p[4]={(0,0),(4,6),(9,10)} p[5]与q[5]的并集p[5]∪q[5]={(0,0),(4,6),(5,4),(9,10)}中跳跃点(5,4)受控于跳跃点(4,6)。将受控跳跃点(5,4)清除后，得到p[4] q[4]=p[4]⊕(6，5)={(6，5)，(10，11)} p[3]={(0，0)，(4，6)，(9，10)，(10，11)} q[3]=p[3]⊕(2，3)={(2，3)，(6，9)} p[2]={(0，0)，(2，3)，(4，6)，(6，9)，(9，10)，(10，11)} q[2]=p[2]⊕(2，6)={(2，6)，(4，9)，(6，12)，(8，15)} p[1]={(0，0)，(2，6)，(4，9)，(6，12)，(8，15)} p[1]的最后的那个跳跃点(8,15)即为所求的最优值，m(1,C)=15 最后，python代码的实现： class Point: def __init__(self, x, y): self.x = x self.y = y # 0-1背包问题 改进 def knapsack_improve(weight, value, capacity): if len(weight) != len(value): print(&quot;parameter err!&quot;) return obj_num = len(weight) jump_points_p = [[] for x in range(obj_num)] jump_points_q = [[] for x in range(obj_num)] jump_points_p.append([Point(0, 0)]) jump_points_q.append([Point(weight[obj_num - 1], value[obj_num - 1])]) for i in reversed(list(range(1, obj_num))): jump_points_p[i] = merge_points(jump_points_p[i + 1], jump_points_q[i + 1]) jump_points_q[i] = [Point(point.x + weight[i - 1], point.y + value[i - 1]) for point in jump_points_p[i] if point.x + weight[i - 1] &lt;= capacity] result = merge_points(jump_points_p[1], jump_points_q[1]) return result def merge_points(points_x, points_y): x_len = len(points_x) y_len = len(points_y) merged_points = [] i = j = 0 while True: if i == x_len or j == y_len: break if points_x[i].x &lt; points_y[j].x: merged_points.append(points_x[i]) if points_x[i].y &gt;= points_y[j].y: j += 1 i += 1 else: merged_points.append(points_y[j]) if points_y[j].y &gt;= points_x[i].y: i += 1 j += 1 while i &lt; x_len: if points_x[i].x &gt; merged_points[-1].x and points_x[i].y &gt; merged_points[-1].y: merged_points.append(points_x[i]) i += 1 while j &lt; y_len: if points_y[j].x &gt; merged_points[-1].x and points_y[j].y &gt; merged_points[-1].y: merged_points.append(points_y[j]) j += 1 return merged_points result = knapsack_improve([2, 2, 6, 5, 4], [6, 3, 5, 4, 6], 10) print() for point in result: print(&apos;(&apos; + str(point.x) + &apos;,&apos; + str(point.y) + &apos;)&apos;, end=&apos; &apos;) #(0,0) (2,6) (4,9) (6,12) (8,15) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划之矩阵连乘]]></title>
    <url>%2F2015%2F10%2F31%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E7%9F%A9%E9%98%B5%E8%BF%9E%E4%B9%98%2F</url>
    <content type="text"><![CDATA[给定n个矩阵｛A 1 ,A 2 ,…,A n ｝，其中Ai与A i+1 是可乘的，i=1,2 ,…,n-1。如何确定计算矩阵连乘积的计算次序，使得依此次序计算矩阵连乘积需要的数乘次数最少。 例如： A 1 ={30x35} ; A 2 ={35x15} ;A 3 ={15x5} ;A 4 ={5x10} ;A 5 ={10x20} ;A 6 ={20x25} ; 结果为：((A 1 (A 2 A 3 ))((A 4 A 5 )A 6 )) 最小的乘次为15125。 原问题为n个矩阵连乘，将原问题分解为子问题，即当n等于1,2,3…..时。 n==1 时，单一矩阵，不需要计算。最小乘次为0 n==2 时，根据n==1时的结果，遍历计算出每相邻两个矩阵的最小乘次 n==3 时， 根据n==1和n==2时的结果 ，此时已经求出 每相邻1个、2个矩阵的最小乘次 ，遍历计算出该相邻三个矩阵的最小乘次 依次类推…… 当 n==n 时， 根据n==1、2、……n-1时的结果 ，此时已经求出 每相邻1个、2个、3个……n-1个矩阵的最小乘次 ，由此求出n==n时的最小乘次 每当n增加1时，就利用已求出的子结构来求解此时的最优值。 数学描述如下： 设矩阵Ai的维数为 P i × P i+1 。 设 A[i:j] 为矩阵A i A i+1 ….A j 的连乘积，即从Ai到Aj的连乘积，其中，0 &lt;= i &lt;= j &lt;= n-1 设m [i][j] 为计算A[i:j]的最小乘次，所以 原问题的最优值为m[0][n-1] 。 当 i==j 时，单一矩阵，无需计算。 m[i][i]=0 ，i=0,1，….n-1 当 i &lt; j 时，利用最优子结构，计算m[i][j]。即寻找断开位置k (i &lt;= k &lt; j) ，使得 m[i][k]+m[k+1][j]+P i P k+1 P j+1 最小。 该算法的python实现： # coding=gbk # 矩阵连乘问题 __author__ = &apos;ice&apos; # row_num 每个矩阵的行数 class Matrix: def __init__(self, row_num=0, col_num=0, matrix=None): if matrix != None: self.row_num = len(matrix) self.col_num = len(matrix[0]) else: self.row_num = row_num self.col_num = col_num self.matrix = matrix def matrix_chain(matrixs): matrix_num = len(matrixs) count = [[0 for j in range(matrix_num)] for i in range(matrix_num)] flag = [[0 for j in range(matrix_num)] for i in range(matrix_num)] for interval in range(1, matrix_num + 1): for i in range(matrix_num - interval): j = i + interval count[i][j] = count[i][i] + count[i + 1][j] + matrixs[i].row_num * matrixs[i + 1].row_num * matrixs[j].col_num flag[i][j] = i for k in range(i + 1, j): temp = count[i][k] + count[k + 1][j] + matrixs[i].row_num * matrixs[k + 1].row_num * matrixs[j].col_num if temp &lt; count[i][j]: count[i][j] = temp flag[i][j] = k traceback(0, matrix_num - 1, flag) return count[0][matrix_num - 1] def traceback(i, j, flag): if i == j: return if j - i &gt; 1: print(str(i + 1) + &apos;~&apos; + str(j + 1), end=&apos;: &apos;) print(str(i + 1) + &quot;:&quot; + str(flag[i][j] + 1), end=&apos;,&apos;) print(str(flag[i][j] + 2) + &quot;:&quot; + str(j + 1)) traceback(i, flag[i][j], flag) traceback(flag[i][j] + 1, j, flag) matrixs = [Matrix(30, 35), Matrix(35, 15), Matrix(15, 5), Matrix(5, 10), Matrix(10, 20), Matrix(20, 25)] result = matrix_chain(matrixs) print(result) # 1~6: 1:3,4:6 # 1~3: 1:1,2:3 # 4~6: 4:5,6:6 # 15125 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 入门 (四) 类与继承]]></title>
    <url>%2F2015%2F10%2F29%2Fpython3%20%E5%85%A5%E9%97%A8%20(%E5%9B%9B)%20%E7%B1%BB%E4%B8%8E%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[Python 类 Python中的类提供了面向对象编程的所有基本功能：类的继承机制允许多个基类，派生类可以覆盖基类中的任何方法，方法中可以调用基类中的同名方法。 对象可以包含任意数量和类型的数据。 python类与c++类相似，提供了类的封装，继承、多继承，构造函数、析构函数。 在python3中，所有类最顶层父类都是object类，与java类似，如果定义类的时候没有写出父类，则object类就是其直接父类。 类定义 类定义语法格式如下： class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 类对象 ：创建一个类之后，可以通过类名访问、改变其属性、方法 实例对象 ：类实例化后，可以使用其属性，可以动态的为实例对象添加属性(类似javascript)而不影响类对象。 类的属性 可以使用点( . )来访问对象的属性 也可以使用以下函数的方式来访问属性： getattr(obj, name[, default]) : 访问对象的属性 hasattr(obj,name) : 检查是否存在一个属性 setattr(obj,name,value) : 设置一个属性。如果属性不存在，会创建一个新属性 delattr(obj, name) : 删除属性 Python内置类属性 dict : 类的属性（包含一个字典，由类的数据属性组成） doc :类的文档字符串 name: 类名 module: 类定义所在的模块（类的全名是’main.className’，如果类位于一个导入模块mymod中，那么className.module 等于 mymod） bases : 类的所有父类构成元素（包含了以个由所有父类组成的元组） class Person: &quot;Person类&quot; def __init__(self, name, age, gender): print(&apos;进入Person的初始化&apos;) self.name = name self.age = age self.gender = gender print(&apos;离开Person的初始化&apos;) def getName(self): print(self.name) p = Person(&apos;ice&apos;, 18, &apos;男&apos;) print(p.name) # ice print(p.age) # 18 print(p.gender) # 男 print(hasattr(p, &apos;weight&apos;)) # False # 为p添加weight属性 p.weight = &apos;70kg&apos; print(hasattr(p, &apos;weight&apos;)) # True print(getattr(p, &apos;name&apos;)) # ice print(p.__dict__) # {&apos;age&apos;: 18, &apos;gender&apos;: &apos;男&apos;, &apos;name&apos;: &apos;ice&apos;} print(Person.__name__) # Person print(Person.__doc__) # Person类 print(Person.__dict__) # {&apos;__doc__&apos;: &apos;Person类&apos;, &apos;__weakref__&apos;: &lt;attribute &apos;__weakref__&apos; of &apos;Person&apos; objects&gt;, &apos;__init__&apos;: &lt;function Person.__init__ at 0x000000000284E950&gt;, &apos;getName&apos;: &lt;function Person.getName at 0x000000000284EA60&gt;, &apos;__dict__&apos;: &lt;attribute &apos;__dict__&apos; of &apos;Person&apos; objects&gt;, &apos;__module__&apos;: &apos;__main__&apos;} print(Person.__mro__) # (&lt;class &apos;__main__.Person&apos;&gt;, &lt;class &apos;object&apos;&gt;) print(Person.__bases__) # (&lt;class &apos;object&apos;&gt;,) print(Person.__module__) # __main__ 类的方法 在类地内部，使用 def 关键字可以为类定义一个方法，与一般函数定义不同， 类方法必须包含参数 self ，且为第一个参数。 类的专有方法： init 构造函数，在生成对象时调用 del 析构函数，释放对象时使用 repr 打印，转换 setitem按照索引赋值 getitem按照索引获取值 len获得长度 cmp比较运算 call函数调用 add加运算 sub减运算 mul乘运算 div除运算 mod求余运算 pow称方 init() 方法是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法，与c++中构造函数类似。只需在自定义的类中重写init()方法即可。 class Person: def __init__(self, name, age, gender): print(&apos;进入Person的初始化&apos;) self.name = name self.age = age self.gender = gender print(&apos;离开Person的初始化&apos;) def getName(self): print(self.name) # Person实例对象 p = Person(&apos;ice&apos;, 18, &apos;男&apos;) print(p.name) print(p.age) print(p.gender) p.getName() # 进入Person的初始化 # 离开Person的初始化 # ice # 18 # 男 # ice 析构函数 del ，del在对象消逝的时候被调用，当对象不再被使用时，del方法运行： 类的封装 python通过 变量名命名来 区分属性和方法的访问权限，默认权限相当于c++和java中的public 类的私有属性： private_attrs ：两个下划线开头，声明该属性为私有，不能在类地外部被使用或直接访问。在类内部的方法中使用时 self.private_attrs 。 类的私有方法： private_method ：两个下划线开头，声明该方法为私有方法，不能在类地外部调用。在类的内部调用 self.private_methods 虽然python不允许实例化的类访问私有数据，但可以使用 object._className__attrName 访问属性。其实python内部私有化的实现只是将attrName属性变为了_className__attrName而已 class Demo: __id = 123456 def getId(self): return self.__id temp = Demo() # print(temp.__id) # 报错 AttributeError: &apos;Demo&apos; object has no attribute &apos;__id&apos; print(temp.getId()) # 123456 print(temp._Demo__id) # 123456 类的继承 面向对象的编程带来的主要好处之一是代码的重用，实现这种重用的方法之一是通过继承机制。继承完全可以理解成类之间的类型和子类型关系。 需要注意的地方： 继承语法 class 派生类名（ 基类名 ）：//… 基类名写作括号里，基本类是在类定义的时候，在元组之中指明的。 在python中继承中的一些特点： 1：在继承中基类的构造（init()方法）不会被自动调用，它需要在其派生类的构造中亲自专门调用。使用super().init()或parentClassName.init() 2：在调用基类的方法时，需要加上基类的类名前缀，且需要带上self参数变量。区别于在类中调用普通函数时并不需要带上self参数 3：Python总是首先查找对应类型的方法，如果它不能在派生类中找到对应的方法，它才开始到基类中逐个查找。（先在本类中查找调用的方法，找不到才去基类中找）。 如果在继承元组中列了一个以上的类，那么它就被称作”多重继承” 。 语法： 派生类的声明，与他们的父类类似，继承的基类列表跟在类名之后，如下所示： 多态 如果父类方法的功能不能满足需求，可以在子类重写父类的方法。实例对象调用方法时会调用其对应子类的重写后的方法 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划之最长公共子序列(LCS)]]></title>
    <url>%2F2015%2F10%2F25%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97(LCS)%2F</url>
    <content type="text"><![CDATA[最长公共子序列(LCS,Longest Common Subsequence)。其定义是，一个序列 S ，如果分别是两个或多个已知序列的子序列，且是所有符合此条件序列中最长的，则 S 称为已知序列的最长公共子序列。而最长公共子串(要求连续)和最长公共子序列是不同的。 设X(m)={x(1), x(2), x(3),….,x(m)} 和 Y(n)={y(1), y(2), y(3),….,y(n)}的最长公共子序列Z(k)={z(1), z(2),z(3),….,z(k)} 首先，将原问题分解为子问题，得出一个已知的结论： 当m或n等于0时，k等于0，即公共子序列长度为0 当m和n都不等于0时，此时分为三种情况： (1) x(m) == y(n) ，此时z(k) = x(m) = y(n)，该元素属于当前最长公共子序列的最后一个元素。此时Z(k-1)={ X(m-1)与Y(n-1)的最长公共子序列 } (2) x(m) ！= y(n) ，且z(k) ！= x(m)，此时Z={ X(m-1)与Y(n)的最长公共子序列 } (3) x(m) ！= y(n) ，且z(k) ！= y(n)，此时Z={ X(m)与Y(n-1)的最长公共子序列 } 其中X(m-1)={x(1), x(2), x(3),….,x(m-1)} ， Y(n-1)={y(1), y(2), y(3),….,y(n-1)}，Z(k-1)={z(1), z(2),z(3),….,z(k-1)} 上面三个步骤，每个步骤都是根据当前序列的状态， 将问题转化为已知解的子问题 (最初的已知解的子问题是当m==0或n==0时)，从而求出当前问题的解。 由此便得出了该问题的状态转移方程，数学描述如下： 现有两个序列X={x 1 ,x 2 ,x 3， …x i }，Y={y 1 ,y 2 ,y 3， ….，y i }， 设一个C[i,j]: 保存X i 与Y j 的LCS的长度 最后，该算法的python实现： # 最长公共子序列问题 __author__ = &apos;ice&apos; # arr_x,arr_y [0 ~ length-1] # subarr_len [0,1~x_length][0,1~y_length] # flag [0 ~ x_length-1][0 ~ y_length] def lcs_length(arr_x, arr_y): x_length = len(arr_x) y_length = len(arr_y) subarr_len = [[0 for j in range(y_length + 1)] for i in range(x_length + 1)] flag = [[0 for j in range(y_length)] for i in range(x_length)] for i in range(1, x_length + 1): for j in range(1, y_length + 1): if arr_x[i - 1] == arr_y[j - 1]: subarr_len[i][j] = subarr_len[i - 1][j - 1] + 1 flag[i - 1][j - 1] = 1 elif subarr_len[i - 1][j] &gt;= subarr_len[i][j - 1]: subarr_len[i][j] = subarr_len[i - 1][j] flag[i - 1][j - 1] = 2 else: subarr_len[i][j] = subarr_len[i][j - 1] flag[i - 1][j - 1] = 3 return {&apos;subarr_length&apos;: subarr_len[x_length][y_length], &apos;flag&apos;: flag} def lcs(arr_x, x_i, y_j, flag, result): if x_i &lt; 0 or y_j &lt; 0: return if flag[x_i][y_j] == 1: lcs(arr_x, x_i - 1, y_j - 1, flag, result) result.append(arr_x[x_i]) elif flag[x_i][y_j] == 2: lcs(arr_x, x_i - 1, y_j, flag, result) elif flag[x_i][y_j] == 3: lcs(arr_x, x_i, y_j - 1, flag, result) array_x = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;b&apos;, &apos;d&apos;, &apos;a&apos;, &apos;b&apos;] array_y = [&apos;b&apos;, &apos;d&apos;, &apos;c&apos;, &apos;a&apos;, &apos;b&apos;, &apos;a&apos;] longest_common_subsequence = [] lcs_info = lcs_length(array_x, array_y) lcs(array_x, len(array_x) - 1, len(array_y) - 1, lcs_info[&apos;flag&apos;], longest_common_subsequence) print(longest_common_subsequence) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>LCS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划之硬币组合问题]]></title>
    <url>%2F2015%2F10%2F25%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E7%A1%AC%E5%B8%81%E7%BB%84%E5%90%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题：如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？ 动态规划的本质是将原问题分解为同性质的若干相同子结构，在求解最优值的过程中将子结构的最优值记录到一个表中以避免有时会有大量的重复计算。 例如硬币组合问题，若求凑够11元的最少硬币数，可以先从凑够0元、1元、2元……的子结构开始分析。 假设d(i)为凑够i元所需最少硬币数，则 d(0) = 0 理所当然 d(1) = 1 要凑够1元，需要从面值小于等于1元的硬币中选择，目前只有面值为1元的硬币 此时d(1) = d(0) + 1 d(2) = d(2 - 1) + 1 = 2 ， 从面值小于等于2元的硬币中选择，符合要求的硬币面值为：1元。 此时d(2) = d(2-1) + 1 d(3) = d(3 - 3) + 1 = 1 ， 从面值小于等于3元的硬币中选择，符合要求的硬币面值为：1元，3元。 此时有有两种选择：是否选择含有面值3元的硬币 含有3元硬币：d(3) = d(3 - 3) + 1 = 1 不含3元硬币：d(3) = d(3 - 1) + 1 = d(2) + 1 = 3 自然是选择二者中较小值 依次类推… 就该问题总结一下，随着要凑够钱数的增加： 1.首先要知道所有不大于该钱数的面值， 2.对于每种面值的硬币，求出当选择一个该面值的硬币时所需的硬币数 当选择一个硬币后，所需硬币数+1，所要凑够的钱数=原所要凑的钱数-该硬币面值，所要凑够的钱数减少，求减少后要凑钱数最少所需硬币数，属于原问题的子结构，已求出解 3.在上述求出的结果集中，选择最小值，即为要凑够该钱数所需的最少硬币数 由此可以看出，每个问题的最优值都是借其子结构的最优值得到的。 而该算法的最小的子结构的最优解是已知的，即：当要凑钱数为0元时，最少需要0枚硬币。 利用这个最小的子结构，通过递推式便可求出所指定值凑够钱数的最优值 上面所提到的递推式，便是状态转移方程。利用已知状态，不断通过状态转移方程求解，便得到了最优值和最优解。 下面看一下硬币组合问题的数学描述： d(i)=min{ d(i-vj)+1 }，其中i-vj &gt;=0，vj表示第j个硬币的面值，i表示要凑够i元，d(i)表示凑够i元最少需要的硬币数。即： 0 i == 0 时 min_coin_num(i) = { min{ min_coin_num( i-coin_value(j) )+1 | i-coin_value(j)&gt;0} coin_value(j)表示第j种硬币的面值 i &gt; 0 时 当总值total_value为i时， 对于所有的 coin_value(j) &lt; i的硬币j ,取min{ min_coin_num(i-coin_value(j)) } 最后，该算法的python实现： # 如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元 __author__ = &apos;ice&apos; def select_coin(coin_value, total_value): min_coin_num = [0] for i in range(1, total_value + 1): min_coin_num.append(float(&apos;inf&apos;)) for value in coin_value: if value &lt;= i and min_coin_num[i - value] + 1 &lt; min_coin_num[i]: min_coin_num[i] = min_coin_num[i - value] + 1 return min_coin_num result = select_coin([1, 3, 5], 11) print(&quot;coin number:&quot; + str(result[-1])) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>算法设计与分析</category>
      </categories>
      <tags>
        <tag>算法设计与分析</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 入门 (三) 函数与lambda表达式、闭包]]></title>
    <url>%2F2015%2F09%2F25%2Fpython3%20%E5%85%A5%E9%97%A8%20(%E4%B8%89)%20%E5%87%BD%E6%95%B0%E4%B8%8Elambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E3%80%81%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[函数 是组织好的、可重复使用的、用来实现单一或相关联功能的代码段。 函数代码块以def关键词开头，后接函数标识符名称和圆括号() 任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明 函数内容以冒号起始，并且缩进 Return[expression]结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None 函数的定义 ： def test0(): &quot;函数_文档字符串&quot; print(&apos;函数内部&apos;) print(test0.__doc__) # 函数_文档字符串 若采用默认参数定义函数，调用函数时，缺省参数的值如果没有传入，则被认为是默认值： def test1(arg1=&apos;参数一&apos;, arg2=&apos;参数二&apos;): print(&apos;arg1:&apos;+arg1) print(&apos;arg2:&apos;+arg2) test1() # arg1:参数一 arg2:参数二 # 默认情况下，参数值和参数名称是按函数声明中定义的的顺序匹配起来的 test1(&apos;ice&apos;, &apos;cream&apos;) # arg1:ice arg2:cream test1(arg2=&apos;cream&apos;, arg1=&apos;ice&apos;) # arg1:ice arg2:cream 不定长参数 。加了星号（*）的变量名会存放所有未命名的变量参数。选择不多传参数也可： def test2(*args, param): print(len(args)) for arg in args: print(arg) print(param) test2(1, 2, 3, 4, param=&apos;This is param&apos;) def test3(param, *args): print(param) print(len(args)) for arg in args: print(arg) test3(&apos;This is param&apos;, 1, 2, 3, 4) 所有参数（自变量）在Python里都是按引用传递。如果在函数里修改了参数，那么在调用这个函数的函数里，原始的参数也被改变了 def test4(mylist): print(mylist) mylist.clear() print(mylist) mylist = [1, 2, 3, 4] test4(mylist) print(mylist) # 输出： # [1, 2, 3, 4] # [] # [] return语句[表达式]退出函数，选择性地向调用方返回一个表达式。不带参数值的return语句返回None def test5(): return (1, 2, 3, 4) def test6(): return 1, 2, 3, 4 def test7(): return [1, 2, 3, 4] result = test5() print(result) # (1, 2, 3, 4) result = test6() print(result) # (1, 2, 3, 4) result = test7() print(result) # [1, 2, 3, 4] 内部函数 。函数体内可以再定义函数： def outerFunc(): print(&apos;Outer Funtion&apos;) def innerFunc(): print(&apos;Inner Function&apos;) innerFunc() outerFunc() # 输出： # Outer Funtion # Inner Function 函数变量作用域 定义在函数内部的变量拥有一个 局部作用域 ，定义在函数外的拥有 全局作用域 。 局部变量 只能在其被声明的 函数内部访问 ，而 全局变量 可以在 整个程序范围内访问 。调用函数时，所有在函数内声明的变量名称都将被加入到作用域中 temp = &apos;ice cream&apos; def test8(): &quot;全局变量可以在整个程序范围内访问&quot; print(temp) def test9(): inner_temp = &apos;ice&apos; print(inner_temp) print(temp) # ice cream test8() # ice cream test9() # ice # 局部变量只能在其被声明的函数内部访问 print(inner_temp) # 报错 name &apos;inner_temp&apos; is not defined def test10(): print(temp) # 报错 local variable &apos;temp&apos; referenced before assignment temp = &apos;ice&apos; print(temp) Python闭包 如果在一个内部函数里，对在外部作用域（但不是在全局作用域）的变量进行引用，那么内部函数就被认为是闭包（closure）。 一个闭包就是你调用了一个函数A，这个函数A返回了一个函数B给你。这个返回的函数B就叫做闭包。你在调用函数A的时候传递的参数就是自由变量 def FuncX(x): def FuncY(y): return x * y return FuncY tempFunc = FuncX(3) result = tempFunc(5) print(result) # 15 result = FuncX(3)(5) print(result) # 15 匿名函数 python 使用 lambda 表达式 来创建匿名函数 lambda只是一个表达式，函数体比def简单很多 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去 lambda函数拥有自己的名字空间，且不能访问自有参数列表之外或全局名字空间里的参数 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率 lambda函数的语法只包含一个语句： lambda [arg1 [,arg2,…..argn]]:expression 使用如下： square = lambda x : x**2 print(square(3)) # 9 sum = lambda x, y : x + y print(sum(2, 3)) # 5 内置函数 filter 的使用 ： 官方文档内容如下： filter( function , iterable ) Construct an iterator from those elements of iterable for which function returns true. iterable may be either a sequence, a container which supports iteration, or an iterator. If function is None, the identity function is assumed, that is, all elements of iterable that are false are removed. function参数可传入None、函数、lambda表达式， iterable 参数传入一个可迭代对象。 若function参数为None：返回可迭代对象中所有不为False的元素 若function参数为函数或 lambda表达式：返回 将元素作为函数参数、函数返回值为True 的元素 reslut = filter(None, [1, 0, False, True]) print(list(reslut)) # [1, True] def odd(num): return num % 2 reslut = filter(odd, range(10)) print(list(reslut)) # [1, 3, 5, 7, 9] reslut = filter(lambda num: num % 2, range(10) ) print(list(reslut)) # [1, 3, 5, 7, 9] 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 入门 (二) 列表的使用]]></title>
    <url>%2F2015%2F09%2F23%2Fpython3%20%E5%85%A5%E9%97%A8%20(%E4%BA%8C)%20%E5%88%97%E8%A1%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[列表 用于组织其它数值，即写在方括号之间、用逗号分隔开的数值列表。列表内的项目不必全是相同的类型。 列表的定义 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] 添加元素 将另一个列表直接赋值给该列表 使用” [头下标:尾下标] “j将另一个列表的指定元素值拷贝至该列表 使用” + “连接符，将元素添加至列表末尾 使用” * “乘号得到多个相同元素 使用append方法，将元素添加至列表末尾 使用extend方法，将元素添加至列表末尾 使用insert方法，将元素插入至指定位置 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] student *= 3 print(student) #[&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] # student中变量为name值的复制 name = [&apos;Jerry&apos;, &apos;Lucy&apos;] student = name[:] print(student) # [&apos;Jerry&apos;, &apos;Lucy&apos;] name.clear() print(student) # [&apos;Jerry&apos;, &apos;Lucy&apos;] # *得到的每一相同项指向同一内存地址 name = [&apos;Jerry&apos;]*3 print(name) # [&apos;Jerry&apos;, &apos;Jerry&apos;, &apos;Jerry&apos;] print(id(name[0])) # 54580088 print(id(name[1])) # 54580088 print(id(name[2])) # 54580088 # name2与name1指向同一内存地址 name1 = [&apos;Jerry&apos;] name2 = name1 print(name2) # [&apos;Jerry&apos;] name1.clear() print(name2) # [] # student中变量为name值的复制，与name不指向同一内存地址 name = [&apos;Jerry&apos;] student = name*3 print(student) # [&apos;Jerry&apos;, &apos;Jerry&apos;, &apos;Jerry&apos;] name.clear() print(student) # [&apos;Jerry&apos;, &apos;Jerry&apos;, &apos;Jerry&apos;] # append添加后,student中的[&apos;Jerry&apos;]与name变量指向同一内存地址 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = [&apos;Jerry&apos;] student.append(name) print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, [&apos;Jerry&apos;]] name.clear() print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, []] # 与name变量不指向同一内存地址 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = &apos;Jerry&apos; student.append(name) print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Jerry&apos;] del name print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Jerry&apos;] # 同上，insert插入后,student中的[&apos;Jerry&apos;]与name变量指向同一内存地址 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = [&apos;Jerry&apos;] student.insert(1, name) print(student) # [&apos;Tom&apos;, [&apos;Jerry&apos;], &apos;Jack&apos;, &apos;Avril&apos;] name.clear() print(student) # [&apos;Tom&apos;, [], &apos;Jack&apos;, &apos;Avril&apos;] # 与name变量不指向同一内存地址 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = &apos;Jerry&apos; student.insert(1, name) print(student) # [&apos;Tom&apos;, &apos;Jerry&apos;, &apos;Jack&apos;, &apos;Avril&apos;] del name print(student) # [&apos;Tom&apos;, &apos;Jerry&apos;, &apos;Jack&apos;, &apos;Avril&apos;] # extend添加后,student中的[&apos;Jerry&apos;]为name值的复制 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = [&apos;Jerry&apos;] student.extend(name) print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Jerry&apos;] name.clear() print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;Jerry&apos;] student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] name = &apos;Jerry&apos; student.extend(name) print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;J&apos;, &apos;e&apos;, &apos;r&apos;, &apos;r&apos;, &apos;y&apos;] del name print(student) # [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;, &apos;J&apos;, &apos;e&apos;, &apos;r&apos;, &apos;r&apos;, &apos;y&apos;] 删除元素 使用remove方法删除指定值的元素 使用pop方法弹出栈顶元素，返回弹出元素 使用 del 关键字删除指定位置元素 使用clear方法清空列表元素 ， 等于del a[:] # 删除指定值的元素 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] student.remove(&apos;Tom&apos;) print(student) # 弹出栈顶元素 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] s = student.pop() print(s) print(student) # 删除指定位置元素 student = [&apos;Tom&apos;, &apos;Jack&apos;, &apos;Avril&apos;] del student[1] print(student) 其他操作： list.index(x) 返回列表中第一个值为 x 的元素的索引。如果没有匹配的元素就会返回一个错误 list.count(x) 返回 x 在列表中出现的次数 list.sort() 对列表中的元素进行排序。参数reverse默认为False，从小到大排序，设置为True则为从大到小排序 list.reverse() 倒排列表中的元素 list.copy() 返回列表的浅复制(变量值的复制)，等于list[:] 列表推导式 列表推导式提供了从序列创建列表的简单途径。通常应用程序将一些操作应用于某个序列的每个元素，用其获得的结果作为生成新列表的元素，或者根据确定的判定条件创建子序列。 每个列表推导式都在 for 之后跟一个表达式，然后有零到多个 for 或 if 子句。返回结果是一个根据表达从其后的 for 和 if 上下文环境中生成出来的列表。如果希望表达式推导出一个元组，就必须使用括号。 将列表中每个数值乘三，获得一个新的列表： &gt;&gt;&gt; num = [1, 2, 3] &gt;&gt;&gt; [3*n for n in num] [3, 6, 9] 可以用 if 子句作为过滤器： &gt;&gt;&gt; num = [1, 2, 3] &gt;&gt;&gt; [3*n for n in num if n &gt; 2] [9] &gt;&gt;&gt; [3*n for n in numif n &lt; 3] [3,6] 其他用法： &gt;&gt;&gt; vec1 = [2, 4, 6] &gt;&gt;&gt; vec2 = [4, 3, -9] &gt;&gt;&gt; [x*y for x in vec1 for y in vec2] [8, 6, -18, 16, 12, -36, 24, 18, -54] &gt;&gt;&gt; [vec1[i]*vec2[i] for i in range(len(vec1))] [8, 12, -54] 用列表推导式实现矩阵转置： # 矩阵转置 matrix = [ [1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12] ] # 方法一 newMatrix = [[row[i] for row in matrix] for i in range(len(matrix[0]))] print(newMatrix) # 方法二 newMatrix = [] for i in range(len(matrix[0])): newMatrix.append([row[i] for row in matrix]) print(newMatrix) # 方法三 newMatrix = [] for i in range(len(matrix[0])): newRow = [] for oldRow in matrix: newRow.append(oldRow[i]) newMatrix.append(newRow) print(newMatrix) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 入门 (一) 基础语法]]></title>
    <url>%2F2015%2F09%2F22%2Fpython3%20%E5%85%A5%E9%97%A8%20(%E4%B8%80)%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.编码问题 默认情况下，Python 3源码文件以 UTF-8 编码，所有字符串都是 unicode 字符串。 也可以为源码文件指定不同的编码，在文件头部加上： coding=gbk2.关键字 保留字即关键字，Python的标准库提供了一个keyword module，可以输出当前版本的所有关键字： &gt;&gt;&gt; import keyword &gt;&gt;&gt; keyword.kwlist [&apos;False&apos;, &apos;None&apos;, &apos;True&apos;, &apos;and&apos;, &apos;as&apos;, &apos;assert&apos;, &apos;break&apos;, &apos;class&apos;, &apos;continue&apos;, &apos;def&apos;, &apos;del&apos;, &apos;elif&apos;, &apos;else&apos;, &apos;except&apos;, &apos;finally&apos;, &apos;for&apos;, &apos;from&apos;, &apos;global&apos;, &apos;if&apos;, &apos;import&apos;, &apos;in&apos;, &apos;is&apos;, &apos;lambda&apos;, &apos;nonlocal&apos;, &apos;not&apos;, &apos;or&apos;, &apos;pass&apos;, &apos;raise&apos;, &apos;return&apos;, &apos;try&apos;, &apos;while&apos;, &apos;with&apos;, &apos;yield&apos;] 3.注释 Python中单行注释以#开头，多行注释用三个单引号（’’’）或者三个双引号（”””）将注释括起来。 4.变量 Python中的变量不需要声明。每个变量在使用前都必须赋值，变量赋值以后该变量才会被创建 Python 3支持int、float、bool、complex（复数）。 数值运算 ： Python可以同时为多个变量赋值，如a, b = 1, 2。 一个变量可以通过赋值指向不同类型的对象。 数值的除法（/）总是返回一个浮点数，要获取整数使用//操作符。 在混合计算时，Python会把整型转换成为浮点数。 字符串 ： python中的字符串str用单引号(‘ ‘)或双引号(“ “)括起来，同时使用反斜杠(\)转义特殊字符 字符串可以使用 + 运算符串连接在一起，或者用 * 运算符重复 text = &apos;ice&apos;+&apos; cream&apos; print(text) text = &apos;ice cream &apos;*3 print(text) 使用三引号(‘’’…’’’或”””…”””)可以指定一个多行字符串 text =&apos;&apos;&apos;啦啦啦 喔呵呵呵呵 呵呵你妹&apos;&apos;&apos; print(text) text = &apos;ice\ cream&apos; print(text) 如果不想让反斜杠发生转义，可以在字符串前面添加一个 r 或 R , 表示原始字符串。 如 r”this is a line with \n” 则\n会显示，并不是换行 text1 = r&apos;E:\notice&apos; text2 = &quot;let&apos;s go!&quot; text3 = r&apos;this is a line with \n&apos; print(text1) # E:\notice print(text2) # let&apos;s go! print(text3) # this is a line with \n 字符串有两种索引方式，第一种是从左往右，从0开始依次增加；第二种是从右往左，从-1开始依次减少。 python中没有单独的字符类型，一个字符就是长度为1的字符串 text = &apos;ice cream&apos; print(len(text)) print(text[0]) # i print(text[-9]) # i print(text[8]) # m print(text[-1]) # m python字符串不能被改变。向一个索引位置赋值会导致错误 text = &apos;ice cream&apos; text[0] = &apos;t&apos; # 报错 print(text) 还可以对字符串进行切片，获取一段子串。用冒号分隔两个索引，形式为变量[头下标:尾下标]。 截取的范围是前闭后开的，并且两个索引都可以省略： text = &apos;ice cream&apos; print(text[:3]) # ice print(text[4:9]) # cream print(text[4:]) # cream 5.三目运算符 x = 100 y = 200 z = x if x &gt; y else y print(z) 6.分支 if-else 语句与其他语言类似，不再赘述 if-elif-else 语句，相当于c或java语言中的if-else if-else ： while True: score = int(input(&quot;Please input your score : &quot;)) if 90 &lt;= score &lt;= 100: print(&apos;A&apos;) elif score &gt;= 80: print(&apos;B&apos;) elif score &gt;= 70: print(&apos;C&apos;) elif score &gt;= 60: print(&apos;D&apos;) else: print(&apos;Your score is too low&apos;) 7.循环 while循环 语句一般形式： while 判断条件 ： statements import random print(&quot;hello world!\n&quot;) number = random.randint(1, 10) temp = input(&quot;Please input a number : &quot;) i = int(temp) while i != number: print(&quot;wrong...&quot;) if i &lt; number: print(&quot;required a bigger number&quot;) else: print(&quot;required a smaller number&quot;) temp = input(&quot;Please input a number : &quot;) i = int(temp) print(&quot;yes...&quot;) for循环 的一般格式如下： for in : else: languaegs = [&apos;C&apos;,&apos;c++&apos;,&apos;java&apos;,&apos;python&apos;] for language in languaegs: print(language, len(language)) 循环语句可以有else子句 它在穷尽列表(以for循环)或条件变为假(以while循环)循环终止时被执行 但循环被break终止时不执行.如下查寻质数的循环例子 for num in range(2, 10): for x in range(2, num): if num%x == 0: print(num, &apos;equals&apos;, x, &apos;*&apos;, num//x) break else: # 循环中没有找到元素 print(num, &apos;is a prime number&apos;) 如果需要遍历数字序列，可以使用内置range()函数： # range()函数,含头不含尾 # 0~4 for i in range(5): print(i) # 2~7 for i in range(2, 8): print(i) # 1~9 步长为3 for i in range(1, 10, 3): print(i) range()函数与for循环结合： languaegs = [&apos;c&apos;,&apos;c++&apos;,&apos;java&apos;,&apos;python&apos;] for i in range(len(languaegs)): print(i, &apos;:&apos;, languaegs[i]) 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据的分页处理]]></title>
    <url>%2F2015%2F08%2F29%2F%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E9%A1%B5%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[当页面中要显示的内容过多需要分多页显示、或是数据量过大内存吃不消时，需要分页处理。 原理：每次从数据库中取出一定量的数据，通过jsp页面显示 实现： ①写一个类封装分页的页面 ②从数据库中取出一个页面的数据，将信息封装到分页页面对象中 ③根据情况，将分页的页面对象设置到request对象、session对象或servletContext对象属性中，供jsp页面调用 ④在jsp页面中显示分页数据、分页页码、上一页下一页、跳转页面等 下面看具体代码: 分页页面Page类： package cn.wzbrilliant.domain; import java.util.List; //界面上所有与分页有关的都找此类要 public class Page { private List records; private int pagesize = 10;//每页显示的记录条数 private int pagenum;//用户要看的页码即当前页码 private int totalpage;//总页数 private int startIndex;//每页开始记录的索引 private int totalrecords;//总记录条数 //显示的页码 private int startPage; private int endPage; public Page(int pagenum,int totalrecords){ this.pagenum = pagenum; this.totalrecords = totalrecords; //计算每页开始记录的索引 startIndex = (pagenum-1)*pagesize; //计算总页数 totalpage = totalrecords%pagesize==0?totalrecords/pagesize:(totalrecords/pagesize+1); //显示的页码 if(totalpage&lt;=9){ startPage = 1; endPage = totalpage; }else{ startPage = pagenum-4; endPage = pagenum+4; if(startPage&lt;1){ startPage = 1; endPage = 9; } if(endPage&gt;totalpage){ endPage = totalpage; startPage = totalpage-8; } } } public List getRecords() { return records; } public void setRecords(List records) { this.records = records; } public int getPagesize() { return pagesize; } public void setPagesize(int pagesize) { this.pagesize = pagesize; } public int getPagenum() { return pagenum; } public void setPagenum(int pagenum) { this.pagenum = pagenum; } public int getTotalpage() { return totalpage; } public void setTotalpage(int totalpage) { this.totalpage = totalpage; } public int getStartIndex() { return startIndex; } public void setStartIndex(int startIndex) { this.startIndex = startIndex; } public int getTotalrecords() { return totalrecords; } public void setTotalrecords(int totalrecords) { this.totalrecords = totalrecords; } public int getStartPage() { return startPage; } public void setStartPage(int startPage) { this.startPage = startPage; } public int getEndPage() { return endPage; } public void setEndPage(int endPage) { this.endPage = endPage; } } 从数据库中取出一定条数的记录，此处以mysql为例，sql语句为 select * from 表名 limit ?,? 两个问号分别为起始位置和结束位置 在jsp页面中显示分页页码、上一页下一页、跳转页面等的实现代码： &lt;%@ page language=&quot;java&quot; import=&quot;java.util.*&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;!-- 分页的部分 --&gt; 第${page.pagenum}页/共${page.totalpage}页 &lt;a href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet&quot;&gt;首页&lt;/a&gt; &lt;a href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet?pagenum=${page.pagenum-1==0?1:page.pagenum-1}&quot;&gt;上一页&lt;/a&gt; &lt;c:forEach begin=&quot;${page.startPage}&quot; end=&quot;${page.endPage}&quot; var=&quot;num&quot;&gt; &lt;a href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet?pagenum=${num}&quot;&gt;${num }&lt;/a&gt; &lt;/c:forEach&gt; &lt;a href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet?pagenum=${page.pagenum+1&gt;page.totalpage?page.totalpage:page.pagenum+1}&quot;&gt;下一页&lt;/a&gt; &lt;a href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet?pagenum=${page.totalpage}&quot;&gt;尾页&lt;/a&gt; &lt;select id=&quot;s1&quot;&gt; &lt;c:forEach begin=&quot;1&quot; end=&quot;${page.totalpage}&quot; var=&quot;num&quot;&gt; &lt;option value=&quot;${num}&quot; ${page.pagenum==num?&apos;selected=&quot;selected&quot;&apos;:&apos;&apos;}&gt;${num}&lt;/option&gt; &lt;/c:forEach&gt; &lt;/select&gt; &lt;a href=&quot;javascript:jump()&quot;&gt;跳转&lt;/a&gt; &lt;script type=&quot;text/javascript&quot;&gt; function jump(){ var num = document.getElementById(&quot;s1&quot;).value; window.location.href=&quot;${pageContext.request.contextPath}/servlet/ShowAllMessageServlet?pagenum=&quot;+num; } &lt;/script&gt; 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Java</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>分页</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EL函数以及自定义标签的应用]]></title>
    <url>%2F2015%2F08%2F28%2FEL%E5%87%BD%E6%95%B0%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%87%E7%AD%BE%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、EL函数 (调用普通类的静态方法) 编写步骤（自定义EL函数的编写步骤即自定义标签的编写步骤）： ①编写一个普通的java类，提供一个静态方法，功能自定 ，例如下： package cn.wzbrilliant.el; public class ElFunction { public static String toUpperCase(String str){ return str.toUpperCase(); } } ②在JavaWeb应用的WEB-INF目录下建立一个扩展名是tld(taglib definition)的XML文件。 内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;taglib xmlns=&quot;http://java.sun.com/xml/ns/j2ee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-jsptaglibrary_2_0.xsd&quot; version=&quot;2.0&quot;&gt; &lt;tlib-version&gt;1.0&lt;/tlib-version&gt; &lt;short-name&gt;myfn&lt;/short-name&gt; &lt;uri&gt;/WEB-INF/myfn.tld&lt;/uri&gt; &lt;function&gt;&lt;!-- 定义函数 --&gt; &lt;name&gt;toUpper&lt;/name&gt; &lt;!-- 调用名称 --&gt; &lt;function-class&gt;cn.wzbrilliant.el.ElFunction&lt;/function-class&gt; &lt;!-- 类全名 --&gt; &lt;function-signature&gt;java.lang.String toUpperCase( java.lang.String )&lt;/function-signature&gt; &lt;/function&gt; &lt;/taglib&gt; 值随意 一般与文件名、前缀名称相同，方便查找，不相同也可。 值随意，只要与web.xml中的uri想对应即可③（可选步骤）前提是把tld文件放到了WEB-INF目录下。告知应用，tld文件和tld中的uri的对应。修改web.xml，增加以下内容： /WEB-INF/myfn.tld /WEB-INF/myfn.tld 代表一个标签库，可以多个 tld文件的位置④ 在JSP中使用用taglib指令，引入自定义的EL函数库： &lt;%@ taglib uri=”/WEB-INF/myfn.tld” prefix=”myfn”%&gt;使用方式如下： &lt;% pageContext.setAttribute(“p”, “abcdef”); %&gt; ${myfn:toUpper(h) } ${myfn:toUpper(“abcdef”) }代码第五行和第六行都可输出”ABCDEF”。二、EL自定义标签开发自定义标签属于JSP技术1、标签的作用移除掉JSP中的Java脚本(&lt;%%&gt;)2、编写自定义标签的步骤 (自定义EL函数，步骤相同)自定义标签分为两种， 传统标签 和 简单标签 ：这里只介绍 简单标签 的开发：①编写一个类，直接或间接实现javax.servlet.jsp.tagext.Tag接口这里继承SimpleTagSupport类,例子如下： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.jsp.JspException; import javax.servlet.jsp.tagext.SimpleTagSupport; public class SimpleTag extends SimpleTagSupport { @Override public void doTag() throws JspException, IOException { // JspFragment jf=getJspBody(); // jf.invoke(getJspContext().getOut()); getJspBody().invoke(null); } }JspFragment对象的invoke方法将标签内容输入到给定的流中，如果为null，例如上面代码，则其作用与注释部分代码相同。下面以一个获取远程IP地址的代码为例： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.jsp.JspException; import javax.servlet.jsp.PageContext; import javax.servlet.jsp.tagext.SimpleTagSupport; public class SimpleTag extends SimpleTagSupport { @Override public void doTag() throws JspException, IOException { PageContext pageContext=(PageContext)getJspContext(); String ip=pageContext.getRequest().getRemoteAddr(); pageContext.getOut().write(ip); } }② 在WEB-INF目录下建立一个扩展名为tld（Tag Libary Definition）的xml文件。 &lt;?xml version=”1.0” encoding=”UTF-8”?&gt; 1.0 mytag /WEB-INF/mytag.tld &lt;tag&gt;&lt;!-- 描述标签 --&gt; &lt;description&gt;Show Remote Address&lt;/description&gt; &lt;name&gt;remoteIp&lt;/name&gt;&lt;!-- 标签名称 --&gt; &lt;tag-class&gt;cn.wzbrilliant.el.SimpleTag&lt;/tag-class&gt; &lt;body-content&gt;empty&lt;/body-content&gt;&lt;!-- 指示标签的主体内容：没有就写empty --&gt; &lt;/tag&gt; &lt;/taglib&gt; 标签内容与EL函数中tld文件中相似。可以添加多个标签。具体如下： taglib：根元素 tlib-version:版本号short-name:引用标签时的短名称。一般与tld文件的文件名一致，好找。uri：标签绑定的名称空间。只是一个名字，没有实际的意义。 tag：定义标签元素 name ：标签的名称。 tag-class ：标签的实现类的全名称。 body-content ：指示标签的主体内容的类型。 可选值： empty ：没有主体内容。适用于传统和简单标签。 JSP ：说明JSP文件中能出现什么，标签主体内容中就能出现什么。适用于传统标签。 scriptless ：说明标签的主体内容不能是java脚本。适用于简单标签。 tagdependent ：说明标签的主体内容是原封不动的传递给标签处理类的，而不是传递的运算结果 attribute ：定义标签的属性 name ：属性名。对应标签处理类中的setter方法 required ：是否是必须的属性 rtexprvalue ：是否支持表达式（EL或java表达式）。默认是false。 ③（可选的）在web.xml中对tld文件和名称空间进行映射对应。 &lt;jsp-config&gt; &lt;taglib&gt; &lt;taglib-uri&gt;/WEB-INF/mytag.tld&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/mytag.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;/jsp-config&gt; 此处配置与EL函数相同 ⑤ 在JSP中使用 首先引入： &lt;%@ taglib uri=”/WEB-INF/mytag.tld” prefix=”mytag”%&gt; 使用方法：在jsp页面中使用： &lt;mytag:remoteIp /&gt; 即可输出访问服务器的远程的ip地址 3.简单标签的原理： 三、自定义标签实例： ①实现JSTL中forEach标签的功能 类代码如下： package cn.wzbrilliant.el; import java.io.IOException; import java.lang.reflect.Array; import java.util.ArrayList; import java.util.Collection; import java.util.List; import java.util.Map; import java.util.Set; import javax.servlet.jsp.JspException; import javax.servlet.jsp.PageContext; import javax.servlet.jsp.tagext.SimpleTagSupport; public class ForEachTag extends SimpleTagSupport { private String var; private Collection items; public void setItems(Object items) { if(items instanceof List){ this.items=(List)items; }else if(items instanceof Set){ this.items=(Set)items; }else if(items instanceof Map){ this.items=((Map)items).entrySet(); }else if(items.getClass().isArray()){ this.items=new ArrayList(); int length=Array.getLength(items); for(int i=0;i&lt;length;i++){ this.items.add(Array.get(items, i)); } }else{ throw new RuntimeException(&quot;对不起，不支持的类型&quot;); } } public void setVar(String var) { this.var = var; } @Override public void doTag() throws JspException, IOException { PageContext pageContext=(PageContext) getJspContext(); for(Object obj:items){ pageContext.setAttribute(var, obj); getJspBody().invoke(null); } } } mytag.tld文件中添加如下内容： &lt;tag&gt;&lt;!-- forEach标签 --&gt; &lt;description&gt;for each&lt;/description&gt; &lt;name&gt;forEach&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.ForEachTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;attribute&gt; &lt;name&gt;items&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;attribute&gt; &lt;name&gt;var&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;/tag&gt; 使用方法： &lt;% int[] arr = new int[] {1,2,3,4}; pageContext.setAttribute(&quot;p&quot;, arr); %&gt; &lt;mytag:forEach items=&quot;${p}&quot; var=&quot;v&quot;&gt; ${v}&lt;br&gt; &lt;/mytag:forEach&gt; ②实现JSTL中when otherwise功能 (与if-else结构相似) 实现用到了父标签。父标签的作用：用于子标签之间数据的传递。 该例使用了三个标签，分别为choose(父标签)，when，otherwise，用三个类实现。 父标签choose实现类： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.jsp.JspException; import javax.servlet.jsp.tagext.SimpleTagSupport; public class ChooseTag extends SimpleTagSupport { private boolean flag=false; protected boolean isFlag(){ return flag; } protected void setFlag(boolean flag){ this.flag=flag; } @Override public void doTag() throws JspException, IOException { getJspBody().invoke(null); } } 子标签when实现类： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.jsp.JspException; import javax.servlet.jsp.tagext.SimpleTagSupport; public class WhenTag extends SimpleTagSupport { private boolean test; public void setTest(boolean test){ this.test=test; } @Override public void doTag() throws JspException, IOException { if(test){ ChooseTag parent=(ChooseTag)getParent(); parent.setFlag(true); getJspBody().invoke(null); } } } 子标签otherwise实现类： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.jsp.JspException; import javax.servlet.jsp.tagext.SimpleTagSupport; public class OtherwiseTag extends SimpleTagSupport { @Override public void doTag() throws JspException, IOException { ChooseTag parent=(ChooseTag)getParent(); if(!parent.isFlag()){ getJspBody().invoke(null); } } } mytag.tld中添加如下内容： &lt;tag&gt;&lt;!-- choose标签 --&gt; &lt;description&gt;when otherwise&lt;/description&gt; &lt;name&gt;choose&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.ChooseTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;/tag&gt; &lt;tag&gt;&lt;!-- when标签 --&gt; &lt;description&gt;when otherwise&lt;/description&gt; &lt;name&gt;when&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.WhenTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;attribute&gt; &lt;name&gt;test&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;/tag&gt; &lt;tag&gt;&lt;!-- otherwise标签 --&gt; &lt;description&gt;when otherwise&lt;/description&gt; &lt;name&gt;otherwise&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.OtherwiseTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;/tag&gt; 使用方法，在jsp中： &lt;% pageContext.setAttribute(&quot;p&quot;, arr); %&gt; &lt;mytag:choose&gt; &lt;mytag:when test=&quot;${empty p }&quot;&gt; there is empty &lt;/mytag:when&gt; &lt;mytag:otherwise&gt; &lt;mytag:forEach items=&quot;${p }&quot; var=&quot;v&quot;&gt; &lt;br&gt;${v} &lt;/mytag:forEach&gt; &lt;/mytag:otherwise&gt; &lt;/mytag:choose&gt; ③ html显示文本中html代码的过滤 例如留言板中，有时候需要将html代码原样输出，而不解析。 实现类代码如下： package cn.wzbrilliant.el; import java.io.IOException; import java.io.StringWriter; import javax.servlet.jsp.JspException; import javax.servlet.jsp.tagext.SimpleTagSupport; public class HtmlTextFilterTag extends SimpleTagSupport { @Override public void doTag() throws JspException, IOException { StringWriter sw=new StringWriter(); getJspBody().invoke(sw); String content=sw.toString(); content = filter(content); getJspContext().getOut().write(content); } private String filter(String message) { if (message == null) return (null); char content[] = new char[message.length()]; message.getChars(0, message.length(), content, 0); StringBuffer result = new StringBuffer(content.length + 50); for (int i = 0; i &lt; content.length; i++) { switch (content[i]) { case &apos;&lt;&apos;: result.append(&quot;&lt;&quot;); break; case &apos;&gt;&apos;: result.append(&quot;&gt;&quot;); break; case &apos;&amp;&apos;: result.append(&quot;&amp;&quot;); break; case &apos;&quot;&apos;: result.append(&quot;&quot;&quot;); break; default: result.append(content[i]); } } return (result.toString()); } } mytag.tld中添加如下内容： &lt;tag&gt;&lt;!-- 文本中Html代码过滤标签 --&gt; &lt;description&gt;htmlfilter&lt;/description&gt; &lt;name&gt;htmlfilter&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.HtmlTextFilterTag&lt;/tag-class&gt; &lt;body-content&gt;scriptless&lt;/body-content&gt; &lt;/tag&gt; 使用方式：在jsp页面中输出文本数据时添加此标签便可将文本中html代码原样输出，而不解析。 ④防盗链标签 防止别的网站、应用盗链，可以利用EL自定义标签，将请求转向其他URI(自定义的广告等等) 实现代码如下： package cn.wzbrilliant.el; import java.io.IOException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.servlet.jsp.JspException; import javax.servlet.jsp.PageContext; import javax.servlet.jsp.tagext.SimpleTagSupport; public class RefererTag extends SimpleTagSupport { private String site; private String redirectPath; public void setSite(String site) { this.site = site; } public void setRedirectPath(String redirectPath) { this.redirectPath = redirectPath; } @Override public void doTag() throws JspException, IOException { PageContext pageContext = (PageContext) getJspContext(); HttpServletRequest request = (HttpServletRequest) pageContext.getRequest(); HttpServletResponse response = (HttpServletResponse) pageContext.getResponse(); String referer = request.getHeader(&quot;referer&quot;); if (referer != null &amp;&amp; !referer.startsWith(site)) { String path; if (redirectPath.startsWith(&quot;/&quot;)) { path = request.getContextPath() + redirectPath; } else { String uri=request.getRequestURI(); path=uri.substring(0, uri.lastIndexOf(&quot;/&quot;)+1)+redirectPath; } response.sendRedirect(path); } } } mytag.tld中添加如下内容： &lt;tag&gt;&lt;!-- 防盗链 --&gt; &lt;description&gt;referer&lt;/description&gt; &lt;name&gt;referer&lt;/name&gt; &lt;tag-class&gt;cn.wzbrilliant.el.RefererTag&lt;/tag-class&gt; &lt;body-content&gt;empty&lt;/body-content&gt; &lt;attribute&gt; &lt;name&gt;site&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;attribute&gt; &lt;name&gt;redirectPath&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;/tag&gt; 使用方法：在防盗链的页面头部添加： &lt;mytag:referer site=”http://localhost:8080/JavaWeb&quot; redirectPath=”error.jsp”/&gt; ，其中site值为本应用的URI，redirectPath是将外部应用的请求转发的目标地址，可以是相对路径，也可以是绝对路径。 四、JSTL中的核心标签库 (替换掉JSP中的Java脚本) ① c:if 作用：判断是否为true，如果为true，那么标签的主体内容就会显示。属性： test：必须的。要求必须是boolean的。支持表达式（EL或Java表达式）var：保存test运算结果的变量scope: 保存的域范围。默认是page ② c:forEach 遍历：数组、List、Set、Map属性： items：要遍历的目标对象。支持表达式var：变量名。指向当前遍历的集合中的一个元素begin：开始的索引（含）end：结束的索引（含）step：步长。默认是1varStatus：取一个名字，引用了一个对象。 该对象有以下方法：int getIndex():当前记录的索引号。从0开始int getCount():当前记录的顺序。从1开始boolean isFirst():是否是第一条记录boolean isLast():是否是最后一条记录 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Java</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jsp内置对象及EL表达式的使用]]></title>
    <url>%2F2015%2F08%2F28%2FJsp%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E5%8F%8AEL%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、JSP的内置对象 （9个JSP内置对象） JSP的内置对象引用名称 对应的类型 request HttpServletRequestresponse HttpServletResponsesession HttpSession(有开关的：page指令的session属性的取值)application ServletContextconfig ServletConfigpage this(当前Servlet对象)exception java.lang.Throwable（有开关：page指令的isErrorPage属性改为true）out JspWriterpageContext javax.servlet.jsp.PageContext非常重要 pageContext 对象有三大作用： 1、 本身是一个域对象，表示的域范围是本页面 。 同时还能操作其他三个域对象 （PageContext ，ServletRequest， HttpSession，ServletContext） 设置属性： void setAttribute(String name,Object value) void removeAttribute(String name) Object getAttribute(String name) 操作其他的三个域对象，设置属性： void setAttribute(String name,Object value,int scope) void removeAttribute(String name,int scope) Object getAttribute(String name,int scope) 参数int scope是由PageContext类提供的静态变量规定的。 PageContext.PAGE_SCOPE:页面范围（是PageContext本身中的那个Map，代号page） PageContext.REQUEST_SCOPE:请求范围（是ServletRequest中的那个Map，代号request） PageContext.SESSION_SCOPE:请求范围（是HttpSession中的那个Map，代号session） PageContext.APPLICATION_SCOPE:请求范围（是ServletContext中的那个Map，代号application） Object findAttribute(String name) ：依次按照page，request， session ，application范围搜索指定名称的对象，找到为止。 EL表达式便是调用了此方法（非常有用） 2、获取其他8个隐式对象 3、提供了转发和包含的方便方法 若不用pageContext对象： RequestDispatcher rd = request.getRequestDispatcher(“/url”); rd.forward(request,response); 用pageContext对象：pageContext.forward(“url”); pageContext.include(“url”); 四大域对象 (两个资源之间互传数据) J SP中隐式对象的名称 范围名称 具体的类型 pageContext page javax.servlet.jsp.PageContextrequest request javax.servlet.ServletRequestsession session javax.servlet.http.HttpSessionapplication application javax.servlet.ServletContext (如果使用，必须同步处理) 二、EL表达式 它只是JSP中的表达式，不是一种开发语言。 基本语法：${EL表达式} 1. 获取数据 EL表达式只能获取四大域中的数据。 EL表达式获取的对象如果是null，页面不会显示数据。因此，EL表达式中永远不会出现空指针异常 “ . “ 运算符 ： ${p.name}：调用域中名称为p对象的getName方法，点运算符是用于获取属性的取值的。 “ [] “ 运算符 ： (.运算符能做的，[]也能做。[]能做的，.不一定能做) 比如${p.name}===${p[‘name’]}==${p[“name”]} 优秀在可以取不符合Java命名规范的东东。 2. 数学逻辑运算: empty运算符：如果判断的对象是null或者空字符串，都返回true。 对于集合，即使集合对象本身不是null，没有任何元素，也返回true。 EL表达式不支持字符串连接操作。 三、EL内置对象 （11大EL内置对象） 获取JSP的内置对象（11大EL内置对象）：难点，不要与JSP的内置对象和范围名称搞混 11大EL隐式对象中，其中一个是表示自身对象外，其余都是表示的Map结构 EL隐式对象名称 Java类型 备注 pageContext javax.servlet.jsp.PageContext 与JSP中的内置对象完全相同 剩余的都是代表的Map集合 pageScope java.util.Map 代表着PageContext页面范围域那个Map requestScope java.util.Map 代表着ServletRequest请求范围域那个Map sessionScope java.util.Map 代表着HttpSession会话范围域那个Map applicationScope java.util.Map 代表着ServletContext应用范围域那个Map param java.util.Map 代表着请求参数。key：请求参数的名称。value：请求参数的值，它是一个字符串。 paramValues java.util.Map 代表着请求参数。key：请求参数的名称。value：请求参数的值，它是一个字符串数组。 header java.util.Map 代表着请求消息头。key：头名称。value：头值，它是一个字符串。 headerValues java.util.Map 代表着请求消息头。key：头名称。value：头值，它是一个字符串数组。 cookie java.util.Map 代表客户端提交的Cookie的Map。key：cookie的name。value：cookie对象本身 initParam java.util.Map 代表着全局初始化参数（web.xml中context-param）.key：参数名称。value：参数值 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Java</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jsp语法、指令及动作元素]]></title>
    <url>%2F2015%2F08%2F27%2FJsp%E8%AF%AD%E6%B3%95%E3%80%81%E6%8C%87%E4%BB%A4%E5%8F%8A%E5%8A%A8%E4%BD%9C%E5%85%83%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[一、JSP的语法 1、JSP的模板元素：(先写HTML) 就是JSP中的那些HTML标记 作用：页面布局和美化 2、JSP的Java脚本表达式： 作用：输出数据到页面上 语法：&lt;%=表达式%&gt;(实际上就是调用输出流打印到页面上) 3、JSP中的Java脚本片段：(实际开发中，应做到JSP中不能出现一行Java脚本片段) 作用：书写Java代码逻辑 语法：&lt;%语句1;语句2;%&gt; 语句为Java语句 原理：其中的语句会原封不动的被服务器翻译到对应的Servlet的service方法中。 4、JSP的声明：（了解其原理） 作用：定义类的成员 语法：&lt;%!Java代码%&gt; 5、JSP的注释： 作用：注释Java脚本代码 语法：&lt;%–这是注释–%&gt; Jsp注释在客户端查看源文件无法看到，而Html注释在客户端可以看到 二、JSP的指令:给JSP引擎用的（服务器用的） 基本的语法格式：&lt;%@ 指令名称 属性1=”值1” 属性2=”值2” ….%&gt;作用：告诉服务器，该如何处理JSP中除了指令之外的内容的。 1. page作用：定义JSP页面的各种属性属性： language :指示JSP页面中使用脚本语言。默认值java，目前只支持java。 extends ：指示JSP对应的Servlet类的父类。不要修改。 import ：导入JSP中的Java脚本使用到的类或包。（如同Java中的import语句）JSP引擎自动导入以下包中的类：javax.servlet.javax.servlet.http.javax.servlet.jsp.*注意：一个import属性可以导入多个包，用逗号分隔。 sessioin :指示JSP页面是否创建HttpSession对象。默认值是true，创建 buffer ：指示JSP用的输出流的缓存大小.默认值是8Kb。 autoFlush ：自动刷新输出流的缓存。 isThreadSafe ：指示页面是否是线程安全的（过时的）。默认是true。true：不安全的。false：安全的。指示JSP对应的Servlet实现SingleThreadModel接口。 errorPage ：指示当前页面出错后转向（转发）的页面。目标页面如果以”/“（当前应用）就是绝对路径。 配置全局错误提示页面：在web.xml中，两种花方式： java.lang.Exception /error.jsp 以及 404 /404.jsp isErrorPage ：指示当前页面是否产生Exception对象。 contentType ：指定当前页面的MIME类型。作用与Servlet中的response.setContentType()作用完全一致 pageEncoding ：通知引擎读取JSP时采用的编码（因为要翻译）还有contentType属性的作用。 isELIgnored :是否忽略EL表达式。${1+1}。默认值是false。 page指令最简单的使用方式：&lt;%@ page pageEncoding=”UTF-8”%&gt; 2. include （ 静态包含 ,开发中能用静的不用动的） 作用：包含其他的组件。 语法：&lt;%@include file=””%&gt;file指定要包含的目标组件。路径如果以”/“（当前应用）就是绝对路径。 原理：把目标组件的内容加到源组件中，输出结果。容器不必先生成被包含jsp页面或servlet的class文件，而是直接将内容添加到源组件中 动态包含 ： 采用动作元素：&lt;jsp:include page=””/&gt;路径如果以”/“（当前应用）就是绝对路径。 原理：先生成被包含jsp页面或servlet的class文件，再添加到源组件中 3. taglib 作用：引入外部的标签 语法：&lt;%@taglib uri=”标签名称空间” prefix=”前缀”%&gt; &lt;%@ taglib uri=”http://java.sun.com/jsp/jstl/core&quot; prefix=”c”%&gt; 三、JSP常用的动作元素 jsp:include/ 包含 jsp:forward/ 请求转发 jsp:param/:在包含和转发时，利用该标签传递请求参数 JSP中操作JavaBean的动作元素： 1. jsp:useBean 作用：用于在指定域范围内查找指定名称的JavaBean对象，找到了就直接使用；没有找到，创建一个，并放到指定的域范围内。 属性：id：必须的。JavaBean的名称 class:JavaBean的完整类名 scope：域范围。默认是page范围。可选值：page request session application 注意：如果该标签有主体内容，只在创建新对象时才会执行。 2. jsp:setProperty （必须先使用useBean） 作用：调用JavaBean的setter方法。还能自动类型转换，仅限基本类型 属性：property：必须的。属性名称。比如setName,名称是name。可以使用通配符*。使用前提是请求参数的名称与属性的名称完全一致。 name：必须的。哪个对象的？即jsp:useBean中的id的取值。 value：属性的取值。支持直接量；支持表达式（&lt;%=表达式%&gt;）。 param:请求参数名 3. jsp:getProperty （必须先使用useBean） 作用：调用JavaBean的getter方法。 property：必须的。属性的名称。比如getName,名称是name。 name:必须的。哪个对象的？即jsp:useBean中的id的取值。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Java</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java之Cookie详解]]></title>
    <url>%2F2015%2F08%2F19%2Fjava%E4%B9%8BCookie%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Cookie 是由服务器端生成，发送给User-Agent（一般是浏览器），浏览器会将Cookie的key/value保存到某个目录下的文本文件内，下次请求同一网站时就发送该Cookie给服务器（前提是浏览器设置为启用cookie）。Cookie名称和值可以由服务器端开发自己定义，对于JSP而言也可以直接写入JSESSIONID用于标记一个会话(session)，这样服务器可以知道该用户是否合法用户以及是否需要重新登录等，服务器可以设置或读取Cookies中包含信息，借此维护用户跟服务器会话中的状态。 Cookie是客户端技术，而HttpSession是服务器端技术。 java中Cookie详细介绍: 1、Cookie是什么？ 一个小信息，由服务器写给浏览器的。由浏览器来保存。 客户端保存的Cookie信息，可以再次带给服务器。 Cookie类：javax.servlet.http.Cookie 2、Cookie的属性： name ： 必须的 value ： 必须的 comment ：可选的。注释 path ： 可选的， 如果不设置路径，那么只有设置该cookie的URI及其子路径可以访问 写Cookie的程序的访问路径是：http://localhost:8080/JavaWeb/servlet/CookieDemo 其中：localhost就是域名；/JavaWeb/servlet就是当前Cookie的path 若访问的地址的URI包含着cookie的路径，即URI.startWith(cookie的路径),为true，则客户端将该cookie带给服务器。 比如浏览器存的cookie的路径是/JavaWeb现在访问的地址是：http://localhost:8080/JavaWeb/servlet/CookieDemo 则带该cookie现在访问的地址是：http://localhost:8080/JavaWeb/CookieDemo 则带该cookie 若浏览器存的cookie的路径是/JavaWeb/servlet/访问的地址是：http://localhost:8080/JavaWeb/servlet/CookieDemo 则带该cookie访问的地址是：http://localhost:8080/JavaWeb/CookieDemo 则不带该cookie 如果一个cookie的路径设置成了/JavaWeb，意味着 浏览器访问 当前应用下的所有资源时都会带着该cookie给服务器。 domain ：可选的。该Cookie所属的网站域名。（apache.org）默认值。 maximum age ：可选的。不设置就是会话过程（存在浏览器的内存中）。单位是秒如果是0，说明要删除。 version ：可选的。 3、如何向客户端写Cookie： HttpServletResponse对象.addCookie(javax.servlet.http.Cookie对象)（就是写了一个响应消息头：Set-Cookie:cookie的信息） Servlet规范中的Cookie API 提供了 setMaxAge setPath setDomain等方法，可以对Cookie状态进行控制 特点：一个浏览器针对一个网站最多存20个Cookie；最多存300个Cookie，每个Cookie的长度不能超过4KB（稀缺）。只是规定，但不同的浏览器实现的不同。 public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { Cookie cookie=new Cookie(&quot;name&quot;,&quot;Tom&quot;); //设置Maximum Age cookie.setMaxAge(1000); //设置cookie路径为当前项目路径 cookie.setPath(request.getContextPath()); //添加cookie response.addCookie(cookie); } 4、服务器如何得到客户端传来的Cookie： 在Java中利用Serlvet或者JSP scriptlet可以向浏览器端写入Cookie， 同样，利用Servet或者JSP scriptlet 也可以读取到 Cookie信息 Servlet规范中的Cookie API 同样存在getMaxAge getPath getDomain等方法，可以获得相应的状态。 不过此处存在一个问题： 读取Cookie时，发现除了Cookie的key和value外，其他值获取都为null。 原因很简单： Cookie从服务器端发送到客户端时，信息是完整的， Cookie从客户器端发送到服务端时，信息只剩下key、value了。(因为 Domain不对的Cookie、Path不对的Cookie、过期的Cookie，客户端是不会发送过来的) 那为什么Java中提供了相应的get方法呢？ 那个方法其实是在生成Cookie后，尚未发送到客户端时使用的 服务器端通过HttpServletRequest对象.getCookies()可获取cookies数组。 public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { PrintWriter out=response.getWriter(); Cookie[] cookies=request.getCookies(); if(cookies!=null){ for(Cookie cookie:cookies){ String name=cookie.getName(); String value=cookie.getValue(); out.write(name+&quot;=&quot;+value); } } } 5、如何区分Cookie： 通过名称不行,应通过 domain+path+name来区分的。 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[servlet请求转发、包含以及重定向]]></title>
    <url>%2F2015%2F08%2F19%2Fservlet%E8%AF%B7%E6%B1%82%E8%BD%AC%E5%8F%91%E3%80%81%E5%8C%85%E5%90%AB%E4%BB%A5%E5%8F%8A%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[请求转发： 方式一: ServletContext对象.getRequestDispatcher(目标资源的URI).forward(request,response); 目标资源的URI “/servlet/GetParam” 必须以”/“开头，否则报错，此”/“就表示的是当前应用（绝对路径表示法） 方式二： request.getRequestDispatcher(目标资源的URI).forward(request,response); 目标资源的URI “/servlet/GetParam” 如果以”/“开头，就表示的是当前应用（绝对路径表示法）。 GetParam” 如果不以”/“开头，就表示相对路径。相对路径：两个绝对路径去掉前面相同的部分 由源组件转发到目标组件时，容器会清空源组件输出的数据。响应头信息是不清空的，客户端地址栏URL不变 编码原则：不要在转发前后向页面输出数据，也不要关闭输出流。 public void forward(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 方式一 // RequestDispatcher rd=getServletContext().getRequestDispatcher(&quot;/servlet/NewPage&quot;); // 方式二 RequestDispatcher rd=request.getRequestDispatcher(&quot;NewPage&quot;); rd.forward(request, response); } 包含(动态包含)： request.getRequestDispatcher(目标资源的URI).include(request,response); 由源组件包含到目标组件时，容器会清空目标组件的头，所以源组件设置的头才有效。响应体信息是不清空的。 编码原则：不要在目标组件中设置响应头。 public void include(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException{ RequestDispatcher rd=request.getRequestDispatcher(&quot;/servlet/NewPage&quot;); rd.include(request, response); } 重定向： response.sendRedirect(“/../…”) 目标资源的URI /应用名/路径.. 绝对路径，”/“后跟应用名 客户端跳转，request中数据不传递!客户端地址栏URL改变。 public void redirect(HttpServletRequest request, HttpServletResponse response) throws IOException{ response.sendRedirect(&quot;/WebProjectName/newURL&quot;); } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[servlet设置缓存时间以及文件的下载]]></title>
    <url>%2F2015%2F08%2F19%2Fservlet%E8%AE%BE%E7%BD%AE%E7%BC%93%E5%AD%98%E6%97%B6%E9%97%B4%E4%BB%A5%E5%8F%8A%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[缓存时间的设置： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html;charset=UTF-8&quot;); PrintWriter out = response.getWriter(); response.setDateHeader(&quot;Expires&quot;, System.currentTimeMillis()+60*60*1000);//缓存时间一小时 out.write(&quot;hello world&quot;); } 通知客户端文件的下载，此处以图片为例： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html&quot;); ServletContext context=getServletContext(); String path=context.getRealPath(&quot;/picture.jpg&quot;); String fileName=path.substring(path.lastIndexOf(&quot;\\&quot;)+1); InputStream in=new FileInputStream(path); //通知客户端文件的下载 URLEncoder.encode解决文件名中文的问题 response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot;+URLEncoder.encode(fileName, &quot;utf-8&quot;)); response.setHeader(&quot;Content-Type&quot;, &quot;application/octet-stream&quot;); OutputStream out=response.getOutputStream(); int length=-1; byte []buffer=new byte[1024]; while((length=in.read(buffer))!=-1){ out.write(buffer,0,length); } in.close(); } 博客园博客:欠扁的小篮子]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet响应的中文字符集问题]]></title>
    <url>%2F2015%2F08%2F05%2FServlet%E5%93%8D%E5%BA%94%E7%9A%84%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6%E9%9B%86%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在Servlet中利用response向客户端浏览器输出中文时有时会遇到乱码问题，总结如下： response输出流有两种，一是以字节流输出，一是以字符流输出。 一、以字节流输出：1.默认编码输出木有乱码2.通过response的setHeader方法设置编码utf-8，无乱码3.通过response的setContentType方法设置编码utf-8，无乱码4.输出数字建议以字符串形式输出 二、以字符流输出：1.默认查iso-8859-1码表(SUN的Servlet规范要求的) ，客户端显示乱码2.通过response的setHeader方法设置编码utf-8，无乱码3.通过response的setContentType方法设置编码utf-8，无乱码 字节流以默认编码输出： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 以字节流用默认编码向客户端输出中文数据,木有乱码 response.setContentType(&quot;text/html&quot;); String str = &quot;喔呵呵呵呵&quot;; OutputStream out = response.getOutputStream(); out.write(&quot;&lt;/br&gt;&lt;/br&gt;&lt;div align=\&quot;center\&quot; style=\&quot;font-size:25px; color:red\&quot;&gt;&quot;.getBytes()); out.write(str.getBytes()); out.write(&quot;&lt;/div&gt;&quot;.getBytes()); out.close(); } 字节流设置编码为utf-8输出： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 通知客户端查UTF-8码表 response.setContentType(&quot;text/html;charset=utf-8&quot;); // 或者： // response.setHeader(&quot;Content-Type&quot;,&quot;text/html;charset=utf-8&quot;); String str = &quot;喔哈哈哈哈&quot;; OutputStream out = response.getOutputStream(); out.write(&quot;&lt;/br&gt;&lt;/br&gt;&lt;div align=\&quot;center\&quot; style=\&quot;font-size:25px; color:red\&quot;&gt;&quot;.getBytes()); out.write(str.getBytes(&quot;utf-8&quot;)); out.write(&quot;&lt;/div&gt;&quot;.getBytes()); out.close(); } 字节流输出数字： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setHeader(&quot;Content-Type&quot;, &quot;text/html;charset=utf-8&quot;); int i = 98; OutputStream out = response.getOutputStream(); out.write(&quot;&lt;/br&gt;&lt;/br&gt;&lt;div align=\&quot;center\&quot; style=\&quot;font-size:25px; color:red\&quot;&gt;&quot; .getBytes()); // out.write(i); 会输出字母b // 输出数字98 out.write((i + &quot;&quot;).getBytes()); out.write(&quot;&lt;/div&gt;&quot;.getBytes()); out.close(); } 字符流设置编码为utf-8输出： public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 通知客户端查UTF-8码表 response.setContentType(&quot;text/html;charset=utf-8&quot;); // 或者： // response.setHeader(&quot;Content-Type&quot;, &quot;text/html;charset=utf-8&quot;); String str = &quot;喔嘿嘿嘿嘿&quot;; PrintWriter out = response.getWriter(); out.write(&quot;&lt;/br&gt;&lt;/br&gt;&lt;div align=\&quot;center\&quot; style=\&quot;font-size:25px; color:red\&quot;&gt;&quot;); out.write(str); out.write(&quot;&lt;/div&gt;&quot;); out.flush(); out.close(); }]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之链表、栈和队列 java代码实现]]></title>
    <url>%2F2015%2F08%2F03%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%93%BE%E8%A1%A8%E3%80%81%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%20%20%20java%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[定义抽象节点类Node： package cn.wzbrilliant.datastructure; /** * 节点 * @author ice * */ public abstract class Node { private Node next; public Node(){ next=null; } public void setNext(Node nextNode){ next=nextNode; } public Node getNext(){ return next; } } 链表类，实现了插入首尾节点、指定位置节点，删除节点、指定位置节点，链表的逆序以及判空操作： package cn.wzbrilliant.datastructure; /** * 链表 * @author ice * */ public class Link { protected Node head; protected Node tail; protected int size; public Link() { this.head = null; this.tail = null; this.size = 0; } public void addAtFirst(Node node){ node.setNext(head); head=node; if(size==0) tail=node; size++; } public void addAtLast(Node node){ if(size==0){ head=tail=node; }else{ tail.setNext(node); tail=node; } node.setNext(null); size++; } public void removeFirst(){ if(size==0) throw new RuntimeException(&quot;link size is 0...&quot;); head=head.getNext(); if(size==1){ tail.setNext(null); } size--; } public void removeLast(){ if(size==0) throw new RuntimeException(&quot;link size is 0...&quot;); if(size==1){ head=tail=null; size--; return ; } Node node=head; while(node.getNext()!=tail){ node=node.getNext(); } node.setNext(null); tail=node; size--; } /** * 队列逆序 */ public void reverse() { Node preNode, node, tempNode; if (size == 0) return; preNode = head; node = preNode.getNext(); preNode.setNext(null); tail = preNode; while (node != null) { tempNode = node.getNext(); node.setNext(preNode); preNode = node; node = tempNode; } head = preNode; } /** * 在第index个节点后插入newNode * * @param newNode * @param index */ public void insert(Node newNode, int index) { if (index &lt; 0 || index &gt; size) throw new RuntimeException(&quot;索引错误&quot;); if (index == 0) { newNode.setNext(head); head = newNode; size++; return; } if (index == size) { newNode.setNext(null); tail.setNext(newNode); tail = newNode; size++; return; } Node node = head; for (int i = 1; node != null; i++, node = node.getNext()) { if (i == index) { newNode.setNext(node.getNext()); node.setNext(newNode); size++; return; } } } /** * 移除Node节点 Node节点需重写equals()方法 * * @param node */ public void remove(Node node) { if (node == null || size == 0) throw new RuntimeException(&quot;remove error...&quot;); for (Node temp = head; temp != null; temp = temp.getNext()) { if (temp == head) { if (temp.equals(node)) { head = head.getNext(); size--; continue; } } if (temp.getNext().equals(node)) { temp.setNext(temp.getNext().getNext()); size--; } } } public Node getFirst() { if (size == 0) return null; return head; } public Node getLast() { if (size == 0) return null; return tail; } public int size() { return size; } public boolean isEmpty() { if (size == 0) return true; return false; } } 栈类，实现了入栈、出战、获取栈顶元素以及判空的操作： package cn.wzbrilliant.datastructure; /** * 栈 * @author ice * */ public class Stack { private int size; private Node top; public Stack() { size = 0; top = null; } public void push(Node node) { node.setNext(top); top = node; size++; } public Node pop() { if (top == null) return null; Node node = top; top = top.getNext(); size--; return node; } public Node top() { return top; } public int size() { return size; } public boolean isEmpty() { if (size == 0) return true; return false; } } 队列类，实现了入队、出队、判空的操作： package cn.wzbrilliant.datastructure; /** * 队列 * @author ice * */ public class Queue { private Node head; private Node tail; private int size; public Queue() { this.head = null; this.tail = null; this.size = 0; } public void enQueue(Node node) { tail.setNext(node); tail = node; size++; } public Node deQueue() { if (size == 0) return null; Node node = head; head = head.getNext(); size--; return node; } public int size() { return size; } public boolean isEmpty() { if (size == 0) return true; return false; } }]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求与响应]]></title>
    <url>%2F2015%2F08%2F03%2FHTTP%E8%AF%B7%E6%B1%82%E4%B8%8E%E5%93%8D%E5%BA%94%2F</url>
    <content type="text"><![CDATA[Http协议对浏览器发出的Request格式以及对Web服务器发出的Response格式有具体的规定。 请求部分由三部分组成： Requset line ：请求行,位于第一行 Request headers ：请求消息头,从第二行开始至第一个空行结束 Request body ：请求正文,从第一个空行之后的都是正文 响应部分也由三部分组成： Response line ：响应行,位于第一行 Response headers ：响应消息头,从第二行开始至第一个空行结束 Response body ：响应正文,从第一个空行之后的都是正文 一、Http请求 Http请求具体格式如下： Method Path-to-resource Http/Version-number User-agent 浏览器的类型 Accept 浏览器接受的MIME类型 Accept language 用户选择的接受语言 Accept-charset 用户首选的编码字符集 …… 空行 Option Request Body ①请求行： 1.Method为请求方式，包括 OPTIONS、GET、HEAD、POST、PUT、DELETE、TRACE ，常用的是GET和POST GET 的特点：默认的请求方式。当请求的资源路径为/SdustExam/Login.jsp?username=admin&amp;password=123456时，GET方式会把表单的请求的数据放在请求的URI的后面，?username=admin&amp;password=123456，这样会暴露数据，而且请求行长度有限。 POST 的特点(经常使用的)：借助HTML中的form表单。请求参数出现在正文部分，长度木有限制，相对安全 。 2.Path-to-resource ：请求的资源的URI。例如/SdustExam/Login.jsp 3.Http/Version-number：客户端使用的协议的版本，有HTTP/1.0和HTTP/1.1。 HTTP/1.0：特点：每次请求服务器上的资源都要建立新的连接，响应完毕后都会关闭连接。是无状态的协议。HTTP/1.1:特点：在一次TCP/IP连接的基础上可以发出多次请求和得到多次的响应。比1.0多了一些请求和响应头。 ②请求消息头 向服务器传递附加信息 Accept :通知服务器，浏览器可以接受的MIME类型。（文件系统中用文件扩展名区分数据的类型。网络上用MIME类型来区分数据类型。Tomcat\conf\web.xml）MIME类型名称 ：大类型/小类型 如text/html、text/css等等Accept-Charset :通知服务器，浏览器支持的字符集，如gbk,utf-8Accept-Encoding :通知服务器，浏览器能够解码的数据压缩方式。比如：gzipAccept-language :通知服务器，所希望的语言Host ：请求的主机和端口Referer ：是一个URL地址。取值是当前页面之前的那个页面地址的。防盗链用Content-Type :通知服务器，请求正文的MIME类型。取值：application/x-www-form-urlencoded默认值,对应的是form表单的enctype属性If-Modified-Since :通知服务器，缓存的文件的最后修改时间。User-Agent :通知服务器，浏览器类型.Content-Length :表示请求消息正文的长度Connection :表示是否需要持久连接。如果服务器看到这里的值为“Keep -Alive”，或者看到请求使用的是HTTP 1.1(HTTP 1.1默认进行持久连接 )Cookie :这是最重要的请求头信息之一（会话有关） 二、http响应 http响应具体格式如下： Http/Version-number Statuscode message Server 服务器的类型信息 Content-type 响应的MIME类型信息 Content-length 被包含在相应类型中的字符数量 …… 空行 Option Response Body ①响应行： Http/Version-number：服务器用的协议版本Statuscode：响应码。代表服务器处理的结果的一种表示，常用的响应码有：200：正常302/307：重定向304:服务器的资源没有被修改404：请求的资源不存在500：服务器报错了message：响应码描述。例如200的描述为OK ② 响应消息头： Location :通知客户端，指示新的资源的位置（结合302/307来用。请求重定向）Server :通知客户端，服务器的类型Content-Encoding :通知客户端，响应正文的压缩编码方式。常用的是gzip。Content-Length ：通知客户端响应正文的数据大小Content-Type :通知客户端响应正文的MIME类型Refresh ：让浏览器自动刷新。取值为整数（刷新的时间间隔，单位是秒）Refresh:3Refresh:3;URL=其他资源的URIContent-Disposition ：通知客户端，以下载的方式打开资源。Content-Disposition ：attachment;filename=1.jpgSet-Cookie :SS=Q0=5Lb_nQ; path=/search服务器端发送的Cookie（会话有关）Expires : -1 网页的有效时间。单位是毫秒，-1为通知客户端不要缓存Cache-Control : no-cache (1.1) 通知客户端不要缓存Pragma : no-cache (1.0) 通知客户端不要缓存]]></content>
      <categories>
        <category>Web</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>网络协议</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 数据类型]]></title>
    <url>%2F2015%2F06%2F29%2FJavaScript%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[在javascript中,数据类型分为两类： 基本数据类型 和 引用数据类型 。javascript中声明变量使用关键字 var 。 一、基本数据类型 javascrip含有五种基本数据类型： undefined ， null ， boolean ， number 和 string 。 boolean ： 布尔，值为 true 或 false number ：数字，值为任何整型会浮点数值 string ：字符串，值为由单引号或双引号括出的单个字符或连续字符（JavaScript不区分字符类型） null ：空类型，其仅有一个值： null undefined ：未定义，其仅有一个值： undefined typeof 关键字 ：由于Javascript中的变量是松散类型的，所以它提供了一种检测当前变量的数据类型的方法，也就是 typeof 关键字，在上面提到的ECMAScript中的5种简单数据类型中（这5种只是 数据类型 ，代表一种数据类型，就想C#中的int，string类型一样），通过 typeof 关键字，对这5种数据类型会返回下面的值（以字符串形式显示） “ boolean “ ——如果变量值为 布尔 类型； “ number “ ——值为 数字 类型； “ string “ ——值为 字符串 类型； “ object “ —— 对象 或者 值为 null ； “ undefined “ —— 未申明 ，或者变量的 值为undefined 或者 未初始化 ； 原始类型的值是直接保存在变量中，并可以用 typeof 进行检测。但是 typeof 对 null 的检测是返回 object ,而不是返回 null 。所以检测 null 时，最好用全等于( === ),其还能避免强制类型转换。 对于字符串、数字或者布尔值，其都有对应的方法，这些方法来自于对应的原始封装类型： String 、 Number 和 Boolean 。原始封装类型将被自动创建。例如： var name = &quot;Tom&quot;; var char = name.charAt(0); console.log(char); // &quot;T&quot; 在JavaScript引擎中发生的事情： var person = &quot;Tom&quot;; var temp = new String(person); var char = temp.charAt(0); temp = null; console.log(char); // &quot;T&quot; 字符串对象的引用在用完之后立即被销毁，所以不能给字符串添加属性，并且 instanceof 检测对应类型时均返回 false ： var person = &quot;Tom&quot;; person.age = 21; console.log(person.age); //undefined console.log(person instanceof String); //false 二、引用数据类型 引用类型 ：保存为对象，实质是指向内存位置的引用，所以不在变量中保存对象。除了自定义的对象，JavaScript提供了多种内建类型。 Object 类型： Object 类型是Javascript引用类型的鼻祖了，就跟在C#和Java中是一样的道理，在创建Object类型的实例后可以为其添加属性和方法。 以 Object 为基础，JavaScript提供的内建类型如图所示： Array ：数组类型，以数字为索引的一组值的有序列表 Date ：日期和时间类型 Error ：运行期错误类型 Function ：函数类型 RegExp ：正则表达式类型 可以用new 来实例化每一个对象，或者用字面量形式来创建对象： var obj = new Object(); var person = { name:&quot;Tom&quot;, sex:&quot;man&quot;, &quot;my age&quot;:22 }; console.log(person.sex); //访问属性 console.log(person[&quot;my age&quot;]); obj = null; //解除引用 obj并不包含对象实例，而是一个指向内存中实际对象所在位置的指针（或者说引用）。因为 typeof 对所有非函数的引用类型均返回 object ，所以需要用 instanceof 来检测引用类型。 Object对象 对象是一种引用类型，创建对象常见的两种方式：Object构造函数和对象字面量形式： var p1 = { name:&quot;Tom&quot;, age:22 }; var p2 = new Object(); p2.name = &quot;Jack&quot;; 在JavaScript中，可以随时为对象添加属性： p1.age = 0; p1.sayName = function(){ alert(this.name); } p1.sayName(); //&quot;Tom&quot; 检测属性是否存在时，有两种方式： in 和 hasOwnProperty() ，前者会检测原型属性和自有(实例)属性，后者只检测自有(实例)属性： console.log(&quot;age&quot; in p1); //true console.log(p1.hasOwnProperty(&quot;age&quot;)); //true console.log(&quot;toString&quot; in p1); //true console.log(p1.hasOwnProperty(&quot;toString&quot;)); //false 对象 p1 并没有定义 toString，该属性继承于Object，所以 in 和hasOwnProperty()检测该属性时出现差异. 若要删除一个属性，用 delete 操作符，用于删除自有属性，不能删除原型属性： p1.toString = function(){ console.log(&quot;p1对象&quot;); }; console.log(p1.hasOwnProperty(&quot;toString&quot;)); //true p1.toString(); //&quot;per1对象&quot; delete p1.toString; console.log(p1.hasOwnProperty(&quot;toString&quot;)); //false console.log(p1.toString()); //[object Object]]]></content>
      <categories>
        <category>js</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdbc基础 (五) 连接池与数据源:DBCP以及C3P0的使用]]></title>
    <url>%2F2015%2F06%2F28%2Fjdbc%E5%9F%BA%E7%A1%80%20(%E4%BA%94)%20%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%BA%90%3ADBCP%E4%BB%A5%E5%8F%8AC3P0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、连接池的概念和使用 在实际应用开发中，特别是在WEB应用系统中，如果JSP、Servlet或EJB使用 J DBC直接访问数据库中的数据，每一次数据访问请求都必须经历建立数据库连接、打开数据库、存取数据和关闭数据库连接等步骤，而连接并打开数据库是一件既消耗资源又费时的工作，如果频繁发生这种数据库操作，系统的性能必然会急剧下降，甚至会导致系统崩溃。 数据库连接池 技术是解决这个问题最常用的方法。 数据库连接池的主要操作如下： （1）建立数据库连接池对象。 （2）按照事先指定的参数创建初始数量的数据库连接（即：空闲连接数）。 （3）对于一个数据库访问请求，直接从连接池中得到一个连接。如果数据库连接池对象中没有空闲的连接，且连接数没有达到最大（即：最大活跃连接数），创建一个新的数据库连接。 （4）存取数据库。 （5）关闭数据库，释放所有数据库连接（此时的关闭数据库连接，并非真正关闭，而是将其放入空闲队列中。如实际空闲连接数大于初始空闲连接数则释放连接）。 （6）释放数据库连接池对象（服务器停止、维护期间，释放数据库连接池对象，并释放所有连接）。 二、开源的连接池项目 DBCP 和 C3P0 1 . DBCP ( DataBase connection pool ) ， 数据库连接池 ， 是 apache 上的一个 java 连接池项目，也是 tomcat 使用的连接池组件。单独使用dbcp需要2个包： commons-dbcp.jar，commons-pool.jar 。最新jar包为 commons-dbcp2-2.1 和 commons-pool2-2.4.1 ，支持java7以上 2. C3P0 是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有 Hibernate，Spring 等 dbcp没有自动回收空闲连接的功能，c3p0有自动回收空闲连接功能 三、DBCP 和C3P0的使用 1.DBCP使用 ①将 commons-dbcp2-2.1 和 commons-pool2-2.4.1 导入项目 ②配置文件为 dbcpconfig.properties ，连接设置自行配置，内容 如下： #连接设置 driverClassName=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/day16 username=root password=123456 #&lt;!-- 初始化连接 --&gt; initialSize=10 #最大连接数量 maxActive=50 #&lt;!-- 最大空闲连接 --&gt; maxIdle=20 #&lt;!-- 最小空闲连接 --&gt; minIdle=5 #&lt;!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 --&gt; maxWait=60000 #JDBC驱动建立连接时附带的连接属性属性的格式必须为这样：[属性名=property;] #注意：&quot;user&quot; 与 &quot;password&quot; 两个属性会被明确地传递，因此这里不需要包含他们。 connectionProperties=useUnicode=true;characterEncoding=utf8 #指定由连接池所创建的连接的自动提交（auto-commit）状态。 defaultAutoCommit=true #driver default 指定由连接池所创建的连接的只读（read-only）状态。 #如果没有设置该值，则“setReadOnly”方法将不被调用。（某些驱动并不支持只读模式，如：Informix） defaultReadOnly= #driver default 指定由连接池所创建的连接的事务级别（TransactionIsolation）。 #可用值为下列之一：（详情可见javadoc。）NONE,READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE defaultTransactionIsolation=REPEATABLE_READ ③写一个工具类，功能类似于 jdbc基础 (二) 通过properties配置文件连接数据库 中的 JdbcUtils ，不过此处原理为从连接池中获取一个数据源，通过数据源来获取Connection对象。代码如下： package com.cream.ice.jdbc; import java.io.InputStream; import java.sql.Connection; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.util.Properties; import javax.sql.DataSource; import org.apache.commons.dbcp2.BasicDataSourceFactory; /** * DBCP工具类 * DBCP使用的默认适配器方式，当Connection对象调用close()方法时，将Connection对象放回连接池中，实际上并不关闭连接 * 通过dbcpconfig.properties文件配置数据库、连接池参数 * * @author ice * */ public class DBCPUtils { public static DataSource dataSource; static { try { InputStream in = DBCPUtils.class.getClassLoader() .getResourceAsStream(&quot;dbcpconfig.properties&quot;); Properties properties = new Properties(); properties.load(in); //返回数据源对象 dataSource = BasicDataSourceFactory.createDataSource(properties); } catch (Exception e) { e.printStackTrace(); } } /** * 获取数据源 * @return 数据源 */ public static DataSource getDataSource(){ return dataSource; } /** * 从连接池中获取连接 * @return */ public static Connection getConnection(){ try { return dataSource.getConnection(); } catch (SQLException e) { throw new RuntimeException(e); } } /** * 释放资源 */ public static void releaseResources(ResultSet resultSet, Statement statement, Connection connection) { try { if (resultSet != null) resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } finally { resultSet = null; try { if (statement != null) statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally { statement = null; try { if (connection != null) connection.close(); } catch (SQLException e) { e.printStackTrace(); } finally { connection = null; } } } } } 2.C3P0使用 ①导入 c3p0-0.9.5.1.jar 和 mchange-commons-java-0.2.10.jar ②配置文件为 c3p0-config.xml ，内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;c3p0-config&gt; &lt;default-config&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/jdbc&lt;/property&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;checkoutTimeout&quot;&gt;30000&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxStatements&quot;&gt;200&lt;/property&gt; &lt;user-overrides user=&quot;test-user&quot;&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;maxStatements&quot;&gt;0&lt;/property&gt; &lt;/user-overrides&gt; &lt;/default-config&gt; &lt;!-- This app is massive! --&gt; &lt;named-config name=&quot;intergalactoApp&quot;&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;50&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;50&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;1000&lt;/property&gt; &lt;!-- intergalactoApp adopts a different approach to configuring statement caching --&gt; &lt;property name=&quot;maxStatements&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;maxStatementsPerConnection&quot;&gt;5&lt;/property&gt; &lt;!-- he&apos;s important, but there&apos;s only one of him --&gt; &lt;user-overrides user=&quot;master-of-the-universe&quot;&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;1&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;5&lt;/property&gt; &lt;property name=&quot;maxStatementsPerConnection&quot;&gt;50&lt;/property&gt; &lt;/user-overrides&gt; &lt;/named-config&gt; &lt;/c3p0-config&gt; ③编写工具类，代码如下： package com.cream.ice.jdbc; import java.sql.Connection; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import javax.sql.DataSource; import com.mchange.v2.c3p0.ComboPooledDataSource; /** * C3P0工具类 * DBCP使用动态代理，当Connection对象调用close()方法时，将Connection对象放回连接池中，实际上并不关闭连接 * 通过c3p0-config.xml文件配置数据库、连接池参数 * @author ice * */ public class C3P0Utils { /** * 数据源 */ public static ComboPooledDataSource cpDataDataSource = new ComboPooledDataSource(); /** * 获取数据源 * @return 数据源 */ public static DataSource getDataSource() { return cpDataDataSource; } /** * 从连接池中获取连接 * @return */ public static Connection getConnection(){ try { return cpDataDataSource.getConnection(); } catch (SQLException e) { throw new RuntimeException(e); } } /** * 释放资源 */ public static void releaseResources(ResultSet resultSet, Statement statement, Connection connection) { try { if (resultSet != null) resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } finally { resultSet = null; try { if (statement != null) statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally { statement = null; try { if (connection != null) connection.close(); } catch (SQLException e) { e.printStackTrace(); } finally { connection = null; } } } } } DBCPUtils 和 C3P0Utils 与 JdbcUtils 的用法别无二致，区别只是释放资源时，Connection对象调用close()方法时，只是将Connection对象放回连接池中，实际上并不关闭连接。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编址与端口配置]]></title>
    <url>%2F2015%2F06%2F21%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E5%9D%80%E4%B8%8E%E7%AB%AF%E5%8F%A3%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[前段时间的考试题，实验环境Cisco Packet Tracer 6.2sv 一、网络拓扑如下： 2.各网段的地址基本需求如下： a.HQ 的 LAN1 网段需要 50 个主机 IP 地址。 b.HQ 的 LAN2 网段网需要 50 个主机 IP 地址。 c.BRANCH1 的 LAN1 网段需要 20 个主机 IP 地址。 d.BRANCH1 的 LAN2 网段需要 20 个主机 IP 地址 e.BRANCH2 的 LAN1 网段需要 12 个主机 IP 地址 f. BRANCH2 的 LAN2 网段需要 12 个主机 IP 地址。 g.连接HQ 与 BRANCH1 的WLAN网段需要2个 IP 地址。 h.连接HQ 与 BRANCH2 的WLAN网段需要2个 IP 地址。 3.编址方案： 本网络使用地址 192.168.10.0/24。 按每个网段的基本地址需求划分子网大小。 按地址从小到大的顺序为从a开始直至h的各网段顺序按需分配子网地址。 为主机接口分配所在子网的最大有效主机地址。 为连接局域网的路由器接口分配所在子网的最小有效主机地址。 为提供时钟信号的WAN接口分配所在子网的最小有效主机地址。 为接收时钟信号的WAN接口分配所在子网的最大有效主机地址。 二、配置任务 1.按拓扑图所示的命名为路由设备配置设备名 2.为主机接口配置IP地址、子网掩码和网关地址。 3.为路由器接口配置IP地址和子网掩码。 4.为连接路由器的提供时钟信号的WAN接口配置64000时钟频率。 5.为HQ路由设备配置可达所有子网的静态路由，采用邻居路由器接口IP地址为下一跳地址。 6.为BRANCH1和BRANCH2路由设备配置可达所有子网的默认路由，采用邻居路由器接口IP地址为下一跳地址。 7.测试各子网间的连通性 具体实现方法： 1.首先按照所给拓扑图连接好，下面是我连接的拓扑图： 各个端口连接情况如上图所示。这是我配置好以后才截的图，刚连接好在没有任何配置的情况下，路由器之间的线路上 不是绿点 ，而是 红点 。 2.下面开始给路由器以及主机的端口配置ip地址和子网掩码。首先要按照所给要求进行编址，至于如何编址就不再赘述，编址方案如下： HQ: LAN1：192.168.10.0~63/26 ip数：64LAN2：192.168.10.64~127/26 ip数： 64 BRANCH1： LAN1：192.168.10.128~159/27 ip数： 32LAN2：192.168.10.160~191/27 ip数： 32 BRANCH2： LAN1：192.168.10.192~207/28 ip数： 16LAN2：192.168.10.208~223/28 ip数：16 连接 HQ 与 BRANCH1 的 WLAN网段: 192.168.10.224~227/30 ip数：4 连接 HQ 与 BRANCH2 的 WLAN网段：192.168.10.228~231/30 ip数：4 ———————————————————————————————————————————— 具体ip分配如下： HQ:LAN1 :路由器fa 0/1: 192.168.10.1 子网掩码：255.255.255.192主机 192.168.10.62 子网掩码：255.255.255.192LAN2 :路由器fa 0/0: 192.168.10.65 子网掩码：255.255.255.192主机 192.168.10.126 子网掩码：255.255.255.192Se0/0/0 : 192.168.10.226 子网掩码：255.255.255.252Se0/0/1 : 192.168.10.230 子网掩码：255.255.255.252 BRANCH1LAN1: 路由器fa 0/0: 192.168.10.129 子网掩码：255.255.255.224主机 192.168.10.158 子网掩码：255.255.255.224LAN2: 路由器fa 0/1: 192.168.10.161 子网掩码：255.255.255.224主机 192.168.10.190 子网掩码：255.255.255.224Se0/0/0 : 192.168.10.225 子网掩码：255.255.255.252 BRANCH2LAN1: 路由器fa 0/1: 192.168.10.193 子网掩码：255.255.255.240主机 192.168.10.206 子网掩码：255.255.255.240LAN2:路由器fa 0/0: 192.168.10.209 子网掩码：255.255.255.240主机 192.168.10.222 子网掩码：255.255.255.240Se0/0/0: 192.168.10.229 子网掩码：255.255.255.252 定下编址方案后，就开始配置端口了。 一、配置路由器端口 1.打开路由器HQ的CLI命令行界面,输入 enable 回车进入特权模式，再输入 configure terminal 回车进入全局配置模式 2. 改名 ： Router(config)#hostname HQ 将路由器改名为HQ 3.输入 interface 端口名 进入端口配置。以HQ的fa 0/0端口为例，简化写法： HQ(config)# int f 0/0 ， int 是 interface 缩写 ，快速以太网口为 f ，串行端口为 s 4.按照上述编址方案配置端口的ip地址。以HQ的fa 0/0端口为例： HQ(config- if )#ip address 192.168.10.65 255.255.255.192 ,address可缩写为add 5.开启端口： HQ(conf- if )# no shutdown 6.配置完一个端口后输入 exit 退出端口配置，回到全局配置模式 7.依次配置每个路由器各个端口ip和子网掩码 注意： 配置串行端口DCE端（就是你用串行线连接两个路由设备时先点的那个设备）时要设置时钟频率为64000： HQ(config- if )#clock rate 64000 二、主机配置 主机配置很简单，在desktop-ip configuration中直接输入就可以了，默认网关是所连接的路由器的端口的ip 三、路由配置 1.为HQ路由设备配置可达所有子网的静态路由 全局配置模式下： HQ(config)#ip route 192.168.10.128 255.255.255.224 192.168.10.225 HQ(config)#ip route 192.168.10.160 255.255.255.224 192.168.10.225 HQ(config)#ip route 192.168.10.192 255.255.255.240 192.168.10.229 HQ(config)#ip route 192.168.10.208 255.255.255.240 192.168.10.229 命令的三个参数分别为目的网络 网络号 、目的网络 子网掩码 以及 下一跳 ，这样就将BRANCH1和BRANCHH2的四个子网的静态路由配置好了。 2.为BRANCH1和BRANCH2路由设备配置可达所有子网的默认路由 默认路由的目的网络ip以及子网掩码都设置为 0.0.0.0 ，下一跳均设置为与其唯一相连的路由器 HQ 的相应的端口ip BRANCH1(config)#ip route 0.0.0.0 0.0.0.0 192.168.10.226 BRANCH2(config)#ip route 0.0.0.0 0.0.0.0 192.168.10.230 这样就算配置完成了，可以用ping命令测试各个子网之间的连通性。 四、总结 总结一下一共需要的几个步骤： 1.连好拓扑结构图 2.根据要求设计出编址方案，为路由器和主机端口分配正确的ip以及掩码 3.为路由器和主机端口配置ip，子网掩码，默认网关，为串行接口DCE端设定时钟频率。 路由器：输入enable进入特权模式，再输入 configure terminal 进入全局配置模式： 输入 hostname 路由器名 更改路由器名 输入 interface 端口名 进入端口配置 用命令 ip address ip 地址 掩码 配置ip和掩码 串行接口设置：用命令 clock rate 64000 配置始终频率 （只在 DCE端 配置，即连 接路由器时先点的那个路由器的端口 ） 开启端口： no shutdown 命令 exit 回到全局配置模式 主机：在desktop-ip configuration中直接输入，默认网关是所连接的路由器的端口的ip 4.配置HQ的静态路由以及BRANCH1和BRANCH2的默认路由。 全局配置模式下，命令为： ip route 目的网络网络号 目的网络子网掩码 下一跳 ，默认路由将网络网络号和子网掩码都设置为 0.0.0.0 特权模式下输入 show ip route 可以查看路由表 5.ping命令测试网络连通性 注意：命令不需要记住，Tab键可自动补全，也可以省略简写，按个人习惯了。enable可写为ena，configure terminal可写为conf t，interface可写为int，快速以太网口可写为f，串行接口可写为s，address可写为add。 步骤大体就是这样，不足之处还望指正。 博客园博文地址： 网络编址与端口配置]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dom4j 使用总结]]></title>
    <url>%2F2015%2F06%2F06%2Fdom4j%20%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[dom4j 是一个Java的XML API，类似于jdom，用来读写XML文件 dom4j的使用方法简单总结来说如下： ①可以创建一个新的xml文件 ②利用SAXReader和File对象创建一个已存在的xml文件的一个Document对象 ③利用Document对象的getRootElement()方法获取根节点，返回值类型为Element ④利用根节点，可以用迭代器遍历子节点，也可以直接利用XPATH语法查找节点，对节点元素、属性读取或更改 ⑤将更改写入xml文件保存 下面来看简单的实例： ①创建一个新的xml文件，这是dom4j官方文档中的一个例子 import org.dom4j.Document; import org.dom4j.DocumentHelper; import org.dom4j.Element; public class Foo { public Document createDocument() { Document document = DocumentHelper.createDocument(); Element root = document.addElement( &quot;root&quot; ); Element author1 = root.addElement( &quot;author&quot; ) .addAttribute( &quot;name&quot;, &quot;James&quot; ) .addAttribute( &quot;location&quot;, &quot;UK&quot; ) .addText( &quot;James Strachan&quot; ); Element author2 = root.addElement( &quot;author&quot; ) .addAttribute( &quot;name&quot;, &quot;Bob&quot; ) .addAttribute( &quot;location&quot;, &quot;US&quot; ) .addText( &quot;Bob McWhirter&quot; ); return document; } } ②利用SAXReader和File对象或xml的URL创建一个已存在的xml文件的一个Document对象 这里是dom4j官方文档中利用xml文件URL创建Document对象的一个例子： import java.net.URL; import org.dom4j.Document; import org.dom4j.DocumentException; import org.dom4j.io.SAXReader; public class Foo { public Document parse(URL url) throws DocumentException { SAXReader reader = new SAXReader(); Document document = reader.read(url); return document; } } 下面是我写的用SAXReader和File创建Document对象的例子： import java.io.File; import java.io.IOException; import org.dom4j.Document; import org.dom4j.DocumentException; import org.dom4j.io.SAXReader; public class Foo { public Document parse() throws DocumentException ,IOException{ SAXReader reader = new SAXReader(); File file = new File(&quot;Student.xml&quot;); Document document = reader.read(file); return document; } } ③利用Document对象的getRootElement()方法获取根节点，返回值类型为Element Element rootElement = document.getRootElement(); ④用迭代器遍历子节点，也可以直接利用XPATH语法查找节点，对节点元素、属性读取或更改 利用迭代器遍历： public void bar(Document document) throws DocumentException { Element root = document.getRootElement(); //迭代root的子节点 for ( Iterator i = root.elementIterator(); i.hasNext(); ) { Element element = (Element) i.next(); // do something } // 迭代root的名为&quot;foo&quot;的子节点 for ( Iterator i = root.elementIterator( &quot;foo&quot; ); i.hasNext(); ) { Element foo = (Element) i.next(); // do something } // 迭代root的属性 for ( Iterator i = root.attributeIterator(); i.hasNext(); ) { Attribute attribute = (Attribute) i.next(); // do something } } 利用XPATH语法查找节点： public void bar(Document document) { List list = document.selectNodes( &quot;//foo/bar&quot; ); Node node = document.selectSingleNode( &quot;//foo/bar/author&quot; ); String name = node.valueOf( &quot;@name&quot; ); } public void findLinks(Document document) throws DocumentException { List list = document.selectNodes( &quot;//a/@href&quot; ); for (Iterator iter = list.iterator(); iter.hasNext(); ) { Attribute attribute = (Attribute) iter.next(); String url = attribute.getValue(); } } Element类中的 attribute(String name) 方法和 element(String name) 方法分别可以获取节点的属性对象和某一子节点对象 elements(String name) 方法可以返回名为name的子节点的列表List。 get(int index) 方法可以获取本节点下以index索引的节点 getName() 方法可以获取本节点的名字(name) attributeValue(String name) 方法以及 Attribute类中的 getValue() 方法 可以获取本节点name属性的值 getText() 方法可以返回本节点的文本内容 elementText(String name) 方法可以获取name子节点的文本内容 remove(Attribute attribute) 方法和 remove(Element element) 方法分别可以移除本节点的某属性和某子节点 ⑤将更改写入xml文件保存 官方文档中的例子： import org.dom4j.Document; import org.dom4j.io.OutputFormat; import org.dom4j.io.XMLWriter; public class Foo { public void write(Document document) throws IOException { // lets write to a file XMLWriter writer = new XMLWriter( new FileWriter( &quot;output.xml&quot; ) ); writer.write( document ); writer.close(); // Pretty print the document to System.out OutputFormat format = OutputFormat.createPrettyPrint(); writer = new XMLWriter( System.out, format ); writer.write( document ); // Compact format to System.out format = OutputFormat.createCompactFormat(); writer = new XMLWriter( System.out, format ); writer.write( document ); } } 博客园博文地址： dom4j 的使用]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>dom4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++实现简单计算器]]></title>
    <url>%2F2015%2F06%2F06%2Fc%2B%2B%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E8%AE%A1%E7%AE%97%E5%99%A8%2F</url>
    <content type="text"><![CDATA[帮一个同学写的，非计算机类专业，应付交差，也没什么功能，两个数的加减乘除运算，以及三角函数的运算。要求用到模板、运算符重载和异常处理。 一直以来都是用的java，没怎么用过c++，就当是复习了一下c++语法。 代码如下： #include&lt;iostream&gt; #include&lt;string&gt; #include&lt;cmath&gt; #include&lt;cstdlib&gt; using namespace std; //四则运算 template &lt;class T&gt; class ElementaryArithmetic{ private: T result; T operand1, operand2; char operators; public: //四则运算 void Calculate(); //加法运算 void add(T, T); //减法运算 void subtraction(T, T); //乘法运算 void multiplication(T, T); //除法运算 void divide(T, T); //输出运算符重载 template &lt;class E&gt; friend ostream &amp;operator&lt;&lt;(ostream&amp;, ElementaryArithmetic&lt;E&gt; &amp;); }; //四则运算 template &lt;class T&gt; void ElementaryArithmetic&lt;T&gt;::Calculate(){ int type; loop1: system(&quot;cls&quot;); cout &lt;&lt; endl &lt;&lt; &quot;*******************&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 1.加法运算 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 2.减法运算 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 3.乘法运算 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 4.除法运算 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;*******************&quot; &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; &quot;请输入菜单项(1-4)：&quot;; try{ cin &gt;&gt; type; if (type != 1 &amp;&amp; type != 2 &amp;&amp; type != 3 &amp;&amp; type != 4) throw 1; } catch (int e){ cout &lt;&lt; endl &lt;&lt; &quot;输入错误，请重新输入选项...&quot;; system(&quot;pause&quot;); goto loop1; } cout &lt;&lt; endl &lt;&lt; &quot;请输入两个数字：&quot;; cin &gt;&gt; operand1 &gt;&gt; operand2; if (type == 1){ add(operand1, operand2); operators = &apos;+&apos;; } else if (type == 2){ subtraction(operand1, operand2); operators = &apos;-&apos;; } else if (type == 3){ multiplication(operand1, operand2); operators = &apos;*&apos;; } else if (type == 4){ divide(operand1, operand2); operators = &apos;/&apos;; } } //加法运算 template &lt;class T&gt; void ElementaryArithmetic&lt;T&gt;::add(T operand1,T operand2){ result = operand1 + operand2; } //减法运算 template &lt;class T&gt; void ElementaryArithmetic&lt;T&gt;::subtraction(T operand1, T operand2){ result = operand1 - operand2; } //乘法运算 template &lt;class T&gt; void ElementaryArithmetic&lt;T&gt;::multiplication(T operand1, T operand2){ result = operand1 * operand2; } //除法运算 template &lt;class T&gt; void ElementaryArithmetic&lt;T&gt;::divide(T operand1, T operand2){ try{ //除数为0，出现异常 if ((operand2 - 0) &lt; 1e-8 &amp;&amp; (operand2 - 0) &gt; -1e-8) throw 0; } catch (int){ throw ; } result = operand1 / operand2; } //输出运算符重载 template &lt;class E&gt; ostream&amp; operator&lt;&lt;(ostream &amp;os, ElementaryArithmetic&lt;E&gt; &amp;result){ os &lt;&lt; endl &lt;&lt; &quot;计算结果 ： &quot; &lt;&lt; result.operand1 &lt;&lt; result.operators &lt;&lt; result.operand2 &lt;&lt; &apos;=&apos; &lt;&lt; result.result &lt;&lt; endl; return os; } //三角函数 class Trigonometric{ private: double radian; string type; double result; public: //三角函数计算 void Calculate(); //输出运算符重载 friend ostream &amp;operator&lt;&lt;(ostream&amp;, Trigonometric &amp;); }; //三角函数计算 void Trigonometric::Calculate(){ int option; loop2: system(&quot;cls&quot;); cout &lt;&lt; &quot;*******************&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 1.求正弦 *&quot;&lt;&lt; endl; cout &lt;&lt; &quot;* 2.求余弦 *&quot;&lt;&lt; endl; cout &lt;&lt; &quot;* 3.求正切 *&quot;&lt;&lt; endl; cout &lt;&lt; &quot;*******************&quot; &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; &quot;请输入菜单项(1-3)：&quot;; try{ cin &gt;&gt; option; if (option != 1 &amp;&amp; option != 2 &amp;&amp; option != 3 &amp;&amp; option != 4) throw 2; } catch (int e){ cout &lt;&lt; endl &lt;&lt; &quot;输入错误，请重新输入选项...&quot; ; system(&quot;pause&quot;); goto loop2; } cout &lt;&lt; endl &lt;&lt; &quot;请输入弧度：&quot;; cin &gt;&gt; radian; if (option == 1){ result = sin(radian); type = &quot;sin&quot;; } else if (option == 2){ result = cos(radian); type = &quot;cos&quot;; } else if (option == 3){ result = tan(radian); type = &quot;tan&quot;; } } //输出运算符重载 ostream &amp;operator&lt;&lt;(ostream &amp;os, Trigonometric &amp;result){ os &lt;&lt; endl &lt;&lt; &quot;计算结果 ： &quot; &lt;&lt; result.type &lt;&lt; &quot;(&quot; &lt;&lt; result.radian &lt;&lt; &quot;) = &quot; &lt;&lt; result.result &lt;&lt; endl; return os; } int main(){ int type; loop: while (true){ system(&quot;cls&quot;); cout &lt;&lt; &quot;*******主菜单**********&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 1. 四则运算 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 2. 三角函数 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* 3. 退出程序 *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;* *&quot; &lt;&lt; endl; cout &lt;&lt; &quot;***********************&quot; &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; &quot;请输入菜单项(1-3)：&quot;; try{ cin &gt;&gt; type; if (type != 1 &amp;&amp; type != 2 &amp;&amp; type != 3) throw - 1; if (type == 1){ ElementaryArithmetic&lt;double&gt; calc; calc.Calculate(); cout &lt;&lt; calc; } else if (type == 2){ Trigonometric calc; calc.Calculate(); cout &lt;&lt; calc; } else if (type == 3) break; } catch (int e){ if (e == -1){ cout &lt;&lt; endl &lt;&lt; &quot;输入错误，请重新输入选项...&quot;; system(&quot;pause&quot;); goto loop; } else if (e == 0) cout &lt;&lt; &quot;除数不能为 0 &quot; &lt;&lt; endl; } cout &lt;&lt; endl; system(&quot;pause&quot;); } return 0; } 好吧，其实我也不知道为什么要求用模板和运算符重载，感觉没什么必要，典型的作业代码，不过也可能是我思想的局限性。总之，就这样吧。]]></content>
      <categories>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql使用基础 sql语句与数据完整性(二)]]></title>
    <url>%2F2015%2F06%2F05%2Fmysql%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%20sql%E8%AF%AD%E5%8F%A5%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[二、 DML:Data Manipulation Language 数据操作语言 作用：操作表中的数据的。关键：INSERT UPDATE DELETE 注意：日期或字符串、字符要使用单引号引起来。 假设已经存在表user ： mysql&gt;CREATE TABLE uesr( id int, username varchar(200), gender varchar(10), birthday date, entry_date date, job varchar(200), salary float(8,2), resume text ); 查看表中的所有记录： mysql&gt;SELECT * FROM user; ① 插入中文时的问题：（编码问题） 查看数据库目前的各种编码： mysql&gt;SHOW VARIABLES LIKE &apos;character%&apos;; 通知服务器客户端使用的编码字符集： mysql&gt;SET character_set_client=gbk; 显示时乱码： mysql&gt;SET character_set_results=gbk; ②使用insert语句向表中插入记录 不省略字段名插入（建议）： mysql&gt;INSERT INTO user (id,username,gender,birthday,entry_date,job,salary,resume) VALUES (1,&apos;Tom&apos;,&apos;0&apos;,&apos;1991-09-07&apos;,&apos;2013-04-12&apos;,&apos;CTO&apos;,10000.00,&apos;beauty&apos;); 省略字段名插入（当插入values值顺序与表字段声明必须完全一致）： mysql&gt;INSERT INTO user VALUES (2,&apos;Jack&apos;,&apos;1&apos;,&apos;1987-09-07&apos;,&apos;2013-04-12&apos;,&apos;CEO&apos;,10000.00,&apos;hand&apos;); ③使用update语句更改表中记录 将所有员工薪水修改为5000元： mysql&gt;UPDATE user SET salary=5000; 将姓名为Tom的记录薪水改为3000： mysql&gt;UPDATE user SET salary=3000 WHERE username=&apos;Tom&apos;; 将姓名为Tom的员工薪水修改为4000,job改为CMO： mysql&gt;UPDATE user SET salary=4000,job=&apos;CMO&apos; WHERE username=&apos;Tom&apos;; 将Jack的薪水在原有基础上增加1000元： mysql&gt;UPDATE user SET salary=salary+1000 WHERE username=&apos;Jack&apos;; ④删除操作 删除表中名称为Tom的记录： mysql&gt;DELETE FROM user WHERE username=&apos;Tom&apos;; 删除表中所有记录(一条一条的删除)： mysql&gt;DELETE FROM user; 使用TRUNCATE删除表中记录(摧毁整张表，然后重建表结构)： mysql&gt;TRUNCATE user; 三、 数据完整性 数据完整性分为四类： 实体完整性 （Entity Integrity）、 域完整性 （Domain Integrity）、 参照完整性 （Referential Integrity）、 用户自定义完整性 （User-definedIntegrity）。 ①实体完整性： 规定表中的一行在表中是唯一的实体， 一般是通过定义主键的形式来实现的。实体完整性要求每一个表中的主键字段都不能为空或者重复的值。实体完整性指表中 行的完整性 。要求表中的所有行都有唯一的标识符，称为 主关键字 。主关键字是否可以修改，或整个列是否可以被删除，取决于主关键字与其他表之间要求的完整性。 关键字：PRIMARY KEY特点：不能为null，必须唯一 CREATE TABLE shanghai1( id int PRIMARY KEY, name varchar(100) ); //实际开发中不建议使用。 CREATE TABLE shanghai2( id int PRIMARY KEY auto_increment, name varchar(100) ); insert into shanghai2 (name) values(&apos;aa&apos;); ②域完整性 指数据库表的列（即字段）必须符合某种特定的数据类型或约束。域完整性是针对某一具体关系数据库的约束条件。它保证表中某些列不能输入无效的值。 NOT NULL：不能为空UNIQUE：必须唯一 CREATE TABLE shanghai3( id int PRIMARY KEY, name varchar(100) NOT NULL, idnum varchar(100) unique ); 关于主键（建议） ：逻辑主键：给编程人员用的。与具体业务无关业务主键：用户也可以用。与具体业务有关 ③参照完整性（多表设计） 当更新、删除、插入一个表中的数据时，通过参照引用相互关联的另一个表中的数据，来检查对表的数据操作是否正确，简单的说就是表间主键外键的关系。 一对多： create table department( id int primary key, name varchar(100) ); create table employee( id int primary key, name varchar(100), salary float(8,2), dept_id int, constraint dept_id_fk foreign key(dept_id) references department(id) ); 多对多： create table teacher( id int primary key, name varchar(100), salary float(8,2) ); create table student1( id int primary key, name varchar(100), grade varchar(10) ); create table teacher_student1( t_id int, s_id int, primary key(t_id,s_id), constraint t_id_fk foreign key(t_id) references teacher(id), constraint s_id_fk foreign key(s_id) references student1(id) ); 一对一： create table human( id int primary key, name varchar(100) ); create table idcard( id int primary key, num varchar(100), constraint huanm_id_fk foreign key(id) references human(id) ); 博客园博文地址： mysql使用基础 sql语句与数据完整性(二)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基础 事务的认识和使用]]></title>
    <url>%2F2015%2F06%2F04%2Fmysql%E5%9F%BA%E7%A1%80%20%E4%BA%8B%E5%8A%A1%E7%9A%84%E8%AE%A4%E8%AF%86%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[事务(Transaction) 是访问并可能更新数据库中各种数据项的一个 程序执行单元(unit) 。事务是恢复和并发控制的基本单位。 在关系数据库中，一个事务可以是 一条SQL语句 ， 一组SQL语句 或 整个程序 。 事务应该具有4个属性： 原子性 、 一致性 、 隔离性 、 持久性 。这四个属性通常称为 ACID 特性 ： 原子性 （atomicity）：一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。 一致性 （consistency）：事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性 （isolation）：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性 （durability）：持久性也称 永久性 （permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 如果不考虑事务的 隔离级别 ，会出现以下“不正确”的情况： 1. 脏读 ：指一个事务读到了另一个事务中未提交的数据。2. 不可重复读 ：针对一条记录的，同一条记录前后不一样3. 虚读（幻读） ：针对一张表，前后读到的记录条数不一样。 隔离级别的分类：READ UNCOMMITTED ： 脏读、不可重复读、虚读都有可能发生 。READ COMMITTED ：能避免脏读。 不可重复读、虚读都有可能发生 。REPEATABLE READ ：能避免脏读、不可重复度。 虚读有可能发生。SERIALIZABLE ：能避免脏读、不可重复度、虚读。 mysql中控制事务隔离级别的语句：select @@tx_isolation; //查看当前的事务隔离级别set transaction isolation level 你的级别（上述四种之一）; //设置隔离级别 mysql中默认级别为 REPEATABLE READ mysql事务控制语句： 默认情况下一条语句为一个事务，无需手动开启。事务控制语句如下 start transaction ：开启一次事务rollback ：回滚 commit ：提交事务 博客园博文地址： mysql基础 事务的认识和使用]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdbc基础 (四) 批处理]]></title>
    <url>%2F2015%2F06%2F04%2Fjdbc%E5%9F%BA%E7%A1%80%20(%E5%9B%9B)%20%E6%89%B9%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[批处理 ，就是字面上的意思，一次性处理一批sql语句。 直接看例子吧： package com.cream.ice.jdbc; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.Statement; import org.junit.Test; /** * * 假设已经存在表test： * create table test( * id int primary key, * name varchar(20) * ); * * @author ice * */ public class Batch { private Connection connection; private Statement statement; private PreparedStatement preStatement; private ResultSet resultSet; /** * 向ttest中插入2条记录，删除掉第1条 * 由于批处理的多条语句不同，所以使用Statement进行批处理 */ @Test public void testBatch1() { try { connection = JdbcUtils.getConnection(); statement = connection.createStatement(); String sql1 = &quot;insert into test (id,name) values(1,&apos;Tom&apos;)&quot;; String sql2 = &quot;insert into test (id,name) values(2,&apos;Jack&apos;)&quot;; String sql3 = &quot;delete from test where id=1&quot;; // 内部维护了一个List，将sql语句加到List中 statement.addBatch(sql1); statement.addBatch(sql2); statement.addBatch(sql3); // 执行批处理 int num[] = statement.executeBatch(); // i为每条语句影响到的行数 for (int i : num) System.out.print(i + &quot; &quot;); } catch (Exception e) { e.printStackTrace(); } finally { JdbcUtils.releaseResources(null, statement, connection); } } /** * 向test中插入100条记录 * 由于语句完全相同，只是参数不同，使用PreparedStatement */ @Test public void testBatch2() { try { connection = JdbcUtils.getConnection(); String sql = &quot;insert into test (id,name) values(?,?)&quot;; preStatement = connection.prepareStatement(sql); // 要插入100条记录 for (int i = 0; i &lt; 100; i++) { preStatement.setInt(1, i + 1); preStatement.setString(2, &quot;No.&quot; + (i + 1)); preStatement.addBatch(); } // 执行批处理语句 preStatement.executeBatch(); statement=connection.createStatement(); resultSet=statement.executeQuery(&quot;select * from test&quot;); //将插入记录打印到控制台上 while(resultSet.next()){ System.out.print(&quot;id:&quot;+resultSet.getInt(&quot;id&quot;)+&quot; &quot;); System.out.println(&quot;name:&quot;+resultSet.getString(&quot;name&quot;)); } } catch (Exception e) { e.printStackTrace(); } finally { JdbcUtils.releaseResources(null, preStatement, connection); JdbcUtils.releaseResources(resultSet, statement, connection); } } } 代码里使用了工具类 JdbcUtils ，可参阅 jdbc基础 (二) 通过properties配置文件连接数据库 中的实现。 第一个例子中由于批处理的多条 语句不同 ，所以使用 Statement 进行批处理。 第二个例子中由于 语句完全相同 ，只是参数不同，使用 PreparedStatement 来处理。 这里值得注意的是，在第二个例子中，如果批处理语句数量不是100，而是达到几十万或上百万条，则在mysql中是极为耗时的，需要若干小时才可处理完，但如果换成oracle数据库，只需几十秒便可完成。 博客园博文地址： jdbc基础 (四) 批处理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdbc基础 (三) 大文本、二进制数据处理]]></title>
    <url>%2F2015%2F05%2F28%2Fjdbc%E5%9F%BA%E7%A1%80%20(%E4%B8%89)%20%E5%A4%A7%E6%96%87%E6%9C%AC%E3%80%81%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[LOB (Large Objects) 分为： CLOB 和 BLOB ，即大文本和大二进制数据 CLOB： 用于存储大文本 BLOB： 用于存储二进制数据，例如图像、声音、二进制文件 在mysql中,只有 BLOB ,没有CLOB，mysql存储大文本用 TEXT TEXT 分为：TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT BLOB 分为：TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB 取值范围如下图： 下面来看具体的代码实现： package com.cream.ice.jdbc; import java.io.File; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.FileWriter; import java.io.Reader; import java.io.Writer; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; import org.junit.Test; /** * 大文本数据操作 * * 假设数据库中已存在表test: * create table test( * id int primary key, * content longtext * ); * * @author ice * */ public class ClobDemo { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet=null; @Test public void add(){ try { connection=JdbcUtils.getConnection(); statement=connection.prepareStatement(&quot;insert into test (id,content) values (?,?)&quot;); statement.setInt(1, 1); //大文本要使用流的形式。将d:/test.txt内容添加至该记录的content字段 File file = new File(&quot;d:/test.txt&quot;); Reader reader = new FileReader(file); //不能使用long的参数，因为mysql根本支持不到那么大的数据，所以没有实现 statement.setCharacterStream(2, reader, (int)file.length()); int i = statement.executeUpdate(); if(i&gt;0) System.out.println(&quot;插入成功&quot;); } catch (SQLException e) { e.printStackTrace(); } catch (FileNotFoundException e) { e.printStackTrace(); } finally{ JdbcUtils.releaseResources(null, statement, connection); } } @Test public void read(){ try { connection = JdbcUtils.getConnection(); statement = connection.prepareStatement(&quot;select * from test where id=?&quot;); statement.setInt(1, 1); //将读取内容保存到E盘上 resultSet = statement.executeQuery(); while(resultSet.next()){ Reader reader = resultSet.getCharacterStream(&quot;content&quot;); Writer writer = new FileWriter(&quot;e:/test.txt&quot;); char buffer[] = new char[1024]; int len = -1; while((len=reader.read(buffer))!=-1){ writer.write(buffer, 0, len); } reader.close(); writer.close(); } } catch (Exception e) { e.printStackTrace(); } finally{ JdbcUtils.releaseResources(resultSet, statement, connection); } } } package com.cream.ice.jdbc; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.InputStream; import java.io.OutputStream; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import org.junit.Test; /** * 大二进制数据操作 * * 假设数据库中已存在表test: * create table test( * id int primary key, * content longblob * ); * * @author ice * */ public class BlobDemo { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet=null; @Test public void add(){ try { connection=JdbcUtils.getConnection(); statement=connection.prepareStatement(&quot;insert into test (id,content) values (?,?)&quot;); statement.setInt(1, 1); InputStream in = new FileInputStream(&quot;d:/test.jpg&quot;); statement.setBinaryStream(2, in, in.available()); int i = statement.executeUpdate(); if(i&gt;0) System.out.println(&quot;插入成功&quot;); } catch (Exception e) { e.printStackTrace(); } finally{ JdbcUtils.releaseResources(null, statement, connection); } } @Test public void read(){ try { connection = JdbcUtils.getConnection(); statement = connection.prepareStatement(&quot;select * from test where id=?&quot;); statement.setInt(1, 1); //保存到E盘上 resultSet = statement.executeQuery(); while(resultSet.next()){ InputStream in = resultSet.getBinaryStream(&quot;content&quot;); OutputStream out = new FileOutputStream(&quot;e:/test.jpg&quot;); byte b[] = new byte[1024]; int len = -1; while((len=in.read(b))!=-1){ out.write(b, 0, len); } out.close(); in.close(); } } catch (Exception e) { e.printStackTrace(); } finally{ JdbcUtils.releaseResources(resultSet, statement, connection); } } } 这里使用了我上一篇jdbc基础中的 JdbcUtils 工具类，同时也使用了单元测试来测试两个成员方法，代码已亲测可运行。 鄙人博客园原博地址： jdbc基础 (三) 大文本、二进制数据处理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql使用基础 sql语句(一)]]></title>
    <url>%2F2015%2F05%2F24%2Fmysql%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%20sql%E8%AF%AD%E5%8F%A5(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[命令行输入mysql -u root -p，回车再输入密码，进入mysql。 终端命令以分号作为一条语句的结束，可分为多行输入，只需在最后加上分号即可。如下图： 一、 DDL：数据定义语言 Data Definition Language 作用：定义数据库或者表结构的。 操作的对象：数据库或表的结构的。 关键字：CREATE ALTER DROP ①查询数据库： 显示目前有几个库,输入： mysql&gt;SHOW DATABASES; ②创建数据库： 创建一个名称为mydb1的数据库： mysql &gt; CREATE DATABASE mydb1; 查看数据库的创建细节 ： mysql &gt; SHOW CREATE DATABASE mydb1; 创建一个使用gbk字符集的mydb2数据库： mysql &gt; CREATE DATABASE mydb2 CHARACTER SET gbk; 创建一个使用gbk字符集，并带校对规则的mydb3数据库： mysql &gt; CREATE DATABASE mydb3 CHARACTER SET gbk COLLATE gbk_chinese_ci; ③删除数据库： 删除前面创建的mydb3数据库： mysql &gt; DROP DATABASE mydb3; 对某一数据库的操作，假设数据库为test： 首先要选择数据库： mysql &gt; USE test; ①显示表的信息： 显示当前数据库中的所有表格： mysql&gt;SHOW TABLES; 查看表结构的定义： mysql&gt;DESC employee; 查看表的创建细节： mysql &gt; SHOW CREATE TABLE user ; ②创建表： 创建一个员工表： mysql&gt;CREATE TABLE employee( id int, name varchar( **200** ), gender varchar( **10** ), birthday date, entry_date date, job varchar( **200** ), salary float( **8** , **2** ), resume text ); ③修改表： 在上面员工表的基本上增加一个image列： mysql &gt; ALTER TABLE employee ADD image blob; 查看表结构的定义： mysql &gt; DESC employee; 修改job列，使其长度为60： mysql &gt; ALTER TABLE employee MODIFY job varchar ( 60 ); 删除image列： mysql &gt; ALTER TABLE employee DROP image ; 表名改为user： mysql &gt; RENAME TABLE employee TO user ; 修改表的字符集为gbk： mysql &gt; ALTER TABLE user CHARACTER SET gbk; 列名name修改为username： mysql &gt; ALTER TABLE user CHANGE name username varchar ( 100 ); ④删除表： 删除表employee： DROP TABLE employee; 鄙人博客园原博地址： mysql使用基础 sql语句(一)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下安装openssh-server]]></title>
    <url>%2F2015%2F05%2F24%2Flinux%E4%B8%8B%E5%AE%89%E8%A3%85openssh-server%2F</url>
    <content type="text"><![CDATA[系统是ubuntu14.04，系统默认安装了openssh-client，但没有安装openssh-server，需要手动安装 终端输入： sudo apt-get install openssh-server 下载openssh-server 但出现下列提示： 正在读取软件包列表... 完成 正在分析软件包的依赖关系树 正在读取状态信息... 完成 有一些软件包无法被安装。如果您用的是 unstable 发行版，这也许是 因为系统无法达到您要求的状态造成的。该版本中可能会有一些您需要的软件 包尚未被创建或是它们已被从新到(Incoming)目录移出。 下列信息可能会对解决问题有所帮助： 下列软件包有未满足的依赖关系： openssh-server : 依赖: openssh-client (= 1:6.6p1-2ubuntu1) 原因是openssh-client与openssh-server所依赖的版本不同，解决方法是下载对应版本的openssh-client后再下载openssh-server。 终端输入： sudo apt-get install openssh-client=1:6.6p1-2ubuntu1 下载openssh-client。 openssh-client 下载完成后再输入 openssh-server 下载命令即可。 下载完成后可在输入 ps -e | grep ssh 来查看是否安装成功。如果出现下图这项，则说明已经启动。 如果没有启动，则在终端输入 sudo /etc/init.d/ssh start 启动服务。 鄙人博客园原博地址： linux下安装openssh-server]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdbc基础 (二) 通过properties配置文件连接数据库]]></title>
    <url>%2F2015%2F05%2F13%2Fjdbc%E5%9F%BA%E7%A1%80%20(%E4%BA%8C)%20%E9%80%9A%E8%BF%87properties%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[上一篇描述了对mysql数据库的简单操作，下面来看一下开发中应该如何灵活应用。 因为jdbc对数据库的驱动加载、连接获取、释放资源的代码都是相同的，为了提高代码的复用性，我们可以写一个工具类，将数据库驱动加载、获取连接、资源释放的代码封装起来。同时，为了提高工具类的灵活性，可以将数据库的驱动、url、用户名、密码等信息以键值对的形式存放在properties文件中，工具类初始化时从配置文件中读取所要连接数据库的信息。当需要更改连接的数据库时，只需要更改配置文件即可，而不必改写工具类的代码。 下面是工具类代码的实现： package com.cream.ice.jdbc; import java.io.IOException; import java.io.InputStream; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.util.Properties; public class JdbcUtils { private static String driverName; private static String url; private static String user; private static String password; /* * 静态代码块，类初始化时加载数据库驱动 */ static { try { // 加载dbinfo.properties配置文件 InputStream in = JdbcUtils.class.getClassLoader() .getResourceAsStream(&quot;dbinfo.properties&quot;); Properties properties = new Properties(); properties.load(in); // 获取驱动名称、url、用户名以及密码 driverName = properties.getProperty(&quot;driverName&quot;); url = properties.getProperty(&quot;url&quot;); user = properties.getProperty(&quot;user&quot;); password = properties.getProperty(&quot;password&quot;); // 加载驱动 Class.forName(driverName); } catch (IOException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } } /* * 获取连接 */ public static Connection getConnection() throws SQLException { return DriverManager.getConnection(url, user, password); } /* * 释放资源 */ public static void releaseResources(ResultSet resultSet, Statement statement, Connection connection) { try { if (resultSet != null) resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } finally { resultSet = null; try { if (statement != null) statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally { statement = null; try { if (connection != null) connection.close(); } catch (SQLException e) { e.printStackTrace(); } finally { connection = null; } } } } } 这里dbinfo.properties文件中信息如下，读者可自行更改： driverName=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/jdbc user=root password=01050233 这里我们来举个例子使用工具类。我们写一个类JdbcCURD实现对特定数据库的增删改查操作，并在main函数中使用。 JdbcCURD.java代码如下： package com.cream.ice.jdbc; import java.sql.Connection; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class JdbcCURD { private Connection connection; private Statement statement; private ResultSet resultSet; //更新操作 public void update(String sql) { try { connection = JdbcUtils.getConnection(); statement = connection.createStatement(); //可执行创建、修改、删除表，添加、删除、修改元组以及查询sql语句 statement.execute(sql); } catch (SQLException e) { e.printStackTrace(); } finally { JdbcUtils.releaseResources(resultSet, statement, connection); } } //查询操作 public void Query(String sql) { try { connection = JdbcUtils.getConnection(); statement = connection.createStatement(); resultSet = statement.executeQuery(sql); while(resultSet.next()){ System.out.println(&quot;name:&quot;+resultSet.getString(&quot;name&quot;)); System.out.println(&quot;id:&quot;+resultSet.getString(&quot;Tid&quot;)); } } catch (SQLException e) { e.printStackTrace(); } finally { JdbcUtils.releaseResources(resultSet, statement, connection); } } //添加操作 public void addElement(String sql) { update(sql); } //删除操作 public void removeElement(String sql) { update(sql); } //创建一个表 public void createTable(String sql){ update(sql); } //删除一个表 public void dropTable(String sql){ update(sql); } } 我们来写一个main函数来测试： package com.cream.ice.jdbc; import java.sql.SQLException; public class JdbcTest { public static void main(String[] args) throws ClassNotFoundException, SQLException { JdbcCURD curd=new JdbcCURD(); String sql = null; //添加表Teacher sql=&quot;create table Teacher (Tid char(9) primary key,name char(9) unique)&quot;; curd.createTable(sql); //添加元组 sql = &quot;insert into Teacher (Tid,name) values (&apos;0001&apos;,&apos;Tom&apos;)&quot;; curd.addElement(sql); //查询Teacher表 sql=&quot;select * from Teacher&quot;; curd.Query(sql); //删除元组 sql=&quot;delete from Teacher where Tid=&apos;0001&apos;&quot;; curd.removeElement(sql); //删除表Teacher sql=&quot;drop table Teacher&quot;; curd.dropTable(sql); } } 经测试，将在控制台输出下列信息： name:Tom id:0001 与上一篇中对数据库的操作相比，从配置文件中读取要连接数据库的信息，大大提高了代码的复用性以及灵活性，省去了当更改数据库时还要更改代码的麻烦。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdbc基础 (一) MySQL的简单使用]]></title>
    <url>%2F2015%2F05%2F12%2Fjdbc%E5%9F%BA%E7%A1%80%20(%E4%B8%80)%20MySQL%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前段时间学习了jdbc,正好利用这几篇文章总结一下。 JDBC 可做三件事：与数据库建立连接、发送操作数据库的语句并处理结果。 而程序首先要做的就是加载数据库驱动,这里我使用的是mysql： String driverName=new String(&quot;com.mysql.jdbc.Driver&quot;); Class.forName(driverName); 然后再获取数据库连接对象，参数为数据库的url，用户名以及密码。这里我使用的数据库名为jdbc，用户名为root，密码为123456： String url=new String(&quot;jdbc:mysql://localhost:3306/jdbc&quot;); String user=new String(&quot;root&quot;); String password=new String(&quot;123456&quot;); Connection coon=DriverManager.getConnection(url, user, password); 因为要对数据库进行操作，所以要获取Statement对象： Statement statement = connection.createStatement(); statement对象内封装的execute(String sql)方法以及executeQuery(String sql)方法和executeUpdate(String sql)方法可以用来执行sql语句，以此来实现对数据库的操作。 String sql = null; ResultSet resultSe = nullt; //创建Student表 sql=&quot;create table Student (id char(9) primary key,name char(9) unique)&quot;; statement.execute(sql); //添加元组 sql = &quot;insert into Student (id,name) values (&apos;0001&apos;,&apos;zhangsan&apos;)&quot;; statement.executeUpdate(sql); //查询Student表 sql=&quot;select * from Student&quot;; resultSet = statement.executeQuery(sql); while(resultSet.next()){ System.out.println(&quot;name:&quot;+resultSet.getString(&quot;name&quot;)); System.out.println(&quot;id:&quot;+resultSet.getString(&quot;id&quot;)); } //删除元组 sql=&quot;delete from Student where id=&apos;0001&apos;&quot;; statement.executeUpdate(sql); //删除表Student sql=&quot;drop table Teacher&quot;; statement.execute(sql); 操作完数据库之后要关闭资源，顺序依次为resultSet,statement,connection: try { if (resultSet != null) resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } finally { resultSet = null; try { if (statement != null) statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally { statement = null; try { if (connection != null) connection.close(); } catch (SQLException e) { e.printStackTrace(); } finally { connection = null; } } } close()方法会抛出异常，需要try/catch语句块。为保证资源的释放，需要将close()方法的调用放在finally语句块里，释放资源前判断对象是否为null。至此，利用jdbc连接数据库进行简单的操作算是完成了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jdbc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows API 开发飞机订票系统（三）]]></title>
    <url>%2F2014%2F11%2F30%2Fwindows%20API%20%E5%BC%80%E5%8F%91%E9%A3%9E%E6%9C%BA%E8%AE%A2%E7%A5%A8%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[嘿嘿，今天继续来完成哥哥我的飞机订票系统。 废话不多说，先把主界面对话框窗口过程贴出来： //主界面_窗口过程 BOOL CALLBACK MainDlgProc(HWND hMainDlg, UINT uMsg, WPARAM wParam, LPARAM lParam){ switch (uMsg) { case WM_INITDIALOG: { if (hIcon) SendMessage(hMainDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); }//WM_INITDIALOG return TRUE; case WM_CLOSE: { //关闭程序时将信息保存 if (WriteOrderData(hMainDlg) &amp;&amp; WriteAccountData(hMainDlg) &amp;&amp; WriteFlightData(hMainDlg)) EndDialog(hMainDlg, 0); else MessageBox(hMainDlg, TEXT(&quot;保存信息错误！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDC_SEARCH: { SearchFlight(hMainDlg); //查找航班 break; } case IDC_TICKET: { BookTickets(hMainDlg); //订票 break; } case IDC_RETURNTICKET: { ReturnTickets(hMainDlg); //退票 break; } case IDC_ENTRY: { //录入航班对话框 DialogBox(hInst, MAKEINTRESOURCE(IDD_ENTRY), NULL, (DLGPROC)EntryFlightProc); break; } case IDC_MODIFYFLIGHT: { //修改航班信息对话框 DialogBox(hInst, MAKEINTRESOURCE(IDD_MODIFYFLT), NULL, (DLGPROC)ModifyFlightProc); break; } }//switch }//WM_COMMAND return TRUE; }//switch return FALSE; }//MainDlgProc() 如上述代码所示，点击查找、订票、退票、航班录入、修改航班信息按钮都会调用相应的函数。下面来看实现各个功能的代码： //查找航班 BOOL SearchFlight(HWND hMainDlg){ int flag1 = 0; //if(flag1==0) 出发地、目的地查询航班，else：航班号查航班 int flag2 = 0; Flight *p; TCHAR szBuffer[256] = {TEXT(&quot;\0&quot;)}; TCHAR szDeparture[16], szDestination[16], szFltNum[16], szDate[16]; HWND hEdit = GetDlgItem(hMainDlg, IDC_INFORMATION); GetDlgItemText(hMainDlg, IDC_DEPARTURE, szDeparture, 15); //获取用户输入出发地 GetDlgItemText(hMainDlg, IDC_DESTINATION, szDestination, 15); //获取用户输入目的地 GetDlgItemText(hMainDlg, IDC_FLIGHTNUM, szFltNum, 15); //获取用户输入航班号 GetDlgItemText(hMainDlg, IDC_DATE, szDate, 15); //获取用户选择航班时间 SetDlgItemText(hMainDlg, IDC_INFORMATION, szBuffer); //清空航班信息区域文本 if (lstrlen(szFltNum) || (!(lstrlen(szDeparture)) &amp;&amp; !(lstrlen(szDestination)))) flag1++; else if (!(lstrlen(szDeparture))){ MessageBox(hMainDlg, TEXT(&quot;请输入出发地！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } else if (!(lstrlen(szDestination))){ MessageBox(hMainDlg, TEXT(&quot;请输入目的地！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } if (flag1 &amp;&amp; !(lstrlen(szFltNum))){ MessageBox(hMainDlg, TEXT(&quot;请输入出发地、目的地或航班号以查询航班！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } p = flightlink.head; while (p){ //查找航班并输出 if (flag1){ //按航班号查找 if (!lstrcmp(p-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(p-&gt;Date,szDate)){//查找到符合航班，输出 if (!flag2){ //若该航班为第一班符合条件的航班 _stprintf(szBuffer, TEXT(&quot;航班号\t出发地\t目的地\t起飞时间\t降落时间\t余座\t价格\t折扣\t出发日期\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); }//if flag2++; PrintFlight(hMainDlg, p); //输出航班信息 }//if }//if else{ //按出发地、目的地查找 if (!lstrcmp(p-&gt;Departure, szDeparture) &amp;&amp; !lstrcmp(p-&gt;Destination, szDestination) &amp;&amp; !lstrcmp(p-&gt;Date, szDate)){//查找到符合航班，输出 if (!flag2){ //若该航班为第一班符合条件的航班 _stprintf(szBuffer, TEXT(&quot;航班号\t出发地\t目的地\t起飞时间\t降落时间\t余座\t价格\t折扣\t出发日期\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); }//if flag2++; PrintFlight(hMainDlg, p); //输出航班信息 }//if }//else p = p-&gt;Next; }//while if (!flag2) MessageBox(hMainDlg, TEXT(&quot;对不起，没有符合您要求的航班&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; }//SearchFlight() //将所查航班信息输出 BOOL PrintFlight(HWND hwndDlg,Flight *p){ TCHAR szBuffer[256]; HWND hEdit = GetDlgItem(hwndDlg, IDC_INFORMATION); _stprintf(szBuffer, TEXT(&quot;\n%s\t%s\t%s\t%s\t%s\t%d\t%.2lf\t%s\t%s\n\n&quot;), p-&gt;Flight_Number, //航班号 p-&gt;Departure, //出发地 p-&gt;Destination, //目的地 p-&gt;TakeOff_Time, //起飞时间 p-&gt;Landing_Time, //降落时间 p-&gt;Vacant_Seat, //余座 p-&gt;Fare, //价格 p-&gt;Discount, //折扣 p-&gt;Date); //出发日期 SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); return TRUE; } //订票 BOOL BookTickets(HWND hMainDlg){ int tickets_num; Flight *p; TCHAR szFltNum[16], szDate[16]; GetDlgItemText(hMainDlg, IDC_FLIGHTNUM, szFltNum, 15); //获取用户输入航班号 GetDlgItemText(hMainDlg, IDC_DATE, szDate, 15); //获取用户选择航班时间 if (!lstrlen(szFltNum)){ MessageBox(hMainDlg, TEXT(&quot;请输入航班号以订票！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } DialogBox(hInst, MAKEINTRESOURCE(IDD_FLTNUM), NULL, (DLGPROC)FlightNumDlgProc); //获取订票数目 if (!lstrlen(szBuffer)) return FALSE; tickets_num = _ttoi(szBuffer); //订票数目 p = flightlink.head; while (p){ //查找航班并订票 if (!lstrcmp(p-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(p-&gt;Date, szDate)) //查找到符合航班 _Book_Tickets(hMainDlg,p,tickets_num); p = p-&gt;Next; }//while return TRUE; }//BookTickets() //订票 BOOL _Book_Tickets(HWND hwndDlg,Flight *p,int Tickets_Num){ OrderForm *new_order = (OrderForm *)malloc(sizeof(OrderForm)); if (!new_order){ MessageBox(hwndDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } if (Tickets_Num &gt; p-&gt;Vacant_Seat){ //余票不足，给出建议航班 Recommend(hwndDlg,p,Tickets_Num); return FALSE; } new_order-&gt;Order_Number = ++allorder.AllOrderNum; //新订单信息，总订单数+1 new_order-&gt;Tickets_Num = Tickets_Num; lstrcpy(new_order-&gt;IdNum, passenger-&gt;IdNum); lstrcpy(new_order-&gt;Flight_Number, p-&gt;Flight_Number); lstrcpy(new_order-&gt;Departure, p-&gt;Departure); lstrcpy(new_order-&gt;Destination, p-&gt;Destination); lstrcpy(new_order-&gt;Date, p-&gt;Date); lstrcpy(new_order-&gt;TakeOff_Time, p-&gt;TakeOff_Time); lstrcpy(new_order-&gt;Landing_Time, p-&gt;Landing_Time); new_order-&gt;Next = NULL; new_order-&gt;psgNext = NULL; if (allorder.head == NULL) //将结点添至订单链表末尾 allorder.head = new_order; else allorder.tail-&gt;Next = new_order; allorder.tail = new_order; if (passenger-&gt;OrderLink.head == NULL) //将结点添至用户订单链表末尾 passenger-&gt;OrderLink.head = new_order; else passenger-&gt;OrderLink.tail-&gt;psgNext = new_order; passenger-&gt;OrderLink.tail = new_order; passenger-&gt;OrderLink.OrderNum++; passenger-&gt;TicketNum += Tickets_Num; p-&gt;Vacant_Seat -= Tickets_Num; //航班余票-1 MessageBox(hwndDlg, TEXT(&quot;订票成功！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; }//_Book_Tickets() //给出建议航班 BOOL Recommend(HWND hwndDlg, Flight *p,int Tickets_Num){ SetDlgItemText(hwndDlg, IDC_INFORMATION, TEXT(&quot;\0&quot;)); //清空航班信息栏 int flag = 0; TCHAR szBuffer[256] = {TEXT(&quot;\0&quot;)}; HWND hEdit = GetDlgItem(hwndDlg, IDC_INFORMATION); Flight *q; q = flightlink.head; while (q){ if (!(lstrcmp(p-&gt;Departure, q-&gt;Departure)) &amp;&amp; !(lstrcmp(p-&gt;Destination, q-&gt;Destination)) &amp;&amp; lstrcmp(p-&gt;Flight_Number, q-&gt;Flight_Number) &amp;&amp; Tickets_Num&lt;=q-&gt;Vacant_Seat) { if (!flag){ wsprintf(szBuffer, TEXT(&quot;您所订航班余票不足，以下为建议航班:\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); wsprintf(szBuffer, TEXT(&quot;\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); wsprintf(szBuffer, TEXT(&quot;航班号\t出发地\t目的地\t起飞时间\t降落时间\t余座\t价格\t折扣\t出发日期\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); ++flag; }//if PrintFlight(hwndDlg, q); }//if q = q-&gt;Next; }//while if (!flag){ wsprintf(szBuffer, TEXT(&quot;对不起，您所订航班余票不足，当天也其它没有符合条件的航班...\n&quot;)); SendMessage(hEdit, EM_SETSEL, LOWORD(-1), HIWORD(-1)); SendMessage(hEdit, EM_REPLACESEL, 0, (LPARAM)(szBuffer)); } return TRUE; }//Recommend() //退票 BOOL ReturnTickets(HWND hwndDlg){ int flag = 0; int num=0,tickets_num; Flight *flight; OrderForm *p,*q,*s,*prePoint; TCHAR szFltNum[16], szDate[16]; GetDlgItemText(hwndDlg, IDC_FLIGHTNUM, szFltNum, 15); //获取用户输入航班号 GetDlgItemText(hwndDlg, IDC_DATE, szDate, 15); //获取用户选择航班时间 if (!lstrlen(szFltNum)){ //未输入航班号 MessageBox(hwndDlg, TEXT(&quot;请输入航班号！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } DialogBox(hInst, MAKEINTRESOURCE(IDD_FLTNUM), NULL, (DLGPROC)FlightNumDlgProc); //获取退票数目 if (!lstrlen(szBuffer)) return FALSE; tickets_num = _ttoi(szBuffer); //退票数 p = passenger-&gt;OrderLink.head; prePoint = p; if (!p){ //用户无订单 MessageBox(hwndDlg, TEXT(&quot;当前用户没有已订票&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } while (p){ //退票航班订票总数 if (!lstrcmp(p-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(p-&gt;Date, szDate)) num += p-&gt;Tickets_Num; p = p-&gt;psgNext; } if (tickets_num &gt; num){ //退票数大于该航班已订票数 wsprintf(szBuffer, TEXT(&quot;对不起，该航班您只订了%d张机票，请重新填写退票张数&quot;), num); MessageBox(hwndDlg, szBuffer, TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; }//if p = passenger-&gt;OrderLink.head; while (p){ //退票 if (!lstrcmp(p-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(p-&gt;Date, szDate) ){ if (tickets_num &gt;= p-&gt;Tickets_Num){ //当退票数大于等于当前订单内票数 s = p-&gt;psgNext; passenger-&gt;TicketNum -= p-&gt;Tickets_Num; //用户订票数减少 allorder.AllOrderNum--; //总订单数减少 passenger-&gt;OrderLink.OrderNum--; //用户订单数减少 tickets_num -= p-&gt;Tickets_Num; //需要退票数减少 若需要退票数为0，则退出，否则继续循环 if (passenger-&gt;OrderLink.head == p){ //若p为头结点，删除头结点 passenger-&gt;OrderLink.head = p-&gt;psgNext; //头指针指向下一个结点 if (!p-&gt;psgNext) //若p同时为尾结点，则尾指针指向NULL passenger-&gt;OrderLink.tail = NULL; } else if (!p-&gt;psgNext) //若p非头结点但为尾结点，尾指针指向前一个结点 passenger-&gt;OrderLink.tail = prePoint; prePoint-&gt;psgNext = p-&gt;psgNext; //链表删除结点p flight = flightlink.head; while (flight){ //航班余座增加 if (!lstrcmp(flight-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(flight-&gt;Date, szDate)){ flight-&gt;Vacant_Seat += p-&gt;Tickets_Num; break; } flight = flight-&gt;Next; }//while q = allorder.head; prePoint = q; while (q){ //删除订单链表中订单结点 if (q == p){ //找到订单结点 if (allorder.head == p){ //若p为头结点，删除头结点 allorder.head = p-&gt;Next; //头指针指向下一个结点 if (!q-&gt;Next) //若q同时为尾结点，则尾指针指向NULL allorder.tail = NULL; } else if (!q-&gt;Next) //若q非头结点但为尾结点，尾指针指向前一个结点 allorder.tail = prePoint; prePoint-&gt;Next = q-&gt;Next; //链表删除结点q free(p); break; //释放p结点内存 }//if prePoint = q; q = q-&gt;Next; }//while if (tickets_num){ //若退票数非0，则继续退票 p = s; continue; } MessageBox(hwndDlg, TEXT(&quot;退票成功！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; }//if else{ //退票数小于该订单订票数 p-&gt;Tickets_Num -= tickets_num; //订单订票数减少 passenger-&gt;TicketNum -= tickets_num; //用户订票数减少 flight = flightlink.head; while (flight){ if (!lstrcmp(flight-&gt;Flight_Number, szFltNum) &amp;&amp; !lstrcmp(flight-&gt;Date, szDate)){ flight-&gt;Vacant_Seat += tickets_num; //航班余票增加 break; } flight = flight-&gt;Next; }//while MessageBox(hwndDlg, TEXT(&quot;退票成功！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; //退票成功 }//else }//if prePoint = p; p = p-&gt;psgNext; }//while wsprintf(szBuffer, TEXT(&quot;对不起，您没有订该航班机票，请确认退票航班&quot;)); MessageBox(hwndDlg, szBuffer, TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; }//ReturnTickets() 点击订票或退票按钮时，会弹出一个对话框来让用户输入订票或退票数目，对话框窗口过程如下： //获取用户输入机票数量_窗口过程 BOOL CALLBACK FlightNumDlgProc(HWND hwndDlg, UINT uMsg, WPARAM wParam, LPARAM lParam){ switch (uMsg) { case WM_INITDIALOG: { if (hIcon) SendMessage(hwndDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); }//WM_INITDIALOG return TRUE; case WM_CLOSE: { wsprintf(szBuffer, TEXT(&quot;\0&quot;)); EndDialog(hwndDlg, FALSE); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDOK: wsprintf(szBuffer, TEXT(&quot;\0&quot;)); GetDlgItemText(hwndDlg, IDC_TICKETNUM, szBuffer, 256); EndDialog(hwndDlg, TRUE); break; }//switch }//WM_COMMAND return TRUE; }//switch return FALSE; } 接下来是航班录入和修改航班信息功能的实现，分别对应一个对话框，窗口过程分别如下: //录入航班_窗口过程 BOOL CALLBACK EntryFlightProc(HWND hEntryDlg, UINT uMsg, WPARAM wParam, LPARAM lParam){ switch (uMsg) { case WM_INITDIALOG: { if (hIcon) SendMessage(hEntryDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); } return TRUE; case WM_CLOSE: { EndDialog(hEntryDlg, 0); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDC_ADDFLT: { EntryFlight(hEntryDlg); //录入航班 break; }//GETNAME case IDC_QUIT: { EndDialog(hEntryDlg, FALSE); break; }//GETNAMECANCEL }//stitch }//WM_COMMAND return TRUE; }//stitch return FALSE; } //修改航班信息_窗口过程 BOOL CALLBACK ModifyFlightProc(HWND hModifyDlg, UINT uMsg, WPARAM wParam, LPARAM lParam){ switch (uMsg) { case WM_INITDIALOG: { if (hIcon) SendMessage(hModifyDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); } return TRUE; case WM_CLOSE: { EndDialog(hModifyDlg, 0); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDC_MODIFY: { ModifyFlight(hModifyDlg); //修改航班信息 break; }//GETNAME case IDC_QUIT: { EndDialog(hModifyDlg, FALSE); break; }//GETNAMECANCEL }//stitch }//WM_COMMAND return TRUE; }//stitch return FALSE; }//ModifyFlightProc() 具体功能实现代码： //录入航班 BOOL EntryFlight(HWND hEntryDlg){ TCHAR szDiscount[16]; TCHAR szFare[16],szSeat_Number[16]; TCHAR szFlight_Number[16], szDate[16]; TCHAR szDeparture[16], szDestination[16]; TCHAR szTakeOff_Time[16], szLanding_Time[16]; Flight *p = (Flight *)malloc(sizeof(Flight)),*q; if (!p){ MessageBox(hEntryDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } GetDlgItemText(hEntryDlg, IDC_DEPARTURE, szDeparture, 16); //获取录入航班信息 GetDlgItemText(hEntryDlg, IDC_DESTINATION, szDestination, 16); GetDlgItemText(hEntryDlg, IDC_FLTNUM, szFlight_Number, 16); GetDlgItemText(hEntryDlg, IDC_FARE, szFare, 16); GetDlgItemText(hEntryDlg, IDC_TAKEOFFTIME, szTakeOff_Time, 16); GetDlgItemText(hEntryDlg, IDC_LANDINGTIME, szLanding_Time, 16); GetDlgItemText(hEntryDlg, IDC_SEATNUM, szSeat_Number, 16); GetDlgItemText(hEntryDlg, IDC_DISCOUNT, szDiscount, 16); GetDlgItemText(hEntryDlg, IDC_DATE, szDate, 16); if (!lstrlen(szDeparture) || !lstrlen(szDestination) || !lstrlen(szFlight_Number) || !lstrlen(szFare) || !lstrlen(szTakeOff_Time) || !lstrlen(szLanding_Time) || !lstrlen(szSeat_Number)) { MessageBox(hEntryDlg, TEXT(&quot;请您填写完整航班信息！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } q = flightlink.head; while (q){ if (!lstrcmp(q-&gt;Flight_Number, szFlight_Number) &amp;&amp; !lstrcmp(q-&gt;Date,szDate)){ MessageBox(hEntryDlg, TEXT(&quot;对不起，同一航班在一天内只能有一班&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); free(p); return FALSE; } q = q-&gt;Next; }//while lstrcpy(p-&gt;Date, szDate); //填入录入航班结点信息 lstrcpy(p-&gt;Discount, szDiscount); lstrcpy(p-&gt;Departure, szDeparture); lstrcpy(p-&gt;Destination, szDestination); lstrcpy(p-&gt;TakeOff_Time, szTakeOff_Time); lstrcpy(p-&gt;Landing_Time, szLanding_Time); lstrcpy(p-&gt;Flight_Number, szFlight_Number); p-&gt;Fare = _ttof(szFare); p-&gt;Seat_Number = _ttoi(szSeat_Number); p-&gt;Vacant_Seat = p-&gt;Seat_Number; p-&gt;Next = NULL; if (flightlink.head == NULL) //将新结点添至航班链表 flightlink.head = p; else flightlink.tail-&gt;Next = p; flightlink.tail = p; flightlink.Flight_Number++; //航班数目增加 MessageBox(hEntryDlg, TEXT(&quot;航班录入成功！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; }//EntryFlight() //修改航班信息 BOOL ModifyFlight(HWND hModifyDlg){ int seat_num; TCHAR szDiscount[16]; TCHAR szFare[16], szSeat_Number[16]; TCHAR szTakeOff_Time[16], szLanding_Time[16]; TCHAR Mdf_flt_num[16], Mdf_flt_date[16]; OrderForm *q; Flight *p; GetDlgItemText(hModifyDlg, IDC_MDFFLTNUM, Mdf_flt_num, 16); //获取要修改的航班 GetDlgItemText(hModifyDlg, IDC_MDFDATE, Mdf_flt_date, 16); if (!lstrlen(Mdf_flt_num)){ MessageBox(hModifyDlg, TEXT(&quot;请输入所要修改信息的航班号&quot;), TEXT(&quot;信息&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } GetDlgItemText(hModifyDlg, IDC_FARE, szFare, 16); //获取要修改的信息 GetDlgItemText(hModifyDlg, IDC_DISCOUNT, szDiscount, 16); GetDlgItemText(hModifyDlg, IDC_SEATNUM, szSeat_Number, 16); GetDlgItemText(hModifyDlg, IDC_TAKEOFFTIME, szTakeOff_Time, 16); GetDlgItemText(hModifyDlg, IDC_LANDINGTIME, szLanding_Time, 16); p = flightlink.head; while (p){ //查找要修改的航班 if (!lstrcmp(Mdf_flt_num, p-&gt;Flight_Number) &amp;&amp; !lstrcmp(Mdf_flt_date, p-&gt;Date)){ if (lstrlen(szFare)) //改变航班票价 p-&gt;Fare = _ttof(szFare); if (lstrlen(szDiscount)) //改变航班折扣 wsprintf(p-&gt;Discount, szDiscount); if (lstrlen(szSeat_Number)){ seat_num = _ttoi(szSeat_Number); if ((p-&gt;Seat_Number - seat_num) &gt; p-&gt;Vacant_Seat){ //余座数量&gt;=0 MessageBox(hModifyDlg, TEXT(&quot;对不起，座位数过少，请重新填写&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } p-&gt;Vacant_Seat -= p-&gt;Seat_Number - seat_num; //改变余票数量 p-&gt;Seat_Number = seat_num; //改变座位数 }//if if (lstrlen(szTakeOff_Time)){ //改变航班起飞时间 wsprintf(p-&gt;TakeOff_Time, szTakeOff_Time); q = allorder.head; //改变该航班所有订单出发时间 while (q){ if (!lstrcmp(q-&gt;Flight_Number, p-&gt;Flight_Number) &amp;&amp; !lstrcmp(q-&gt;Date, p-&gt;Date)) wsprintf(q-&gt;TakeOff_Time, szTakeOff_Time); q = q-&gt;Next; } }//if if (lstrlen(szLanding_Time)){ //改变航班降落时间 wsprintf(p-&gt;Landing_Time, szLanding_Time); q = allorder.head; //改变该航班所有订单降落时间 while (q) { if (!lstrcmp(q-&gt;Flight_Number, p-&gt;Flight_Number) &amp;&amp; !lstrcmp(q-&gt;Date, p-&gt;Date)) wsprintf(q-&gt;Landing_Time, szLanding_Time); q = q-&gt;Next; } }//if MessageBox(hModifyDlg, TEXT(&quot;修改成功！&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return TRUE; }//if p = p-&gt;Next; }//while MessageBox(hModifyDlg, TEXT(&quot;对不起，您所要修改的航班尚未录入。&quot;), TEXT(&quot;提示&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; }//ModifyFlight() 至此，订票系统的功能已经基本全部实现了，剩下的问题就是在程序退出时将账户、航班、订单数据写进文件里。 具体实现起来很简单，代码如下： //保存账户资料 BOOL WriteAccountData(HWND hMainDlg){ Passenger *p; FILE *fp; if ((fp = fopen(&quot;.\\AccountData.txt&quot;, &quot;w&quot;)) == NULL){ MessageBox(hMainDlg, TEXT(&quot;账户信息保存出现错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } p = psglink.head; while (p){ fprintf(fp, &quot;%s\n%s\n%s\n&quot;, p-&gt;Name, p-&gt;IdNum, p-&gt;PassWord); p = p-&gt;Next; }//while fclose(fp); return TRUE; }//WriteAccountData //保存订单信息 BOOL WriteOrderData(HWND hMainDlg){ OrderForm *p; FILE *fp; if ((fp = fopen(&quot;.\\OrderForm.txt&quot;, &quot;w&quot;)) == NULL){ MessageBox(hMainDlg, TEXT(&quot;订单信息保存出现错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } p = allorder.head; while (p){ fprintf(fp, &quot;%s\n&quot;, p-&gt;IdNum); fprintf(fp, &quot;%d\n&quot;, p-&gt;Order_Number); fprintf(fp, &quot;%d\n&quot;, p-&gt;Tickets_Num); fprintf(fp, &quot;%s\n&quot;, p-&gt;Flight_Number); fprintf(fp, &quot;%s\n&quot;, p-&gt;Departure); fprintf(fp, &quot;%s\n&quot;, p-&gt;Destination); fprintf(fp, &quot;%s\n&quot;, p-&gt;Date); fprintf(fp, &quot;%s\n&quot;, p-&gt;TakeOff_Time); fprintf(fp, &quot;%s\n&quot;, p-&gt;Landing_Time); p = p-&gt;Next; }//while fclose(fp); return TRUE; }//WriteOrderData() //保存航班信息 BOOL WriteFlightData(HWND hMainDlg){ Flight *p; FILE *fp; if ((fp = fopen(&quot;.\\FlightData.txt&quot;, &quot;w&quot;)) == NULL){ MessageBox(hMainDlg, TEXT(&quot;航班信息保存出现错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } p = flightlink.head; while (p){ fprintf(fp, &quot;%s\n&quot;, p-&gt;Flight_Number); fprintf(fp, &quot;%.2lf\n&quot;, p-&gt;Fare); fprintf(fp, &quot;%s\n&quot;, p-&gt;Discount); fprintf(fp, &quot;%d\n%d\n&quot;, p-&gt;Seat_Number, p-&gt;Vacant_Seat); fprintf(fp, &quot;%s\n&quot;, p-&gt;Departure); fprintf(fp, &quot;%s\n&quot;, p-&gt;Destination); fprintf(fp, &quot;%s\n&quot;, p-&gt;Date); fprintf(fp, &quot;%s\n&quot;, p-&gt;TakeOff_Time); fprintf(fp, &quot;%s\n&quot;, p-&gt;Landing_Time); p = p-&gt;Next; }//while fclose(fp); return TRUE; }//WriteFlight() 至此，我的处女作就算是完成了，其中还是有很多不足之处。查找算法只是简单的遍历链表，数据结构也只是采用了单链表，倒是订单用上了十字链表来存储。查找起来效率不高，一旦数据量变大，便会很耗费时间，不过考虑到这只是一个课程设计，数据量很小，查找起来时间耗费上没有多少差别，姑且就这样吧。]]></content>
      <categories>
        <category>windows程序设计</category>
      </categories>
      <tags>
        <tag>windows程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows API 开发飞机订票系统（二）]]></title>
    <url>%2F2014%2F11%2F27%2Fwindows%20API%20%E5%BC%80%E5%8F%91%E9%A3%9E%E6%9C%BA%E8%AE%A2%E7%A5%A8%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[呐，上回书说到写代码过程中遇到不少问题，在这里就一点一点慢慢道来吧。 首先，定义的结构体、全局变量和函数如下： // Flight.c : 定义应用程序的入口点。 // #include &quot;stdafx.h&quot; //订单 typedef struct OrderForm{ TCHAR IdNum[32]; //订单用户身份证号 int Order_Number; //订单号 int Tickets_Num; //订票数量 TCHAR Flight_Number[16]; //航班号 TCHAR Departure[16]; //出发地 TCHAR Destination[16]; //目的地 TCHAR Date[16]; //出发日期 TCHAR TakeOff_Time[16]; //起飞时间 TCHAR Landing_Time[16]; //降落时间 struct OrderForm *Next; //所有订单链表next struct OrderForm *psgNext; //用户订单链表next }OrderForm; //乘客订单链表 typedef struct PsgOrderLink{ int OrderNum; //订单数目 OrderForm *head; //头结点 OrderForm *tail; //尾结点 }PsgOrderLink; //所有订单列表 typedef struct AllOrderLink{ int AllOrderNum; //所有订单数目 OrderForm *head; //头结点 OrderForm *tail; //尾结点 }AllOrderLink; //乘客 typedef struct Passenger{ TCHAR Name[16]; //姓名 TCHAR IdNum[32]; //身份证号码 TCHAR PassWord[32]; //密码 int TicketNum; //订单数目 PsgOrderLink OrderLink; //用户所有订单 struct Passenger *Next; }Passenger; //乘客链表 typedef struct PsgLinkList{ int PsgNum; //账户数量 Passenger *head; //头结点 Passenger *tail; //尾结点 }PsgLinkList; //航班 typedef struct Flight{ double Fare; //票价 int Seat_Number; //座位数 int Vacant_Seat; //空余座位数 TCHAR Discount[16]; //折扣 TCHAR Flight_Number[16]; //航班号 TCHAR Departure[16]; //出发地 TCHAR Destination[16]; //目的地 TCHAR Date[16]; //出发日期 TCHAR TakeOff_Time[16]; //起飞时间 TCHAR Landing_Time[16]; //降落时间 struct Flight *Next; }Flight; //航班链表 typedef struct FlightLinkList{ Flight *head; //头结点 Flight *tail; //尾结点 int Flight_Number; //航班数目 }FilghtLinkList; // 全局变量: HICON hIcon; HINSTANCE hInst; //当前实例 static TCHAR szBuffer[256]; //缓冲区 static PsgLinkList psglink; //所有账户_链表 static Passenger *passenger; //登陆账户信息 static AllOrderLink allorder; //所有订单_链表 static FilghtLinkList flightlink; //所有航班_链表 //函数声明 BOOL AccountLogIn(HWND); //账户登陆 BOOL AccountRegister(HWND); //注册账户 BOOL ReadFlightData(HWND); //读入航班信息 BOOL ReadAccountData(HWND); //读入账户资料 BOOL ReadAccountOrder(HWND,Passenger*); //读入所有订单、账户订单 BOOL SearchFlight(HWND); //查询航班 BOOL BookTickets(HWND); //订票 BOOL _Book_Tickets(HWND,Flight*,int); //订票 BOOL Recommend(HWND,Flight*,int); //航班建议 BOOL ReturnTickets(HWND); //退票 BOOL EntryFlight(HWND); //录入航班 BOOL ModifyFlight(HWND); //修改航班信息 BOOL PrintFlight(HWND, Flight*); //输出航班信息 BOOL WriteFlightData(HWND); //保存航班信息 BOOL WriteAccountData(HWND); //保存账户资料 BOOL WriteOrderData(HWND); //保存订单信息 BOOL CALLBACK LogInDlgProc(HWND, UINT, WPARAM, LPARAM); //登陆窗口窗口过程 BOOL CALLBACK MainDlgProc(HWND, UINT, WPARAM, LPARAM); //主界面窗口过程 BOOL CALLBACK NameDlgProc(HWND, UINT, WPARAM, LPARAM); //获取新注册用户姓名窗口过程 BOOL CALLBACK FlightNumDlgProc(HWND, UINT, WPARAM, LPARAM); //获取用户输入机票数量窗口过程 BOOL CALLBACK EntryFlightProc(HWND, UINT, WPARAM, LPARAM); //录入航班窗口过程 BOOL CALLBACK ModifyFlightProc(HWND, UINT, WPARAM, LPARAM); //修改航班信息窗口过程 主函数如下： //主函数 int WINAPI WinMain(HINSTANCE hInstance,HINSTANCE hPrevInstance,LPSTR szCmdLine,int iCmdShow) { hInst = hInstance; InitCommonControls(); hIcon=LoadIcon(hInst, MAKEINTRESOURCE(IDI_ICON1)); return DialogBox(hInst, MAKEINTRESOURCE(IDD_LOGINDLG), NULL, (DLGPROC)LogInDlgProc); }//WinMain 登陆界面窗口过程： //登陆窗口_窗口过程 BOOL CALLBACK LogInDlgProc(HWND hwndDlg, UINT uMsg, WPARAM wParam, LPARAM lParam) { switch (uMsg) { //WM_INITDIALOG是当其对话框和子控件全部创建完毕，将要显示内容的时候发送的消息 //因此可以在WM_INITDIALOG消息响应函数中添加对编辑框控件的初始化和修改 case WM_INITDIALOG: { if (hIcon) SendMessage(hwndDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); ReadAccountData(hwndDlg); //登陆对话框初始化时读入账户资料 ReadFlightData(hwndDlg); //登陆对话框初始化时读入航班信息 }//WM_INITDIALOG return TRUE; case WM_CLOSE: { EndDialog(hwndDlg, 0); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDC_LOGIN: AccountLogIn(hwndDlg); //登陆 break; case IDC_REGISTER: AccountRegister(hwndDlg); //注册 break; }//switch }//WM_COMMAND return TRUE; }//switch return FALSE; }//LogInDlgProc（） 我在对话框初始化时调用了下述函数来 加载程序标题栏的图标： if (hIcon) SendMessage(hwndDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); 接下来就该读取文件了。 那么问题就来了，挖掘机…额，不对，应该怎么读入账户资料和航班信息？ 我把 账户资料和航班信息储存在了.txt文件里，每一行是结构体的一个成员，一个一个读入。 两个读入函数代码如下： //读入账户信息 BOOL ReadAccountData(HWND hwndDlg){ FILE *fp; passenger = (Passenger *)malloc(sizeof(Passenger)); //为登录账户分配内存 if (!passenger){ MessageBox(hwndDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); return FALSE; }//if psglink.head = NULL; psglink.tail = NULL; psglink.PsgNum = 0; if ((fp = fopen(&quot;.\\AccountData.txt&quot;, &quot;r+&quot;)) == NULL){ //打开文件 MessageBox(hwndDlg, TEXT(&quot;账户文件读入错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); }//if while (!feof(fp)){ Passenger *p = (Passenger *)malloc(sizeof(Passenger)); if (!p){ MessageBox(hwndDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); return FALSE; }//if //读入账户姓名、身份证号、密码 if (fscanf(fp, &quot;%s%s%s&quot;, p-&gt;Name, p-&gt;IdNum, p-&gt;PassWord) == EOF){ free(p); break; } p-&gt;Next = NULL; if (psglink.head == NULL) //读入第一个账户信息时，头、尾结点均指向p psglink.head = p; else psglink.tail-&gt;Next = p; //否则，尾结点Next指向p psglink.tail = p; //尾结点指向p psglink.PsgNum++; //已注册账户个数 }//while fclose(fp); //关闭文件 return TRUE; }//ReadAccountData(HWND) //读入航班信息 BOOL ReadFlightData(HWND hwndDlg){ int flag = 0; FILE *fp; flightlink.Flight_Number = 0; flightlink.head = NULL; flightlink.tail = NULL; if ((fp = fopen(&quot;.\\FlightData.txt&quot;, &quot;r&quot;)) == NULL){ //打开文件 MessageBox(hwndDlg, TEXT(&quot;账户文件读入错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); }//if while (!feof(fp)){ Flight *p = (Flight *)malloc(sizeof(Flight)); if (!p){ MessageBox(hwndDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); return FALSE; }//if //读入航班信息 if (fscanf(fp, &quot;%s%lf%s%d%d%s%s%s%s%s&quot;, p-&gt;Flight_Number, &amp;p-&gt;Fare, p-&gt;Discount, &amp;p-&gt;Seat_Number, &amp;p-&gt;Vacant_Seat, p-&gt;Departure, p-&gt;Destination, p-&gt;Date, p-&gt;TakeOff_Time, p-&gt;Landing_Time) == EOF) { free(p); break; } p-&gt;Next = NULL; if (flightlink.head == NULL) //添加至链表 flightlink.head = p; else flightlink.tail-&gt;Next = p; flightlink.tail = p; flightlink.Flight_Number++; }//while fclose(fp); //关闭文件 return TRUE; }//ReadFlightData() 编译运行的时候会报错，报错信息是大体是说fopen()函数不安全，根据提示信息，解决办法是在文件头部做如下定义： #define _CRT_SECURE_NO_WARNINGS 或者是在项目-&gt;属性-&gt;c/c++-&gt;预处理器-&gt;预处理器定义，后面加上_CRT_SECURE_NO_WARNINGS就行了。 结下来又遇到问题了：程序退出把数据写入txt文件时每行末尾都会有一个\n，读入数据的时候用的是feof()函数，而feof()返回的其实是”最后一次读操作的内容”，与数据库中的eof()不同，eof()读取的是当前指针位置。因此在读到文件末尾的时候，程序会多执行一次循环，为了防止这种情况，我采取的是检查fscanf()返回值的方法，在此以读入账户资料时为例： //读入账户姓名、身份证号、密码 if (fscanf(fp, &quot;%s%s%s&quot;, p-&gt;Name, p-&gt;IdNum, p-&gt;PassWord) == EOF){ &lt;span style=&quot;white-space:pre&quot;&gt; &lt;/span&gt;free(p); break; } 下面继续贴函数代码： //登陆用户验证 BOOL AccountLogIn(HWND hwndDlg){ int flag = 0; //flag！=0则该用户已注册，flag==0则该用户尚未注册 Passenger *p; GetDlgItemText(hwndDlg, IDC_IDEDIT, passenger-&gt;IdNum, 256); //获取用户输入ID GetDlgItemText(hwndDlg, IDC_PSWEDIT, passenger-&gt;PassWord, 256); //获取用户输入密码 p = psglink.head; while (p){ //在用户链表查找登陆用户ID if (!lstrcmp(passenger-&gt;IdNum, p-&gt;IdNum)){ flag++; //该用户已注册 if (!lstrcmp(passenger-&gt;PassWord, p-&gt;PassWord)){ //密码匹配，登陆成功 lstrcpy(passenger-&gt;Name, p-&gt;Name); MessageBox(hwndDlg, TEXT(&quot;登陆成功，单击确定进入程序主界面&quot;), TEXT(&quot;登陆成功&quot;), MB_OK | MB_ICONINFORMATION); break; }//if else{ //密码错误，退出循环 MessageBox(hwndDlg, TEXT(&quot;密码错误，请重新输入&quot;), TEXT(&quot;密码错误&quot;), MB_OK | MB_ICONERROR); return FALSE; }//else }//if p = p-&gt;Next; }//while if (!flag){ //用户尚未注册 if (lstrlen(passenger-&gt;PassWord)==0) MessageBox(hwndDlg, TEXT(&quot;请输入密码！&quot;), TEXT(&quot;信息&quot;), MB_OK | MB_ICONINFORMATION); else MessageBox(hwndDlg, TEXT(&quot;该账户尚未注册，请先注册&quot;), TEXT(&quot;信息&quot;), MB_OK | MB_ICONINFORMATION); }//if else{ //关闭登陆界面，弹出主界面 EndDialog(hwndDlg, TRUE); if (ReadAccountOrder(hwndDlg, passenger)) //读取用户订单 DialogBox(hInst, MAKEINTRESOURCE(IDD_MAINDLG), NULL, (DLGPROC)MainDlgProc); }//else return TRUE; }//AccountLogIn(HWND) //用户注册 BOOL AccountRegister(HWND hwndDlg){ GetDlgItemText(hwndDlg, IDC_IDEDIT, passenger-&gt;IdNum, 256); //获取用户输入ID GetDlgItemText(hwndDlg, IDC_PSWEDIT, passenger-&gt;PassWord, 256); //获取用户输入密码 if (lstrlen(passenger-&gt;PassWord) == 0){ MessageBox(hwndDlg, TEXT(&quot;请输入注册用户密码！&quot;), TEXT(&quot;信息&quot;), MB_OK | MB_ICONINFORMATION); return FALSE; } DialogBox(hInst, MAKEINTRESOURCE(IDD_NAMEDLG), NULL, (DLGPROC)NameDlgProc); //获取新注册用户姓名 if (lstrlen(passenger-&gt;Name) == 0) return FALSE; passenger-&gt;Next = NULL; if (psglink.head == NULL) //该注册账户为第一个账户时，头、尾结点均指向passenger psglink.head = passenger; else psglink.tail-&gt;Next = passenger; //将新注册账户资料添加至账户链表 psglink.tail = passenger; //链表尾指针指向链表尾 psglink.PsgNum++; //注册用户数目加1 passenger-&gt;TicketNum = 0; passenger-&gt;OrderLink.head = NULL; //乘客订单链表初始化 passenger-&gt;OrderLink.tail = NULL; passenger-&gt;OrderLink.OrderNum = 0; MessageBox(hwndDlg, TEXT(&quot;注册成功！请单击确定进入主界面&quot;), TEXT(&quot;注册成功&quot;), MB_OK | MB_ICONINFORMATION); EndDialog(hwndDlg, TRUE); //关闭登陆界面 DialogBox(hInst, MAKEINTRESOURCE(IDD_MAINDLG), NULL, (DLGPROC)MainDlgProc); //弹出主界面 return TRUE; }//AccountRegister(HWND) //获取新注册用户姓名_窗口过程 BOOL CALLBACK NameDlgProc(HWND hNameDlg, UINT uMsg, WPARAM wParam, LPARAM lParam){ switch (uMsg) { case WM_INITDIALOG: { if (hIcon) SendMessage(hNameDlg, WM_SETICON, ICON_SMALL, (LPARAM)hIcon); } return TRUE; case WM_CLOSE: { wsprintf(passenger-&gt;IdNum, TEXT(&quot;\0&quot;)); EndDialog(hNameDlg, 0); }//WM_CLOSE return TRUE; case WM_COMMAND: { switch (LOWORD(wParam)) { case IDC_GETNAMEOK: { GetDlgItemText(hNameDlg, IDC_GETNAME, passenger-&gt;Name, 16); EndDialog(hNameDlg, TRUE); break; }//GETNAME case IDC_GETNAMECANCEL: { wsprintf(passenger-&gt;IdNum, TEXT(&quot;\0&quot;)); EndDialog(hNameDlg, TRUE); break; }//GETNAMECANCEL }//stitch }//WM_COMMAND return TRUE; }//stitch return FALSE; }//NameDlgProc() //读取订单信息 BOOL ReadAccountOrder(HWND hwndDlg, Passenger *passenger){ FILE *fp; allorder.AllOrderNum = 0; //订单链表初始化 allorder.head = NULL; allorder.tail = NULL; passenger-&gt;TicketNum = 0; //乘客订单链表初始化 passenger-&gt;OrderLink.head = NULL; passenger-&gt;OrderLink.tail = NULL; passenger-&gt;OrderLink.OrderNum = 0; if ((fp = fopen(&quot;.\\OrderForm.txt&quot;, &quot;r&quot;)) == NULL){ //打开存储订单信息文件 MessageBox(hwndDlg, TEXT(&quot;订单文件读入错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); return FALSE; } while (!feof(fp)){ OrderForm *p = (OrderForm *)malloc(sizeof(OrderForm)); if (!p){ MessageBox(hwndDlg, TEXT(&quot;内存申请错误!&quot;), TEXT(&quot;错误&quot;), MB_OK | MB_ICONERROR); EndDialog(hwndDlg, 0); return FALSE; }//if if (fscanf(fp, &quot;%s%d%d%s%s%s%s%s%s&quot;, p-&gt;IdNum, //读取订单信息 &amp;p-&gt;Order_Number, &amp;p-&gt;Tickets_Num, p-&gt;Flight_Number, p-&gt;Departure, p-&gt;Destination, p-&gt;Date, p-&gt;TakeOff_Time, p-&gt;Landing_Time) == EOF) { free(p); break; } p-&gt;Next = NULL; p-&gt;psgNext = NULL; if (allorder.head == NULL){ //将结点添至订单链表末尾 allorder.head = p; } else allorder.tail-&gt;Next = p; allorder.tail = p; allorder.AllOrderNum++; //订单数目增加 if (!lstrcmp(p-&gt;IdNum, passenger-&gt;IdNum)){ //若该订单为当前登录账户订单，则添至用户订单链表末尾 if (passenger-&gt;OrderLink.head == NULL){ //将结点添至用户订单链表末尾 passenger-&gt;OrderLink.head = p; } else passenger-&gt;OrderLink.tail-&gt;psgNext = p; passenger-&gt;OrderLink.tail = p; passenger-&gt;TicketNum += p-&gt;Tickets_Num; passenger-&gt;OrderLink.OrderNum++; //订单数目增加 }//if }//while fclose(fp); return TRUE; }//ReadAccountOrder() 至此，登录对话框部分已经完成。下篇博客来完成主界面的部分功能…..]]></content>
      <categories>
        <category>windows程序设计</category>
      </categories>
      <tags>
        <tag>windows程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows API 开发飞机订票系统（一）]]></title>
    <url>%2F2014%2F11%2F26%2Fwindows%20API%20%E5%BC%80%E5%8F%91%E9%A3%9E%E6%9C%BA%E8%AE%A2%E7%A5%A8%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[课程设计做一个飞机订票系统，c语言实现，功能如下： 录入： 可以录入航班情况（数据可以存储在一个数据文件中，数据结构、具体数据自定） 查询： 可以查询某个航线的情况（如，输入航班号，查询起降时间，起飞抵达城市，航班票价，票价折扣，确定航班是否满仓）； 可以输入起飞抵达城市，查询飞机航班情况； 订票：（订票情况可以存在一个数据文件中，结构自己设定） 可以订票，如果该航班已经无票，可以提供相关可选择航班； 退票： 可退票，退票后修改相关数据文件； 客户资料有姓名，证件号，订票数量及航班情况，订单要有编号。 修改航班信息： 当航班信息改变可以修改航班数据文件 要求： 根据以上功能说明，设计航班信息，订票信息的存储结构，设计程序完成功能； 写惯了控制台程序，所以打算做个界面出来，时间也很充裕，于是就自学了windows API，开发环境为vs2013。 代码以及程序已打包，下载地址：http://download.csdn.net/download/u013805360/8213827 下面就开始一步一步晒代码了 下面代码是头文件 // stdafx.h : 标准系统包含文件的包含文件， // 或是经常使用但不常更改的 // 特定于项目的包含文件 // #pragma once #define _CRT_SECURE_NO_WARNINGS #define _CRT_NON_CONFORMING_SWPRINTFS #define WIN32_LEAN_AND_MEAN // 从 Windows 头文件中排除极少使用的信息 // Windows 头文件: #include &lt;windows.h&gt; // C 运行时头文件 #include &lt;stdlib.h&gt; #include &lt;math.h&gt; #include &lt;malloc.h&gt; #include &lt;memory.h&gt; #include &lt;tchar.h&gt; #include &lt;string.h&gt; #include &lt;stdio.h&gt; // 包括 SDKDDKVer.h 将定义可用的最高版本的 Windows 平台。 #include &lt;SDKDDKVer.h&gt; // TODO: 在此处引用程序需要的其他头文件 #include&lt;commctrl.h&gt; #include &quot;resource.h&quot; #pragma comment(lib, &quot;comctl32.lib&quot;) 下面是资源头文件 //{{NO_DEPENDENCIES}} // Microsoft Visual C++ 生成的包含文件。 // 供 Flight.rc 使用 // #define IDC_MYICON 2 #define IDOK2 2 #define IDD_MYHOMEWORK_DIALOG 102 #define IDD_ABOUTBOX 103 #define IDD_LOGINDLG 103 #define IDI_ICON1 128 #define IDB_BITMAP1 133 #define IDR_MAINFRAME 134 #define IDD_MAINDLG 136 #define IDD_NAMEDLG 138 #define IDB_BITMAP2 144 #define IDD_FLTNUM 147 #define IDD_ENTRY 149 #define IDD_MODIFYFLT 150 #define IDC_ID 1002 #define IDC_PASSWORD 1003 #define IDC_IDEDIT 1005 #define IDC_PSWEDIT 1006 #define IDC_LOGIN 1007 #define IDC_REGISTER 1008 #define IDC_IMAGE 1009 #define IDC_GETNAMEOK 1011 #define IDC_GETNAME 1012 #define IDC_GETNAMECANCEL 1014 #define IDC_DEPARTURE 1019 #define IDC_DESTINATION 1020 #define IDC_FLIGHTNUM 1021 #define IDC_FLTNUM 1022 #define IDC_FARE 1023 #define IDC_LANDINGTIME 1024 #define IDC_DATE 1037 #define IDC_SEARCH 1038 #define IDC_TICKET 1039 #define IDC_RETURNTICKET 1040 #define IDC_ENTRY 1041 #define IDC_MODIFYFLIGHT 1042 #define IDC_INFORMATION 1043 #define IDC_TICKETNUM 1044 #define IDC_TAKEOFFTIME 1051 #define IDC_SEATNUM 1053 #define IDC_DISCOUNT 1054 #define IDC_ADDFLT 1055 #define IDC_QUIT 1056 #define IDC_MDFFLTNUM 1058 #define IDC_MDFDATE 1059 #define IDC_MODIFY 1060 #define IDC_STATIC -1 // Next default values for new objects // #ifdef APSTUDIO_INVOKED #ifndef APSTUDIO_READONLY_SYMBOLS #define _APS_NO_MFC 1 #define _APS_NEXT_RESOURCE_VALUE 152 #define _APS_NEXT_COMMAND_VALUE 32771 #define _APS_NEXT_CONTROL_VALUE 1064 #define _APS_NEXT_SYMED_VALUE 110 #endif #endif 资源文件： // Microsoft Visual C++ generated resource script. // #include &quot;resource.h&quot; #define APSTUDIO_READONLY_SYMBOLS ///////////////////////////////////////////////////////////////////////////// // // Generated from the TEXTINCLUDE 2 resource. // #define APSTUDIO_HIDDEN_SYMBOLS #include &quot;windows.h&quot; #undef APSTUDIO_HIDDEN_SYMBOLS ///////////////////////////////////////////////////////////////////////////// #undef APSTUDIO_READONLY_SYMBOLS ///////////////////////////////////////////////////////////////////////////// // 中文(简体，中国) resources #if !defined(AFX_RESOURCE_DLL) || defined(AFX_TARG_CHS) LANGUAGE LANG_CHINESE, SUBLANG_CHINESE_SIMPLIFIED ///////////////////////////////////////////////////////////////////////////// // // Dialog // IDD_LOGINDLG DIALOGEX 230, 120, 307, 175 STYLE DS_SETFONT | DS_MODALFRAME | DS_FIXEDSYS | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;登陆&quot; FONT 9, &quot;MS Shell Dlg&quot;, 0, 0, 0x1 BEGIN CTEXT &quot;身份证号&quot;,IDC_ID,99,60,31,8,SS_CENTERIMAGE CONTROL IDB_BITMAP1,IDC_IMAGE,&quot;Static&quot;,SS_BITMAP,14,19,74,103 CTEXT &quot;密码&quot;,IDC_PASSWORD,99,87,31,8,SS_CENTERIMAGE EDITTEXT IDC_IDEDIT,138,58,116,13,ES_AUTOHSCROLL EDITTEXT IDC_PSWEDIT,138,84,116,13,ES_PASSWORD | ES_AUTOHSCROLL | ES_WANTRETURN CTEXT &quot;灰机订票系统&quot;,IDC_STATIC,105,18,111,24,SS_CENTERIMAGE DEFPUSHBUTTON &quot;登陆&quot;,IDC_LOGIN,139,118,39,17 PUSHBUTTON &quot;注册&quot;,IDC_REGISTER,202,118,39,17 END IDD_MAINDLG DIALOGEX 0, 0, 358, 226 STYLE DS_SETFONT | DS_MODALFRAME | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;飞机订票系统&quot; FONT 10, &quot;Microsoft YaHei UI&quot;, 400, 0, 0x86 BEGIN CTEXT &quot;欢迎来到飞机订票系统&quot;,IDC_STATIC,145,16,67,8 EDITTEXT IDC_DEPARTURE,38,39,57,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_DESTINATION,130,39,57,12,ES_AUTOHSCROLL | ES_WANTRETURN CONTROL &quot;出发地：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,9,41,24,11 CONTROL &quot;目的地：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,102,41,24,11 CONTROL &quot;日期：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,102,70,18,8 CTEXT &quot;航班号：&quot;,IDC_STATIC,10,70,26,8 CTEXT &quot;航班信息&quot;,IDC_STATIC,16,120,31,8 CONTROL IDB_BITMAP2,IDC_STATIC,&quot;Static&quot;,SS_BITMAP,271,27,75,70 EDITTEXT IDC_FLIGHTNUM,38,68,57,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;&quot;,IDC_DATE,&quot;SysDateTimePick32&quot;,DTS_RIGHTALIGN | WS_TABSTOP,130,68,57,12 DEFPUSHBUTTON &quot;查询&quot;,IDC_SEARCH,38,96,33,14 PUSHBUTTON &quot;订票&quot;,IDC_TICKET,95,96,33,14 PUSHBUTTON &quot;退票&quot;,IDC_RETURNTICKET,152,96,33,14 PUSHBUTTON &quot;航班录入&quot;,IDC_ENTRY,229,52,43,15 PUSHBUTTON &quot;修改航班信息&quot;,IDC_MODIFYFLIGHT,229,81,43,15 EDITTEXT IDC_INFORMATION,18,131,322,88,ES_MULTILINE | ES_AUTOVSCROLL | ES_AUTOHSCROLL | ES_READONLY | WS_VSCROLL | WS_HSCROLL END IDD_NAMEDLG DIALOGEX 0, 0, 260, 116 STYLE DS_SETFONT | DS_MODALFRAME | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;注册&quot; FONT 9, &quot;Microsoft YaHei UI&quot;, 400, 0, 0x86 BEGIN EDITTEXT IDC_GETNAME,99,47,81,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CTEXT &quot;请输入用户真实姓名&quot;,IDC_STATIC,98,21,63,8 CTEXT &quot;姓名：&quot;,IDC_STATIC,61,49,33,11 DEFPUSHBUTTON &quot;确认提交&quot;,IDC_GETNAMEOK,78,83,44,16,WS_GROUP PUSHBUTTON &quot;取消&quot;,IDC_GETNAMECANCEL,146,83,44,16 END IDD_FLTNUM DIALOGEX 0, 0, 181, 87 STYLE DS_SETFONT | DS_MODALFRAME | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;机票数量&quot; FONT 10, &quot;Microsoft YaHei UI&quot;, 400, 0, 0x86 BEGIN EDITTEXT IDC_TICKETNUM,72,35,37,12,ES_AUTOHSCROLL CONTROL &quot;机票数量:&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,37,37,33,8 DEFPUSHBUTTON &quot;确定&quot;,IDOK,126,34,31,13 END IDD_ENTRY DIALOGEX 0, 0, 266, 153 STYLE DS_SETFONT | DS_MODALFRAME | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;航班录入&quot; FONT 10, &quot;Microsoft YaHei UI&quot;, 400, 0, 0x0 BEGIN CONTROL &quot;请输入录入航班信息&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,103,18,59,8 EDITTEXT IDC_DEPARTURE,41,35,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_DESTINATION,123,35,31,12,ES_AUTOHSCROLL | ES_WANTRETURN CONTROL &quot;出发地：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,16,36,24,11 CONTROL &quot;目的地：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,98,36,24,8 CONTROL &quot;日期：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,174,98,18,8 CTEXT &quot;航班号：&quot;,IDC_STATIC,16,67,26,8 EDITTEXT IDC_TAKEOFFTIME,206,35,35,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;价格：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,98,67,24,8 CONTROL &quot;座位数：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,16,98,24,8 CONTROL &quot;折扣：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,98,98,24,8 EDITTEXT IDC_FLTNUM,41,65,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_FARE,123,65,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_LANDINGTIME,206,65,35,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;起飞时间：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,174,36,30,8 CONTROL &quot;降落时间：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,174,67,30,8 EDITTEXT IDC_SEATNUM,41,96,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_DISCOUNT,123,96,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;&quot;,IDC_DATE,&quot;SysDateTimePick32&quot;,DTS_RIGHTALIGN | WS_TABSTOP,198,96,57,12 DEFPUSHBUTTON &quot;添加&quot;,IDC_ADDFLT,75,120,37,15 PUSHBUTTON &quot;退出&quot;,IDC_QUIT,153,120,37,15 END IDD_MODIFYFLT DIALOGEX 0, 0, 323, 200 STYLE DS_SETFONT | DS_MODALFRAME | DS_CENTER | WS_POPUP | WS_CAPTION | WS_SYSMENU CAPTION &quot;航班录入&quot; FONT 10, &quot;Microsoft YaHei UI&quot;, 400, 0, 0x0 BEGIN EDITTEXT IDC_MDFFLTNUM,59,34,44,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CTEXT &quot;航班号：&quot;,IDC_STATIC,28,36,26,8 GROUPBOX &quot;请输入要修改的信息&quot;,IDC_STATIC,7,65,309,128 LTEXT &quot;请输入修改航班航班号&quot;,IDC_STATIC,10,14,65,8 CTEXT &quot;日期：&quot;,IDC_STATIC,149,36,26,8 CONTROL &quot;&quot;,IDC_MDFDATE,&quot;SysDateTimePick32&quot;,DTS_RIGHTALIGN | WS_TABSTOP,175,34,57,12 EDITTEXT IDC_FARE,56,96,28,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;价格：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,23,99,24,8 CONTROL &quot;座位数：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,198,99,24,8 CONTROL &quot;折扣：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,110,99,24,8 EDITTEXT IDC_DISCOUNT,144,96,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_SEATNUM,228,96,31,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP CONTROL &quot;起飞时间：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,23,136,30,8 CONTROL &quot;降落时间：&quot;,IDC_STATIC,&quot;Static&quot;,SS_LEFTNOWORDWRAP | WS_GROUP,111,136,30,8 EDITTEXT IDC_TAKEOFFTIME,56,133,35,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP EDITTEXT IDC_LANDINGTIME,144,133,35,12,ES_AUTOHSCROLL | ES_WANTRETURN | WS_GROUP DEFPUSHBUTTON &quot;确认修改&quot;,IDC_MODIFY,104,168,37,15 PUSHBUTTON &quot;退出&quot;,IDC_QUIT,182,168,37,15 END ///////////////////////////////////////////////////////////////////////////// // // DESIGNINFO // #ifdef APSTUDIO_INVOKED GUIDELINES DESIGNINFO BEGIN IDD_LOGINDLG, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 300 TOPMARGIN, 7 BOTTOMMARGIN, 168 END IDD_MAINDLG, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 351 TOPMARGIN, 6 BOTTOMMARGIN, 220 END IDD_NAMEDLG, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 253 TOPMARGIN, 7 BOTTOMMARGIN, 108 END IDD_FLTNUM, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 174 TOPMARGIN, 7 BOTTOMMARGIN, 80 END IDD_ENTRY, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 259 TOPMARGIN, 7 BOTTOMMARGIN, 146 END IDD_MODIFYFLT, DIALOG BEGIN LEFTMARGIN, 7 RIGHTMARGIN, 316 TOPMARGIN, 7 BOTTOMMARGIN, 193 END END #endif // APSTUDIO_INVOKED #ifdef APSTUDIO_INVOKED ///////////////////////////////////////////////////////////////////////////// // // TEXTINCLUDE // 1 TEXTINCLUDE BEGIN &quot;resource.h\0&quot; END 2 TEXTINCLUDE BEGIN &quot;#ifndef APSTUDIO_INVOKED\r\n&quot; &quot;#include &quot;&quot;targetver.h&quot;&quot;\r\n&quot; &quot;#endif\r\n&quot; &quot;#define APSTUDIO_HIDDEN_SYMBOLS\r\n&quot; &quot;#include &quot;&quot;windows.h&quot;&quot;\r\n&quot; &quot;#undef APSTUDIO_HIDDEN_SYMBOLS\r\n&quot; &quot;\0&quot; END 3 TEXTINCLUDE BEGIN &quot;\r\n&quot; &quot;\0&quot; END #endif // APSTUDIO_INVOKED ///////////////////////////////////////////////////////////////////////////// // // Bitmap // IDB_BITMAP1 BITMAP &quot;login_2.bmp&quot; IDB_BITMAP2 BITMAP &quot;main_2.bmp&quot; IDB_BITMAP3 BITMAP &quot;login.bmp&quot; IDB_BITMAP4 BITMAP &quot;main.bmp&quot; ///////////////////////////////////////////////////////////////////////////// // // Icon // // Icon with lowest ID value placed first to ensure application icon // remains consistent on all systems. IDI_ICON1 ICON &quot;icon.ico&quot; #endif // 中文(简体，中国) resources ///////////////////////////////////////////////////////////////////////////// #ifndef APSTUDIO_INVOKED ///////////////////////////////////////////////////////////////////////////// // // Generated from the TEXTINCLUDE 3 resource. // ///////////////////////////////////////////////////////////////////////////// #endif // not APSTUDIO_INVOKED 具体实现代码见下篇博文吧，写代码的过程中还是遇到不少问题的。先附几张程序效果图，包含了一些个人二次元爱好….]]></content>
      <categories>
        <category>windows程序设计</category>
      </categories>
      <tags>
        <tag>windows程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于程序提示丢失msvcr120.dll的解决办法]]></title>
    <url>%2F2014%2F11%2F26%2F%E5%85%B3%E4%BA%8E%E7%A8%8B%E5%BA%8F%E6%8F%90%E7%A4%BA%E4%B8%A2%E5%A4%B1msvcr120.dll%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[程序的开发环境是vs2013，程序放在别人电脑上提示丢失msvcr120.dll，找了好一会儿，发现了问题所在。 项目-&gt;属性-&gt;c/c++-&gt;代码生成-&gt;运行库，改为多线程(/MT)，原本为多线程DLL(/MD)，这样就解决了。 另外，如果从Debug变为Release，要确保上述运行库不是多线程调试，否则也会出现类似问题]]></content>
      <categories>
        <category>windows程序设计</category>
      </categories>
      <tags>
        <tag>windows程序设计</tag>
      </tags>
  </entry>
</search>
